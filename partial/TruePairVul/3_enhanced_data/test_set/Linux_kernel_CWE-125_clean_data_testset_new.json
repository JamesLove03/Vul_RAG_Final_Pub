[
    {
        "cve_id": "CVE-2014-7825",
        "code_before_change": "static void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_enter *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->enter_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* get the size after alignment with the u32 buffer size field */\n\tsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\n\tsize = ALIGN(size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->enter_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\n\t\t\t       (unsigned long *)&rec->args);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "code_after_change": "static void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_enter *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->enter_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* get the size after alignment with the u32 buffer size field */\n\tsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\n\tsize = ALIGN(size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->enter_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\n\t\t\t       (unsigned long *)&rec->args);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}",
        "patch": "--- code before\n+++ code after\n@@ -8,7 +8,7 @@\n \tint size;\n \n \tsyscall_nr = trace_get_syscall_nr(current, regs);\n-\tif (syscall_nr < 0)\n+\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n \t\treturn;\n \tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n \t\treturn;",
        "function_modified_lines": {
            "added": [
                "\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)"
            ],
            "deleted": [
                "\tif (syscall_nr < 0)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the perf subsystem, which allows local users to cause a denial of service (out-of-bounds read and OOPS) or bypass the ASLR protection mechanism via a crafted application.",
        "id": 592
    },
    {
        "cve_id": "CVE-2017-9074",
        "code_before_change": "static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb,\n\t\t\t\t\t netdev_features_t features)\n{\n\tstruct sk_buff *segs = ERR_PTR(-EINVAL);\n\tunsigned int mss;\n\tunsigned int unfrag_ip6hlen, unfrag_len;\n\tstruct frag_hdr *fptr;\n\tu8 *packet_start, *prevhdr;\n\tu8 nexthdr;\n\tu8 frag_hdr_sz = sizeof(struct frag_hdr);\n\t__wsum csum;\n\tint tnl_hlen;\n\n\tmss = skb_shinfo(skb)->gso_size;\n\tif (unlikely(skb->len <= mss))\n\t\tgoto out;\n\n\tif (skb_gso_ok(skb, features | NETIF_F_GSO_ROBUST)) {\n\t\t/* Packet is from an untrusted source, reset gso_segs. */\n\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss);\n\n\t\t/* Set the IPv6 fragment id if not set yet */\n\t\tif (!skb_shinfo(skb)->ip6_frag_id)\n\t\t\tipv6_proxy_select_ident(dev_net(skb->dev), skb);\n\n\t\tsegs = NULL;\n\t\tgoto out;\n\t}\n\n\tif (skb->encapsulation && skb_shinfo(skb)->gso_type &\n\t    (SKB_GSO_UDP_TUNNEL|SKB_GSO_UDP_TUNNEL_CSUM))\n\t\tsegs = skb_udp_tunnel_segment(skb, features, true);\n\telse {\n\t\tconst struct ipv6hdr *ipv6h;\n\t\tstruct udphdr *uh;\n\n\t\tif (!pskb_may_pull(skb, sizeof(struct udphdr)))\n\t\t\tgoto out;\n\n\t\t/* Do software UFO. Complete and fill in the UDP checksum as HW cannot\n\t\t * do checksum of UDP packets sent as multiple IP fragments.\n\t\t */\n\n\t\tuh = udp_hdr(skb);\n\t\tipv6h = ipv6_hdr(skb);\n\n\t\tuh->check = 0;\n\t\tcsum = skb_checksum(skb, 0, skb->len, 0);\n\t\tuh->check = udp_v6_check(skb->len, &ipv6h->saddr,\n\t\t\t\t\t  &ipv6h->daddr, csum);\n\t\tif (uh->check == 0)\n\t\t\tuh->check = CSUM_MANGLED_0;\n\n\t\tskb->ip_summed = CHECKSUM_NONE;\n\n\t\t/* If there is no outer header we can fake a checksum offload\n\t\t * due to the fact that we have already done the checksum in\n\t\t * software prior to segmenting the frame.\n\t\t */\n\t\tif (!skb->encap_hdr_csum)\n\t\t\tfeatures |= NETIF_F_HW_CSUM;\n\n\t\t/* Check if there is enough headroom to insert fragment header. */\n\t\ttnl_hlen = skb_tnl_header_len(skb);\n\t\tif (skb->mac_header < (tnl_hlen + frag_hdr_sz)) {\n\t\t\tif (gso_pskb_expand_head(skb, tnl_hlen + frag_hdr_sz))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t/* Find the unfragmentable header and shift it left by frag_hdr_sz\n\t\t * bytes to insert fragment header.\n\t\t */\n\t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n\t\tnexthdr = *prevhdr;\n\t\t*prevhdr = NEXTHDR_FRAGMENT;\n\t\tunfrag_len = (skb_network_header(skb) - skb_mac_header(skb)) +\n\t\t\t     unfrag_ip6hlen + tnl_hlen;\n\t\tpacket_start = (u8 *) skb->head + SKB_GSO_CB(skb)->mac_offset;\n\t\tmemmove(packet_start-frag_hdr_sz, packet_start, unfrag_len);\n\n\t\tSKB_GSO_CB(skb)->mac_offset -= frag_hdr_sz;\n\t\tskb->mac_header -= frag_hdr_sz;\n\t\tskb->network_header -= frag_hdr_sz;\n\n\t\tfptr = (struct frag_hdr *)(skb_network_header(skb) + unfrag_ip6hlen);\n\t\tfptr->nexthdr = nexthdr;\n\t\tfptr->reserved = 0;\n\t\tif (!skb_shinfo(skb)->ip6_frag_id)\n\t\t\tipv6_proxy_select_ident(dev_net(skb->dev), skb);\n\t\tfptr->identification = skb_shinfo(skb)->ip6_frag_id;\n\n\t\t/* Fragment the skb. ipv6 header and the remaining fields of the\n\t\t * fragment header are updated in ipv6_gso_segment()\n\t\t */\n\t\tsegs = skb_segment(skb, features);\n\t}\n\nout:\n\treturn segs;\n}",
        "code_after_change": "static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb,\n\t\t\t\t\t netdev_features_t features)\n{\n\tstruct sk_buff *segs = ERR_PTR(-EINVAL);\n\tunsigned int mss;\n\tunsigned int unfrag_ip6hlen, unfrag_len;\n\tstruct frag_hdr *fptr;\n\tu8 *packet_start, *prevhdr;\n\tu8 nexthdr;\n\tu8 frag_hdr_sz = sizeof(struct frag_hdr);\n\t__wsum csum;\n\tint tnl_hlen;\n\n\tmss = skb_shinfo(skb)->gso_size;\n\tif (unlikely(skb->len <= mss))\n\t\tgoto out;\n\n\tif (skb_gso_ok(skb, features | NETIF_F_GSO_ROBUST)) {\n\t\t/* Packet is from an untrusted source, reset gso_segs. */\n\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss);\n\n\t\t/* Set the IPv6 fragment id if not set yet */\n\t\tif (!skb_shinfo(skb)->ip6_frag_id)\n\t\t\tipv6_proxy_select_ident(dev_net(skb->dev), skb);\n\n\t\tsegs = NULL;\n\t\tgoto out;\n\t}\n\n\tif (skb->encapsulation && skb_shinfo(skb)->gso_type &\n\t    (SKB_GSO_UDP_TUNNEL|SKB_GSO_UDP_TUNNEL_CSUM))\n\t\tsegs = skb_udp_tunnel_segment(skb, features, true);\n\telse {\n\t\tconst struct ipv6hdr *ipv6h;\n\t\tstruct udphdr *uh;\n\n\t\tif (!pskb_may_pull(skb, sizeof(struct udphdr)))\n\t\t\tgoto out;\n\n\t\t/* Do software UFO. Complete and fill in the UDP checksum as HW cannot\n\t\t * do checksum of UDP packets sent as multiple IP fragments.\n\t\t */\n\n\t\tuh = udp_hdr(skb);\n\t\tipv6h = ipv6_hdr(skb);\n\n\t\tuh->check = 0;\n\t\tcsum = skb_checksum(skb, 0, skb->len, 0);\n\t\tuh->check = udp_v6_check(skb->len, &ipv6h->saddr,\n\t\t\t\t\t  &ipv6h->daddr, csum);\n\t\tif (uh->check == 0)\n\t\t\tuh->check = CSUM_MANGLED_0;\n\n\t\tskb->ip_summed = CHECKSUM_NONE;\n\n\t\t/* If there is no outer header we can fake a checksum offload\n\t\t * due to the fact that we have already done the checksum in\n\t\t * software prior to segmenting the frame.\n\t\t */\n\t\tif (!skb->encap_hdr_csum)\n\t\t\tfeatures |= NETIF_F_HW_CSUM;\n\n\t\t/* Check if there is enough headroom to insert fragment header. */\n\t\ttnl_hlen = skb_tnl_header_len(skb);\n\t\tif (skb->mac_header < (tnl_hlen + frag_hdr_sz)) {\n\t\t\tif (gso_pskb_expand_head(skb, tnl_hlen + frag_hdr_sz))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t/* Find the unfragmentable header and shift it left by frag_hdr_sz\n\t\t * bytes to insert fragment header.\n\t\t */\n\t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n\t\tif (unfrag_ip6hlen < 0)\n\t\t\treturn ERR_PTR(unfrag_ip6hlen);\n\t\tnexthdr = *prevhdr;\n\t\t*prevhdr = NEXTHDR_FRAGMENT;\n\t\tunfrag_len = (skb_network_header(skb) - skb_mac_header(skb)) +\n\t\t\t     unfrag_ip6hlen + tnl_hlen;\n\t\tpacket_start = (u8 *) skb->head + SKB_GSO_CB(skb)->mac_offset;\n\t\tmemmove(packet_start-frag_hdr_sz, packet_start, unfrag_len);\n\n\t\tSKB_GSO_CB(skb)->mac_offset -= frag_hdr_sz;\n\t\tskb->mac_header -= frag_hdr_sz;\n\t\tskb->network_header -= frag_hdr_sz;\n\n\t\tfptr = (struct frag_hdr *)(skb_network_header(skb) + unfrag_ip6hlen);\n\t\tfptr->nexthdr = nexthdr;\n\t\tfptr->reserved = 0;\n\t\tif (!skb_shinfo(skb)->ip6_frag_id)\n\t\t\tipv6_proxy_select_ident(dev_net(skb->dev), skb);\n\t\tfptr->identification = skb_shinfo(skb)->ip6_frag_id;\n\n\t\t/* Fragment the skb. ipv6 header and the remaining fields of the\n\t\t * fragment header are updated in ipv6_gso_segment()\n\t\t */\n\t\tsegs = skb_segment(skb, features);\n\t}\n\nout:\n\treturn segs;\n}",
        "patch": "--- code before\n+++ code after\n@@ -72,6 +72,8 @@\n \t\t * bytes to insert fragment header.\n \t\t */\n \t\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n+\t\tif (unfrag_ip6hlen < 0)\n+\t\t\treturn ERR_PTR(unfrag_ip6hlen);\n \t\tnexthdr = *prevhdr;\n \t\t*prevhdr = NEXTHDR_FRAGMENT;\n \t\tunfrag_len = (skb_network_header(skb) - skb_mac_header(skb)) +",
        "function_modified_lines": {
            "added": [
                "\t\tif (unfrag_ip6hlen < 0)",
                "\t\t\treturn ERR_PTR(unfrag_ip6hlen);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The IPv6 fragmentation implementation in the Linux kernel through 4.11.1 does not consider that the nexthdr field may be associated with an invalid option, which allows local users to cause a denial of service (out-of-bounds read and BUG) or possibly have unspecified other impact via crafted socket and send system calls.",
        "id": 1563
    },
    {
        "cve_id": "CVE-2017-7277",
        "code_before_change": "void __skb_tstamp_tx(struct sk_buff *orig_skb,\n\t\t     struct skb_shared_hwtstamps *hwtstamps,\n\t\t     struct sock *sk, int tstype)\n{\n\tstruct sk_buff *skb;\n\tbool tsonly;\n\n\tif (!sk)\n\t\treturn;\n\n\ttsonly = sk->sk_tsflags & SOF_TIMESTAMPING_OPT_TSONLY;\n\tif (!skb_may_tx_timestamp(sk, tsonly))\n\t\treturn;\n\n\tif (tsonly) {\n#ifdef CONFIG_INET\n\t\tif ((sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS) &&\n\t\t    sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM)\n\t\t\tskb = tcp_get_timestamping_opt_stats(sk);\n\t\telse\n#endif\n\t\t\tskb = alloc_skb(0, GFP_ATOMIC);\n\t} else {\n\t\tskb = skb_clone(orig_skb, GFP_ATOMIC);\n\t}\n\tif (!skb)\n\t\treturn;\n\n\tif (tsonly) {\n\t\tskb_shinfo(skb)->tx_flags = skb_shinfo(orig_skb)->tx_flags;\n\t\tskb_shinfo(skb)->tskey = skb_shinfo(orig_skb)->tskey;\n\t}\n\n\tif (hwtstamps)\n\t\t*skb_hwtstamps(skb) = *hwtstamps;\n\telse\n\t\tskb->tstamp = ktime_get_real();\n\n\t__skb_complete_tx_timestamp(skb, sk, tstype);\n}",
        "code_after_change": "void __skb_tstamp_tx(struct sk_buff *orig_skb,\n\t\t     struct skb_shared_hwtstamps *hwtstamps,\n\t\t     struct sock *sk, int tstype)\n{\n\tstruct sk_buff *skb;\n\tbool tsonly, opt_stats = false;\n\n\tif (!sk)\n\t\treturn;\n\n\ttsonly = sk->sk_tsflags & SOF_TIMESTAMPING_OPT_TSONLY;\n\tif (!skb_may_tx_timestamp(sk, tsonly))\n\t\treturn;\n\n\tif (tsonly) {\n#ifdef CONFIG_INET\n\t\tif ((sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS) &&\n\t\t    sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM) {\n\t\t\tskb = tcp_get_timestamping_opt_stats(sk);\n\t\t\topt_stats = true;\n\t\t} else\n#endif\n\t\t\tskb = alloc_skb(0, GFP_ATOMIC);\n\t} else {\n\t\tskb = skb_clone(orig_skb, GFP_ATOMIC);\n\t}\n\tif (!skb)\n\t\treturn;\n\n\tif (tsonly) {\n\t\tskb_shinfo(skb)->tx_flags = skb_shinfo(orig_skb)->tx_flags;\n\t\tskb_shinfo(skb)->tskey = skb_shinfo(orig_skb)->tskey;\n\t}\n\n\tif (hwtstamps)\n\t\t*skb_hwtstamps(skb) = *hwtstamps;\n\telse\n\t\tskb->tstamp = ktime_get_real();\n\n\t__skb_complete_tx_timestamp(skb, sk, tstype, opt_stats);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \t\t     struct sock *sk, int tstype)\n {\n \tstruct sk_buff *skb;\n-\tbool tsonly;\n+\tbool tsonly, opt_stats = false;\n \n \tif (!sk)\n \t\treturn;\n@@ -16,9 +16,10 @@\n #ifdef CONFIG_INET\n \t\tif ((sk->sk_tsflags & SOF_TIMESTAMPING_OPT_STATS) &&\n \t\t    sk->sk_protocol == IPPROTO_TCP &&\n-\t\t    sk->sk_type == SOCK_STREAM)\n+\t\t    sk->sk_type == SOCK_STREAM) {\n \t\t\tskb = tcp_get_timestamping_opt_stats(sk);\n-\t\telse\n+\t\t\topt_stats = true;\n+\t\t} else\n #endif\n \t\t\tskb = alloc_skb(0, GFP_ATOMIC);\n \t} else {\n@@ -37,5 +38,5 @@\n \telse\n \t\tskb->tstamp = ktime_get_real();\n \n-\t__skb_complete_tx_timestamp(skb, sk, tstype);\n+\t__skb_complete_tx_timestamp(skb, sk, tstype, opt_stats);\n }",
        "function_modified_lines": {
            "added": [
                "\tbool tsonly, opt_stats = false;",
                "\t\t    sk->sk_type == SOCK_STREAM) {",
                "\t\t\topt_stats = true;",
                "\t\t} else",
                "\t__skb_complete_tx_timestamp(skb, sk, tstype, opt_stats);"
            ],
            "deleted": [
                "\tbool tsonly;",
                "\t\t    sk->sk_type == SOCK_STREAM)",
                "\t\telse",
                "\t__skb_complete_tx_timestamp(skb, sk, tstype);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The TCP stack in the Linux kernel through 4.10.6 mishandles the SCM_TIMESTAMPING_OPT_STATS feature, which allows local users to obtain sensitive information from the kernel's internal socket data structures or cause a denial of service (out-of-bounds read) via crafted system calls, related to net/core/skbuff.c and net/socket.c.",
        "id": 1492
    },
    {
        "cve_id": "CVE-2017-7277",
        "code_before_change": "void skb_complete_tx_timestamp(struct sk_buff *skb,\n\t\t\t       struct skb_shared_hwtstamps *hwtstamps)\n{\n\tstruct sock *sk = skb->sk;\n\n\tif (!skb_may_tx_timestamp(sk, false))\n\t\treturn;\n\n\t/* Take a reference to prevent skb_orphan() from freeing the socket,\n\t * but only if the socket refcount is not zero.\n\t */\n\tif (likely(atomic_inc_not_zero(&sk->sk_refcnt))) {\n\t\t*skb_hwtstamps(skb) = *hwtstamps;\n\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);\n\t\tsock_put(sk);\n\t}\n}",
        "code_after_change": "void skb_complete_tx_timestamp(struct sk_buff *skb,\n\t\t\t       struct skb_shared_hwtstamps *hwtstamps)\n{\n\tstruct sock *sk = skb->sk;\n\n\tif (!skb_may_tx_timestamp(sk, false))\n\t\treturn;\n\n\t/* Take a reference to prevent skb_orphan() from freeing the socket,\n\t * but only if the socket refcount is not zero.\n\t */\n\tif (likely(atomic_inc_not_zero(&sk->sk_refcnt))) {\n\t\t*skb_hwtstamps(skb) = *hwtstamps;\n\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND, false);\n\t\tsock_put(sk);\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -11,7 +11,7 @@\n \t */\n \tif (likely(atomic_inc_not_zero(&sk->sk_refcnt))) {\n \t\t*skb_hwtstamps(skb) = *hwtstamps;\n-\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);\n+\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND, false);\n \t\tsock_put(sk);\n \t}\n }",
        "function_modified_lines": {
            "added": [
                "\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND, false);"
            ],
            "deleted": [
                "\t\t__skb_complete_tx_timestamp(skb, sk, SCM_TSTAMP_SND);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The TCP stack in the Linux kernel through 4.10.6 mishandles the SCM_TIMESTAMPING_OPT_STATS feature, which allows local users to obtain sensitive information from the kernel's internal socket data structures or cause a denial of service (out-of-bounds read) via crafted system calls, related to net/core/skbuff.c and net/socket.c.",
        "id": 1493
    },
    {
        "cve_id": "CVE-2014-3180",
        "code_before_change": "\nCOMPAT_SYSCALL_DEFINE2(nanosleep, struct compat_timespec __user *, rqtp,\n\t\t       struct compat_timespec __user *, rmtp)\n{\n\tstruct timespec tu, rmt;\n\tmm_segment_t oldfs;\n\tlong ret;\n\n\tif (compat_get_timespec(&tu, rqtp))\n\t\treturn -EFAULT;\n\n\tif (!timespec_valid(&tu))\n\t\treturn -EINVAL;\n\n\toldfs = get_fs();\n\tset_fs(KERNEL_DS);\n\tret = hrtimer_nanosleep(&tu,\n\t\t\t\trmtp ? (struct timespec __user *)&rmt : NULL,\n\t\t\t\tHRTIMER_MODE_REL, CLOCK_MONOTONIC);\n\tset_fs(oldfs);\n\n\tif (ret) {\n\t\tstruct restart_block *restart\n\t\t\t= &current_thread_info()->restart_block;\n\n\t\trestart->fn = compat_nanosleep_restart;\n\t\trestart->nanosleep.compat_rmtp = rmtp;\n\n\t\tif (rmtp && compat_put_timespec(&rmt, rmtp))\n\t\t\treturn -EFAULT;\n\t}\n\n\treturn ret;\n}",
        "code_after_change": "\nCOMPAT_SYSCALL_DEFINE2(nanosleep, struct compat_timespec __user *, rqtp,\n\t\t       struct compat_timespec __user *, rmtp)\n{\n\tstruct timespec tu, rmt;\n\tmm_segment_t oldfs;\n\tlong ret;\n\n\tif (compat_get_timespec(&tu, rqtp))\n\t\treturn -EFAULT;\n\n\tif (!timespec_valid(&tu))\n\t\treturn -EINVAL;\n\n\toldfs = get_fs();\n\tset_fs(KERNEL_DS);\n\tret = hrtimer_nanosleep(&tu,\n\t\t\t\trmtp ? (struct timespec __user *)&rmt : NULL,\n\t\t\t\tHRTIMER_MODE_REL, CLOCK_MONOTONIC);\n\tset_fs(oldfs);\n\n\t/*\n\t * hrtimer_nanosleep() can only return 0 or\n\t * -ERESTART_RESTARTBLOCK here because:\n\t *\n\t * - we call it with HRTIMER_MODE_REL and therefor exclude the\n\t *   -ERESTARTNOHAND return path.\n\t *\n\t * - we supply the rmtp argument from the task stack (due to\n\t *   the necessary compat conversion. So the update cannot\n\t *   fail, which excludes the -EFAULT return path as well. If\n\t *   it fails nevertheless we have a bigger problem and wont\n\t *   reach this place anymore.\n\t *\n\t * - if the return value is 0, we do not have to update rmtp\n\t *    because there is no remaining time.\n\t *\n\t * We check for -ERESTART_RESTARTBLOCK nevertheless if the\n\t * core implementation decides to return random nonsense.\n\t */\n\tif (ret == -ERESTART_RESTARTBLOCK) {\n\t\tstruct restart_block *restart\n\t\t\t= &current_thread_info()->restart_block;\n\n\t\trestart->fn = compat_nanosleep_restart;\n\t\trestart->nanosleep.compat_rmtp = rmtp;\n\n\t\tif (rmtp && compat_put_timespec(&rmt, rmtp))\n\t\t\treturn -EFAULT;\n\t}\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -19,7 +19,26 @@\n \t\t\t\tHRTIMER_MODE_REL, CLOCK_MONOTONIC);\n \tset_fs(oldfs);\n \n-\tif (ret) {\n+\t/*\n+\t * hrtimer_nanosleep() can only return 0 or\n+\t * -ERESTART_RESTARTBLOCK here because:\n+\t *\n+\t * - we call it with HRTIMER_MODE_REL and therefor exclude the\n+\t *   -ERESTARTNOHAND return path.\n+\t *\n+\t * - we supply the rmtp argument from the task stack (due to\n+\t *   the necessary compat conversion. So the update cannot\n+\t *   fail, which excludes the -EFAULT return path as well. If\n+\t *   it fails nevertheless we have a bigger problem and wont\n+\t *   reach this place anymore.\n+\t *\n+\t * - if the return value is 0, we do not have to update rmtp\n+\t *    because there is no remaining time.\n+\t *\n+\t * We check for -ERESTART_RESTARTBLOCK nevertheless if the\n+\t * core implementation decides to return random nonsense.\n+\t */\n+\tif (ret == -ERESTART_RESTARTBLOCK) {\n \t\tstruct restart_block *restart\n \t\t\t= &current_thread_info()->restart_block;\n \n@@ -29,6 +48,5 @@\n \t\tif (rmtp && compat_put_timespec(&rmt, rmtp))\n \t\t\treturn -EFAULT;\n \t}\n-\n \treturn ret;\n }",
        "function_modified_lines": {
            "added": [
                "\t/*",
                "\t * hrtimer_nanosleep() can only return 0 or",
                "\t * -ERESTART_RESTARTBLOCK here because:",
                "\t *",
                "\t * - we call it with HRTIMER_MODE_REL and therefor exclude the",
                "\t *   -ERESTARTNOHAND return path.",
                "\t *",
                "\t * - we supply the rmtp argument from the task stack (due to",
                "\t *   the necessary compat conversion. So the update cannot",
                "\t *   fail, which excludes the -EFAULT return path as well. If",
                "\t *   it fails nevertheless we have a bigger problem and wont",
                "\t *   reach this place anymore.",
                "\t *",
                "\t * - if the return value is 0, we do not have to update rmtp",
                "\t *    because there is no remaining time.",
                "\t *",
                "\t * We check for -ERESTART_RESTARTBLOCK nevertheless if the",
                "\t * core implementation decides to return random nonsense.",
                "\t */",
                "\tif (ret == -ERESTART_RESTARTBLOCK) {"
            ],
            "deleted": [
                "\tif (ret) {",
                ""
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In kernel/compat.c in the Linux kernel before 3.17, as used in Google Chrome OS and other products, there is a possible out-of-bounds read. restart_syscall uses uninitialized data when restarting compat_sys_nanosleep. NOTE: this is disputed because the code path is unreachable",
        "id": 510
    },
    {
        "cve_id": "CVE-2017-16530",
        "code_before_change": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tint alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (alt < 0)\n\t\treturn alt;\n\n\treturn usb_set_interface(udev,\n\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n}",
        "code_after_change": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tstruct usb_host_interface *alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (!alt)\n\t\treturn -ENODEV;\n\n\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n\t\t\talt->desc.bAlternateSetting);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,12 +1,12 @@\n static int uas_switch_interface(struct usb_device *udev,\n \t\t\t\tstruct usb_interface *intf)\n {\n-\tint alt;\n+\tstruct usb_host_interface *alt;\n \n \talt = uas_find_uas_alt_setting(intf);\n-\tif (alt < 0)\n-\t\treturn alt;\n+\tif (!alt)\n+\t\treturn -ENODEV;\n \n-\treturn usb_set_interface(udev,\n-\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n+\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n+\t\t\talt->desc.bAlternateSetting);\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct usb_host_interface *alt;",
                "\tif (!alt)",
                "\t\treturn -ENODEV;",
                "\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,",
                "\t\t\talt->desc.bAlternateSetting);"
            ],
            "deleted": [
                "\tint alt;",
                "\tif (alt < 0)",
                "\t\treturn alt;",
                "\treturn usb_set_interface(udev,",
                "\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The uas driver in the Linux kernel before 4.13.6 allows local users to cause a denial of service (out-of-bounds read and system crash) or possibly have unspecified other impact via a crafted USB device, related to drivers/usb/storage/uas-detect.h and drivers/usb/storage/uas.c.",
        "id": 1318
    },
    {
        "cve_id": "CVE-2023-6121",
        "code_before_change": "static void nvmet_execute_admin_connect(struct nvmet_req *req)\n{\n\tstruct nvmf_connect_command *c = &req->cmd->connect;\n\tstruct nvmf_connect_data *d;\n\tstruct nvmet_ctrl *ctrl = NULL;\n\tu16 status = 0;\n\tint ret;\n\n\tif (!nvmet_check_transfer_len(req, sizeof(struct nvmf_connect_data)))\n\t\treturn;\n\n\td = kmalloc(sizeof(*d), GFP_KERNEL);\n\tif (!d) {\n\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto complete;\n\t}\n\n\tstatus = nvmet_copy_from_sgl(req, 0, d, sizeof(*d));\n\tif (status)\n\t\tgoto out;\n\n\t/* zero out initial completion result, assign values as needed */\n\treq->cqe->result.u32 = 0;\n\n\tif (c->recfmt != 0) {\n\t\tpr_warn(\"invalid connect version (%d).\\n\",\n\t\t\tle16_to_cpu(c->recfmt));\n\t\treq->error_loc = offsetof(struct nvmf_connect_command, recfmt);\n\t\tstatus = NVME_SC_CONNECT_FORMAT | NVME_SC_DNR;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(d->cntlid != cpu_to_le16(0xffff))) {\n\t\tpr_warn(\"connect attempt for invalid controller ID %#x\\n\",\n\t\t\td->cntlid);\n\t\tstatus = NVME_SC_CONNECT_INVALID_PARAM | NVME_SC_DNR;\n\t\treq->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(cntlid);\n\t\tgoto out;\n\t}\n\n\tstatus = nvmet_alloc_ctrl(d->subsysnqn, d->hostnqn, req,\n\t\t\t\t  le32_to_cpu(c->kato), &ctrl);\n\tif (status)\n\t\tgoto out;\n\n\tctrl->pi_support = ctrl->port->pi_enable && ctrl->subsys->pi_support;\n\n\tuuid_copy(&ctrl->hostid, &d->hostid);\n\n\tret = nvmet_setup_auth(ctrl);\n\tif (ret < 0) {\n\t\tpr_err(\"Failed to setup authentication, error %d\\n\", ret);\n\t\tnvmet_ctrl_put(ctrl);\n\t\tif (ret == -EPERM)\n\t\t\tstatus = (NVME_SC_CONNECT_INVALID_HOST | NVME_SC_DNR);\n\t\telse\n\t\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto out;\n\t}\n\n\tstatus = nvmet_install_queue(ctrl, req);\n\tif (status) {\n\t\tnvmet_ctrl_put(ctrl);\n\t\tgoto out;\n\t}\n\n\tpr_info(\"creating %s controller %d for subsystem %s for NQN %s%s%s.\\n\",\n\t\tnvmet_is_disc_subsys(ctrl->subsys) ? \"discovery\" : \"nvm\",\n\t\tctrl->cntlid, ctrl->subsys->subsysnqn, ctrl->hostnqn,\n\t\tctrl->pi_support ? \" T10-PI is enabled\" : \"\",\n\t\tnvmet_has_auth(ctrl) ? \" with DH-HMAC-CHAP\" : \"\");\n\treq->cqe->result.u32 = cpu_to_le32(nvmet_connect_result(ctrl));\nout:\n\tkfree(d);\ncomplete:\n\tnvmet_req_complete(req, status);\n}",
        "code_after_change": "static void nvmet_execute_admin_connect(struct nvmet_req *req)\n{\n\tstruct nvmf_connect_command *c = &req->cmd->connect;\n\tstruct nvmf_connect_data *d;\n\tstruct nvmet_ctrl *ctrl = NULL;\n\tu16 status = 0;\n\tint ret;\n\n\tif (!nvmet_check_transfer_len(req, sizeof(struct nvmf_connect_data)))\n\t\treturn;\n\n\td = kmalloc(sizeof(*d), GFP_KERNEL);\n\tif (!d) {\n\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto complete;\n\t}\n\n\tstatus = nvmet_copy_from_sgl(req, 0, d, sizeof(*d));\n\tif (status)\n\t\tgoto out;\n\n\t/* zero out initial completion result, assign values as needed */\n\treq->cqe->result.u32 = 0;\n\n\tif (c->recfmt != 0) {\n\t\tpr_warn(\"invalid connect version (%d).\\n\",\n\t\t\tle16_to_cpu(c->recfmt));\n\t\treq->error_loc = offsetof(struct nvmf_connect_command, recfmt);\n\t\tstatus = NVME_SC_CONNECT_FORMAT | NVME_SC_DNR;\n\t\tgoto out;\n\t}\n\n\tif (unlikely(d->cntlid != cpu_to_le16(0xffff))) {\n\t\tpr_warn(\"connect attempt for invalid controller ID %#x\\n\",\n\t\t\td->cntlid);\n\t\tstatus = NVME_SC_CONNECT_INVALID_PARAM | NVME_SC_DNR;\n\t\treq->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(cntlid);\n\t\tgoto out;\n\t}\n\n\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n\tstatus = nvmet_alloc_ctrl(d->subsysnqn, d->hostnqn, req,\n\t\t\t\t  le32_to_cpu(c->kato), &ctrl);\n\tif (status)\n\t\tgoto out;\n\n\tctrl->pi_support = ctrl->port->pi_enable && ctrl->subsys->pi_support;\n\n\tuuid_copy(&ctrl->hostid, &d->hostid);\n\n\tret = nvmet_setup_auth(ctrl);\n\tif (ret < 0) {\n\t\tpr_err(\"Failed to setup authentication, error %d\\n\", ret);\n\t\tnvmet_ctrl_put(ctrl);\n\t\tif (ret == -EPERM)\n\t\t\tstatus = (NVME_SC_CONNECT_INVALID_HOST | NVME_SC_DNR);\n\t\telse\n\t\t\tstatus = NVME_SC_INTERNAL;\n\t\tgoto out;\n\t}\n\n\tstatus = nvmet_install_queue(ctrl, req);\n\tif (status) {\n\t\tnvmet_ctrl_put(ctrl);\n\t\tgoto out;\n\t}\n\n\tpr_info(\"creating %s controller %d for subsystem %s for NQN %s%s%s.\\n\",\n\t\tnvmet_is_disc_subsys(ctrl->subsys) ? \"discovery\" : \"nvm\",\n\t\tctrl->cntlid, ctrl->subsys->subsysnqn, ctrl->hostnqn,\n\t\tctrl->pi_support ? \" T10-PI is enabled\" : \"\",\n\t\tnvmet_has_auth(ctrl) ? \" with DH-HMAC-CHAP\" : \"\");\n\treq->cqe->result.u32 = cpu_to_le32(nvmet_connect_result(ctrl));\nout:\n\tkfree(d);\ncomplete:\n\tnvmet_req_complete(req, status);\n}",
        "patch": "--- code before\n+++ code after\n@@ -38,6 +38,8 @@\n \t\tgoto out;\n \t}\n \n+\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n+\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';\n \tstatus = nvmet_alloc_ctrl(d->subsysnqn, d->hostnqn, req,\n \t\t\t\t  le32_to_cpu(c->kato), &ctrl);\n \tif (status)",
        "function_modified_lines": {
            "added": [
                "\td->subsysnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';",
                "\td->hostnqn[NVMF_NQN_FIELD_LEN - 1] = '\\0';"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read vulnerability was found in the NVMe-oF/TCP subsystem in the Linux kernel. This issue may allow a remote attacker to send a crafted TCP packet, triggering a heap-based buffer overflow that results in kmalloc data being printed and potentially leaked to the kernel ring buffer (dmesg).",
        "id": 4298
    },
    {
        "cve_id": "CVE-2022-20132",
        "code_before_change": "static int asus_probe(struct hid_device *hdev, const struct hid_device_id *id)\n{\n\tint ret;\n\tstruct asus_drvdata *drvdata;\n\n\tdrvdata = devm_kzalloc(&hdev->dev, sizeof(*drvdata), GFP_KERNEL);\n\tif (drvdata == NULL) {\n\t\thid_err(hdev, \"Can't alloc Asus descriptor\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\thid_set_drvdata(hdev, drvdata);\n\n\tdrvdata->quirks = id->driver_data;\n\n\t/*\n\t * T90CHI's keyboard dock returns same ID values as T100CHI's dock.\n\t * Thus, identify T90CHI dock with product name string.\n\t */\n\tif (strstr(hdev->name, \"T90CHI\")) {\n\t\tdrvdata->quirks &= ~QUIRK_T100CHI;\n\t\tdrvdata->quirks |= QUIRK_T90CHI;\n\t}\n\n\tif (drvdata->quirks & QUIRK_IS_MULTITOUCH)\n\t\tdrvdata->tp = &asus_i2c_tp;\n\n\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) &&\n\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n\t\tstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\n\n\t\tif (intf->altsetting->desc.bInterfaceNumber == T100_TPAD_INTF) {\n\t\t\tdrvdata->quirks = QUIRK_SKIP_INPUT_MAPPING;\n\t\t\t/*\n\t\t\t * The T100HA uses the same USB-ids as the T100TAF and\n\t\t\t * the T200TA uses the same USB-ids as the T100TA, while\n\t\t\t * both have different max x/y values as the T100TA[F].\n\t\t\t */\n\t\t\tif (dmi_match(DMI_PRODUCT_NAME, \"T100HAN\"))\n\t\t\t\tdrvdata->tp = &asus_t100ha_tp;\n\t\t\telse if (dmi_match(DMI_PRODUCT_NAME, \"T200TA\"))\n\t\t\t\tdrvdata->tp = &asus_t200ta_tp;\n\t\t\telse\n\t\t\t\tdrvdata->tp = &asus_t100ta_tp;\n\t\t}\n\t}\n\n\tif (drvdata->quirks & QUIRK_T100CHI) {\n\t\t/*\n\t\t * All functionality is on a single HID interface and for\n\t\t * userspace the touchpad must be a separate input_dev.\n\t\t */\n\t\thdev->quirks |= HID_QUIRK_MULTI_INPUT;\n\t\tdrvdata->tp = &asus_t100chi_tp;\n\t}\n\n\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) &&\n\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n\t\tstruct usb_host_interface *alt =\n\t\t\tto_usb_interface(hdev->dev.parent)->altsetting;\n\n\t\tif (alt->desc.bInterfaceNumber == MEDION_E1239T_TPAD_INTF) {\n\t\t\t/* For separate input-devs for tp and tp toggle key */\n\t\t\thdev->quirks |= HID_QUIRK_MULTI_INPUT;\n\t\t\tdrvdata->quirks |= QUIRK_SKIP_INPUT_MAPPING;\n\t\t\tdrvdata->tp = &medion_e1239t_tp;\n\t\t}\n\t}\n\n\tif (drvdata->quirks & QUIRK_NO_INIT_REPORTS)\n\t\thdev->quirks |= HID_QUIRK_NO_INIT_REPORTS;\n\n\tdrvdata->hdev = hdev;\n\n\tif (drvdata->quirks & (QUIRK_T100CHI | QUIRK_T90CHI)) {\n\t\tret = asus_battery_probe(hdev);\n\t\tif (ret) {\n\t\t\thid_err(hdev,\n\t\t\t    \"Asus hid battery_probe failed: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = hid_parse(hdev);\n\tif (ret) {\n\t\thid_err(hdev, \"Asus hid parse failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (ret) {\n\t\thid_err(hdev, \"Asus hw start failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (!drvdata->input) {\n\t\thid_err(hdev, \"Asus input not registered\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_stop_hw;\n\t}\n\n\tif (drvdata->tp) {\n\t\tdrvdata->input->name = \"Asus TouchPad\";\n\t} else {\n\t\tdrvdata->input->name = \"Asus Keyboard\";\n\t}\n\n\tif (drvdata->tp) {\n\t\tret = asus_start_multitouch(hdev);\n\t\tif (ret)\n\t\t\tgoto err_stop_hw;\n\t}\n\n\treturn 0;\nerr_stop_hw:\n\thid_hw_stop(hdev);\n\treturn ret;\n}",
        "code_after_change": "static int asus_probe(struct hid_device *hdev, const struct hid_device_id *id)\n{\n\tint ret;\n\tstruct asus_drvdata *drvdata;\n\n\tdrvdata = devm_kzalloc(&hdev->dev, sizeof(*drvdata), GFP_KERNEL);\n\tif (drvdata == NULL) {\n\t\thid_err(hdev, \"Can't alloc Asus descriptor\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\thid_set_drvdata(hdev, drvdata);\n\n\tdrvdata->quirks = id->driver_data;\n\n\t/*\n\t * T90CHI's keyboard dock returns same ID values as T100CHI's dock.\n\t * Thus, identify T90CHI dock with product name string.\n\t */\n\tif (strstr(hdev->name, \"T90CHI\")) {\n\t\tdrvdata->quirks &= ~QUIRK_T100CHI;\n\t\tdrvdata->quirks |= QUIRK_T90CHI;\n\t}\n\n\tif (drvdata->quirks & QUIRK_IS_MULTITOUCH)\n\t\tdrvdata->tp = &asus_i2c_tp;\n\n\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) && hid_is_usb(hdev)) {\n\t\tstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\n\n\t\tif (intf->altsetting->desc.bInterfaceNumber == T100_TPAD_INTF) {\n\t\t\tdrvdata->quirks = QUIRK_SKIP_INPUT_MAPPING;\n\t\t\t/*\n\t\t\t * The T100HA uses the same USB-ids as the T100TAF and\n\t\t\t * the T200TA uses the same USB-ids as the T100TA, while\n\t\t\t * both have different max x/y values as the T100TA[F].\n\t\t\t */\n\t\t\tif (dmi_match(DMI_PRODUCT_NAME, \"T100HAN\"))\n\t\t\t\tdrvdata->tp = &asus_t100ha_tp;\n\t\t\telse if (dmi_match(DMI_PRODUCT_NAME, \"T200TA\"))\n\t\t\t\tdrvdata->tp = &asus_t200ta_tp;\n\t\t\telse\n\t\t\t\tdrvdata->tp = &asus_t100ta_tp;\n\t\t}\n\t}\n\n\tif (drvdata->quirks & QUIRK_T100CHI) {\n\t\t/*\n\t\t * All functionality is on a single HID interface and for\n\t\t * userspace the touchpad must be a separate input_dev.\n\t\t */\n\t\thdev->quirks |= HID_QUIRK_MULTI_INPUT;\n\t\tdrvdata->tp = &asus_t100chi_tp;\n\t}\n\n\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) && hid_is_usb(hdev)) {\n\t\tstruct usb_host_interface *alt =\n\t\t\tto_usb_interface(hdev->dev.parent)->altsetting;\n\n\t\tif (alt->desc.bInterfaceNumber == MEDION_E1239T_TPAD_INTF) {\n\t\t\t/* For separate input-devs for tp and tp toggle key */\n\t\t\thdev->quirks |= HID_QUIRK_MULTI_INPUT;\n\t\t\tdrvdata->quirks |= QUIRK_SKIP_INPUT_MAPPING;\n\t\t\tdrvdata->tp = &medion_e1239t_tp;\n\t\t}\n\t}\n\n\tif (drvdata->quirks & QUIRK_NO_INIT_REPORTS)\n\t\thdev->quirks |= HID_QUIRK_NO_INIT_REPORTS;\n\n\tdrvdata->hdev = hdev;\n\n\tif (drvdata->quirks & (QUIRK_T100CHI | QUIRK_T90CHI)) {\n\t\tret = asus_battery_probe(hdev);\n\t\tif (ret) {\n\t\t\thid_err(hdev,\n\t\t\t    \"Asus hid battery_probe failed: %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = hid_parse(hdev);\n\tif (ret) {\n\t\thid_err(hdev, \"Asus hid parse failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = hid_hw_start(hdev, HID_CONNECT_DEFAULT);\n\tif (ret) {\n\t\thid_err(hdev, \"Asus hw start failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (!drvdata->input) {\n\t\thid_err(hdev, \"Asus input not registered\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_stop_hw;\n\t}\n\n\tif (drvdata->tp) {\n\t\tdrvdata->input->name = \"Asus TouchPad\";\n\t} else {\n\t\tdrvdata->input->name = \"Asus Keyboard\";\n\t}\n\n\tif (drvdata->tp) {\n\t\tret = asus_start_multitouch(hdev);\n\t\tif (ret)\n\t\t\tgoto err_stop_hw;\n\t}\n\n\treturn 0;\nerr_stop_hw:\n\thid_hw_stop(hdev);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -25,8 +25,7 @@\n \tif (drvdata->quirks & QUIRK_IS_MULTITOUCH)\n \t\tdrvdata->tp = &asus_i2c_tp;\n \n-\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) &&\n-\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n+\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) && hid_is_usb(hdev)) {\n \t\tstruct usb_interface *intf = to_usb_interface(hdev->dev.parent);\n \n \t\tif (intf->altsetting->desc.bInterfaceNumber == T100_TPAD_INTF) {\n@@ -54,8 +53,7 @@\n \t\tdrvdata->tp = &asus_t100chi_tp;\n \t}\n \n-\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) &&\n-\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {\n+\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) && hid_is_usb(hdev)) {\n \t\tstruct usb_host_interface *alt =\n \t\t\tto_usb_interface(hdev->dev.parent)->altsetting;\n ",
        "function_modified_lines": {
            "added": [
                "\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) && hid_is_usb(hdev)) {",
                "\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) && hid_is_usb(hdev)) {"
            ],
            "deleted": [
                "\tif ((drvdata->quirks & QUIRK_T100_KEYBOARD) &&",
                "\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {",
                "\tif ((drvdata->quirks & QUIRK_MEDION_E1239T) &&",
                "\t    hid_is_using_ll_driver(hdev, &usb_hid_driver)) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In lg_probe and related functions of hid-lg.c and other USB HID files, there is a possible out of bounds read due to improper input validation. This could lead to local information disclosure if a malicious USB HID device were plugged in, with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-188677105References: Upstream kernel",
        "id": 3332
    },
    {
        "cve_id": "CVE-2021-3490",
        "code_before_change": "static void scalar32_min_max_xor(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\n\t/* Assuming scalar64_min_max_xor will be called so it is safe\n\t * to skip updating register for known case.\n\t */\n\tif (src_known && dst_known)\n\t\treturn;\n\n\t/* We get both minimum and maximum from the var32_off. */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\n\tif (dst_reg->s32_min_value >= 0 && smin_val >= 0) {\n\t\t/* XORing two positive sign numbers gives a positive,\n\t\t * so safe to cast u32 result into s32.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t} else {\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t}\n}",
        "code_after_change": "static void scalar32_min_max_xor(struct bpf_reg_state *dst_reg,\n\t\t\t\t struct bpf_reg_state *src_reg)\n{\n\tbool src_known = tnum_subreg_is_const(src_reg->var_off);\n\tbool dst_known = tnum_subreg_is_const(dst_reg->var_off);\n\tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n\ts32 smin_val = src_reg->s32_min_value;\n\n\tif (src_known && dst_known) {\n\t\t__mark_reg32_known(dst_reg, var32_off.value);\n\t\treturn;\n\t}\n\n\t/* We get both minimum and maximum from the var32_off. */\n\tdst_reg->u32_min_value = var32_off.value;\n\tdst_reg->u32_max_value = var32_off.value | var32_off.mask;\n\n\tif (dst_reg->s32_min_value >= 0 && smin_val >= 0) {\n\t\t/* XORing two positive sign numbers gives a positive,\n\t\t * so safe to cast u32 result into s32.\n\t\t */\n\t\tdst_reg->s32_min_value = dst_reg->u32_min_value;\n\t\tdst_reg->s32_max_value = dst_reg->u32_max_value;\n\t} else {\n\t\tdst_reg->s32_min_value = S32_MIN;\n\t\tdst_reg->s32_max_value = S32_MAX;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,11 +6,10 @@\n \tstruct tnum var32_off = tnum_subreg(dst_reg->var_off);\n \ts32 smin_val = src_reg->s32_min_value;\n \n-\t/* Assuming scalar64_min_max_xor will be called so it is safe\n-\t * to skip updating register for known case.\n-\t */\n-\tif (src_known && dst_known)\n+\tif (src_known && dst_known) {\n+\t\t__mark_reg32_known(dst_reg, var32_off.value);\n \t\treturn;\n+\t}\n \n \t/* We get both minimum and maximum from the var32_off. */\n \tdst_reg->u32_min_value = var32_off.value;",
        "function_modified_lines": {
            "added": [
                "\tif (src_known && dst_known) {",
                "\t\t__mark_reg32_known(dst_reg, var32_off.value);",
                "\t}"
            ],
            "deleted": [
                "\t/* Assuming scalar64_min_max_xor will be called so it is safe",
                "\t * to skip updating register for known case.",
                "\t */",
                "\tif (src_known && dst_known)"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "The eBPF ALU32 bounds tracking for bitwise ops (AND, OR and XOR) in the Linux kernel did not properly update 32-bit bounds, which could be turned into out of bounds reads and writes in the Linux kernel and therefore, arbitrary code execution. This issue was fixed via commit 049c4e13714e (\"bpf: Fix alu32 const subreg bound tracking on bitwise operations\") (v5.13-rc4) and backported to the stable kernels in v5.12.4, v5.11.21, and v5.10.37. The AND/OR issues were introduced by commit 3f50f132d840 (\"bpf: Verifier, do explicit ALU32 bounds tracking\") (5.7-rc1) and the XOR variant was introduced by 2921c90d4718 (\"bpf:Fix a verifier failure with xor\") ( 5.10-rc1).",
        "id": 3010
    },
    {
        "cve_id": "CVE-2020-35519",
        "code_before_change": "static int x25_connect(struct socket *sock, struct sockaddr *uaddr,\n\t\t       int addr_len, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct x25_sock *x25 = x25_sk(sk);\n\tstruct sockaddr_x25 *addr = (struct sockaddr_x25 *)uaddr;\n\tstruct x25_route *rt;\n\tint rc = 0;\n\n\tlock_sock(sk);\n\tif (sk->sk_state == TCP_ESTABLISHED && sock->state == SS_CONNECTING) {\n\t\tsock->state = SS_CONNECTED;\n\t\tgoto out; /* Connect completed during a ERESTARTSYS event */\n\t}\n\n\trc = -ECONNREFUSED;\n\tif (sk->sk_state == TCP_CLOSE && sock->state == SS_CONNECTING) {\n\t\tsock->state = SS_UNCONNECTED;\n\t\tgoto out;\n\t}\n\n\trc = -EISCONN;\t/* No reconnect on a seqpacket socket */\n\tif (sk->sk_state == TCP_ESTABLISHED)\n\t\tgoto out;\n\n\trc = -EALREADY;\t/* Do nothing if call is already in progress */\n\tif (sk->sk_state == TCP_SYN_SENT)\n\t\tgoto out;\n\n\tsk->sk_state   = TCP_CLOSE;\n\tsock->state = SS_UNCONNECTED;\n\n\trc = -EINVAL;\n\tif (addr_len != sizeof(struct sockaddr_x25) ||\n\t    addr->sx25_family != AF_X25)\n\t\tgoto out;\n\n\trc = -ENETUNREACH;\n\trt = x25_get_route(&addr->sx25_addr);\n\tif (!rt)\n\t\tgoto out;\n\n\tx25->neighbour = x25_get_neigh(rt->dev);\n\tif (!x25->neighbour)\n\t\tgoto out_put_route;\n\n\tx25_limit_facilities(&x25->facilities, x25->neighbour);\n\n\tx25->lci = x25_new_lci(x25->neighbour);\n\tif (!x25->lci)\n\t\tgoto out_put_neigh;\n\n\trc = -EINVAL;\n\tif (sock_flag(sk, SOCK_ZAPPED)) /* Must bind first - autobinding does not work */\n\t\tgoto out_put_neigh;\n\n\tif (!strcmp(x25->source_addr.x25_addr, null_x25_address.x25_addr))\n\t\tmemset(&x25->source_addr, '\\0', X25_ADDR_LEN);\n\n\tx25->dest_addr = addr->sx25_addr;\n\n\t/* Move to connecting socket, start sending Connect Requests */\n\tsock->state   = SS_CONNECTING;\n\tsk->sk_state  = TCP_SYN_SENT;\n\n\tx25->state = X25_STATE_1;\n\n\tx25_write_internal(sk, X25_CALL_REQUEST);\n\n\tx25_start_heartbeat(sk);\n\tx25_start_t21timer(sk);\n\n\t/* Now the loop */\n\trc = -EINPROGRESS;\n\tif (sk->sk_state != TCP_ESTABLISHED && (flags & O_NONBLOCK))\n\t\tgoto out;\n\n\trc = x25_wait_for_connection_establishment(sk);\n\tif (rc)\n\t\tgoto out_put_neigh;\n\n\tsock->state = SS_CONNECTED;\n\trc = 0;\nout_put_neigh:\n\tif (rc && x25->neighbour) {\n\t\tread_lock_bh(&x25_list_lock);\n\t\tx25_neigh_put(x25->neighbour);\n\t\tx25->neighbour = NULL;\n\t\tread_unlock_bh(&x25_list_lock);\n\t\tx25->state = X25_STATE_0;\n\t}\nout_put_route:\n\tx25_route_put(rt);\nout:\n\trelease_sock(sk);\n\treturn rc;\n}",
        "code_after_change": "static int x25_connect(struct socket *sock, struct sockaddr *uaddr,\n\t\t       int addr_len, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct x25_sock *x25 = x25_sk(sk);\n\tstruct sockaddr_x25 *addr = (struct sockaddr_x25 *)uaddr;\n\tstruct x25_route *rt;\n\tint rc = 0;\n\n\tlock_sock(sk);\n\tif (sk->sk_state == TCP_ESTABLISHED && sock->state == SS_CONNECTING) {\n\t\tsock->state = SS_CONNECTED;\n\t\tgoto out; /* Connect completed during a ERESTARTSYS event */\n\t}\n\n\trc = -ECONNREFUSED;\n\tif (sk->sk_state == TCP_CLOSE && sock->state == SS_CONNECTING) {\n\t\tsock->state = SS_UNCONNECTED;\n\t\tgoto out;\n\t}\n\n\trc = -EISCONN;\t/* No reconnect on a seqpacket socket */\n\tif (sk->sk_state == TCP_ESTABLISHED)\n\t\tgoto out;\n\n\trc = -EALREADY;\t/* Do nothing if call is already in progress */\n\tif (sk->sk_state == TCP_SYN_SENT)\n\t\tgoto out;\n\n\tsk->sk_state   = TCP_CLOSE;\n\tsock->state = SS_UNCONNECTED;\n\n\trc = -EINVAL;\n\tif (addr_len != sizeof(struct sockaddr_x25) ||\n\t    addr->sx25_family != AF_X25 ||\n\t    strnlen(addr->sx25_addr.x25_addr, X25_ADDR_LEN) == X25_ADDR_LEN)\n\t\tgoto out;\n\n\trc = -ENETUNREACH;\n\trt = x25_get_route(&addr->sx25_addr);\n\tif (!rt)\n\t\tgoto out;\n\n\tx25->neighbour = x25_get_neigh(rt->dev);\n\tif (!x25->neighbour)\n\t\tgoto out_put_route;\n\n\tx25_limit_facilities(&x25->facilities, x25->neighbour);\n\n\tx25->lci = x25_new_lci(x25->neighbour);\n\tif (!x25->lci)\n\t\tgoto out_put_neigh;\n\n\trc = -EINVAL;\n\tif (sock_flag(sk, SOCK_ZAPPED)) /* Must bind first - autobinding does not work */\n\t\tgoto out_put_neigh;\n\n\tif (!strcmp(x25->source_addr.x25_addr, null_x25_address.x25_addr))\n\t\tmemset(&x25->source_addr, '\\0', X25_ADDR_LEN);\n\n\tx25->dest_addr = addr->sx25_addr;\n\n\t/* Move to connecting socket, start sending Connect Requests */\n\tsock->state   = SS_CONNECTING;\n\tsk->sk_state  = TCP_SYN_SENT;\n\n\tx25->state = X25_STATE_1;\n\n\tx25_write_internal(sk, X25_CALL_REQUEST);\n\n\tx25_start_heartbeat(sk);\n\tx25_start_t21timer(sk);\n\n\t/* Now the loop */\n\trc = -EINPROGRESS;\n\tif (sk->sk_state != TCP_ESTABLISHED && (flags & O_NONBLOCK))\n\t\tgoto out;\n\n\trc = x25_wait_for_connection_establishment(sk);\n\tif (rc)\n\t\tgoto out_put_neigh;\n\n\tsock->state = SS_CONNECTED;\n\trc = 0;\nout_put_neigh:\n\tif (rc && x25->neighbour) {\n\t\tread_lock_bh(&x25_list_lock);\n\t\tx25_neigh_put(x25->neighbour);\n\t\tx25->neighbour = NULL;\n\t\tread_unlock_bh(&x25_list_lock);\n\t\tx25->state = X25_STATE_0;\n\t}\nout_put_route:\n\tx25_route_put(rt);\nout:\n\trelease_sock(sk);\n\treturn rc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -32,7 +32,8 @@\n \n \trc = -EINVAL;\n \tif (addr_len != sizeof(struct sockaddr_x25) ||\n-\t    addr->sx25_family != AF_X25)\n+\t    addr->sx25_family != AF_X25 ||\n+\t    strnlen(addr->sx25_addr.x25_addr, X25_ADDR_LEN) == X25_ADDR_LEN)\n \t\tgoto out;\n \n \trc = -ENETUNREACH;",
        "function_modified_lines": {
            "added": [
                "\t    addr->sx25_family != AF_X25 ||",
                "\t    strnlen(addr->sx25_addr.x25_addr, X25_ADDR_LEN) == X25_ADDR_LEN)"
            ],
            "deleted": [
                "\t    addr->sx25_family != AF_X25)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds (OOB) memory access flaw was found in x25_bind in net/x25/af_x25.c in the Linux kernel version v5.12-rc5. A bounds check failure allows a local attacker with a user account on the system to gain access to out-of-bounds memory, leading to a system crash or a leak of internal kernel information. The highest threat from this vulnerability is to confidentiality, integrity, as well as system availability.",
        "id": 2712
    },
    {
        "cve_id": "CVE-2022-1508",
        "code_before_change": "static int io_read(struct io_kiocb *req, unsigned int issue_flags)\n{\n\tstruct iovec inline_vecs[UIO_FASTIOV], *iovec = inline_vecs;\n\tstruct kiocb *kiocb = &req->rw.kiocb;\n\tstruct iov_iter __iter, *iter = &__iter;\n\tstruct io_async_rw *rw = req->async_data;\n\tssize_t io_size, ret, ret2;\n\tbool force_nonblock = issue_flags & IO_URING_F_NONBLOCK;\n\n\tif (rw) {\n\t\titer = &rw->iter;\n\t\tiovec = NULL;\n\t} else {\n\t\tret = io_import_iovec(READ, req, &iovec, iter, !force_nonblock);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tio_size = iov_iter_count(iter);\n\treq->result = io_size;\n\n\t/* Ensure we clear previously set non-block flag */\n\tif (!force_nonblock)\n\t\tkiocb->ki_flags &= ~IOCB_NOWAIT;\n\telse\n\t\tkiocb->ki_flags |= IOCB_NOWAIT;\n\n\t/* If the file doesn't support async, just async punt */\n\tif (force_nonblock && !io_file_supports_async(req, READ)) {\n\t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\t\treturn ret ?: -EAGAIN;\n\t}\n\n\tret = rw_verify_area(READ, req->file, io_kiocb_ppos(kiocb), io_size);\n\tif (unlikely(ret)) {\n\t\tkfree(iovec);\n\t\treturn ret;\n\t}\n\n\tret = io_iter_do_read(req, iter);\n\n\tif (ret == -EAGAIN || (req->flags & REQ_F_REISSUE)) {\n\t\treq->flags &= ~REQ_F_REISSUE;\n\t\t/* IOPOLL retry should happen for io-wq threads */\n\t\tif (!force_nonblock && !(req->ctx->flags & IORING_SETUP_IOPOLL))\n\t\t\tgoto done;\n\t\t/* no retry on NONBLOCK nor RWF_NOWAIT */\n\t\tif (req->flags & REQ_F_NOWAIT)\n\t\t\tgoto done;\n\t\t/* some cases will consume bytes even on error returns */\n\t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n\t\tret = 0;\n\t} else if (ret == -EIOCBQUEUED) {\n\t\tgoto out_free;\n\t} else if (ret <= 0 || ret == io_size || !force_nonblock ||\n\t\t   (req->flags & REQ_F_NOWAIT) || !(req->flags & REQ_F_ISREG)) {\n\t\t/* read all, failed, already did sync or don't want to retry */\n\t\tgoto done;\n\t}\n\n\tret2 = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\tif (ret2)\n\t\treturn ret2;\n\n\tiovec = NULL;\n\trw = req->async_data;\n\t/* now use our persistent iterator, if we aren't already */\n\titer = &rw->iter;\n\n\tdo {\n\t\tio_size -= ret;\n\t\trw->bytes_done += ret;\n\t\t/* if we can retry, do so with the callbacks armed */\n\t\tif (!io_rw_should_retry(req)) {\n\t\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t\t\treturn -EAGAIN;\n\t\t}\n\n\t\t/*\n\t\t * Now retry read with the IOCB_WAITQ parts set in the iocb. If\n\t\t * we get -EIOCBQUEUED, then we'll get a notification when the\n\t\t * desired page gets unlocked. We can also get a partial read\n\t\t * here, and if we do, then just retry at the new offset.\n\t\t */\n\t\tret = io_iter_do_read(req, iter);\n\t\tif (ret == -EIOCBQUEUED)\n\t\t\treturn 0;\n\t\t/* we got some bytes, but not all. retry. */\n\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t} while (ret > 0 && ret < io_size);\ndone:\n\tkiocb_done(kiocb, ret, issue_flags);\nout_free:\n\t/* it's faster to check here then delegate to kfree */\n\tif (iovec)\n\t\tkfree(iovec);\n\treturn 0;\n}",
        "code_after_change": "static int io_read(struct io_kiocb *req, unsigned int issue_flags)\n{\n\tstruct iovec inline_vecs[UIO_FASTIOV], *iovec = inline_vecs;\n\tstruct kiocb *kiocb = &req->rw.kiocb;\n\tstruct iov_iter __iter, *iter = &__iter;\n\tstruct io_async_rw *rw = req->async_data;\n\tssize_t io_size, ret, ret2;\n\tbool force_nonblock = issue_flags & IO_URING_F_NONBLOCK;\n\n\tif (rw) {\n\t\titer = &rw->iter;\n\t\tiovec = NULL;\n\t} else {\n\t\tret = io_import_iovec(READ, req, &iovec, iter, !force_nonblock);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tio_size = iov_iter_count(iter);\n\treq->result = io_size;\n\n\t/* Ensure we clear previously set non-block flag */\n\tif (!force_nonblock)\n\t\tkiocb->ki_flags &= ~IOCB_NOWAIT;\n\telse\n\t\tkiocb->ki_flags |= IOCB_NOWAIT;\n\n\t/* If the file doesn't support async, just async punt */\n\tif (force_nonblock && !io_file_supports_async(req, READ)) {\n\t\tret = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\t\treturn ret ?: -EAGAIN;\n\t}\n\n\tret = rw_verify_area(READ, req->file, io_kiocb_ppos(kiocb), io_size);\n\tif (unlikely(ret)) {\n\t\tkfree(iovec);\n\t\treturn ret;\n\t}\n\n\tret = io_iter_do_read(req, iter);\n\n\tif (ret == -EAGAIN || (req->flags & REQ_F_REISSUE)) {\n\t\treq->flags &= ~REQ_F_REISSUE;\n\t\t/* IOPOLL retry should happen for io-wq threads */\n\t\tif (!force_nonblock && !(req->ctx->flags & IORING_SETUP_IOPOLL))\n\t\t\tgoto done;\n\t\t/* no retry on NONBLOCK nor RWF_NOWAIT */\n\t\tif (req->flags & REQ_F_NOWAIT)\n\t\t\tgoto done;\n\t\t/* some cases will consume bytes even on error returns */\n\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);\n\t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n\t\tret = 0;\n\t} else if (ret == -EIOCBQUEUED) {\n\t\tgoto out_free;\n\t} else if (ret <= 0 || ret == io_size || !force_nonblock ||\n\t\t   (req->flags & REQ_F_NOWAIT) || !(req->flags & REQ_F_ISREG)) {\n\t\t/* read all, failed, already did sync or don't want to retry */\n\t\tgoto done;\n\t}\n\n\tret2 = io_setup_async_rw(req, iovec, inline_vecs, iter, true);\n\tif (ret2)\n\t\treturn ret2;\n\n\tiovec = NULL;\n\trw = req->async_data;\n\t/* now use our persistent iterator, if we aren't already */\n\titer = &rw->iter;\n\n\tdo {\n\t\tio_size -= ret;\n\t\trw->bytes_done += ret;\n\t\t/* if we can retry, do so with the callbacks armed */\n\t\tif (!io_rw_should_retry(req)) {\n\t\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t\t\treturn -EAGAIN;\n\t\t}\n\n\t\t/*\n\t\t * Now retry read with the IOCB_WAITQ parts set in the iocb. If\n\t\t * we get -EIOCBQUEUED, then we'll get a notification when the\n\t\t * desired page gets unlocked. We can also get a partial read\n\t\t * here, and if we do, then just retry at the new offset.\n\t\t */\n\t\tret = io_iter_do_read(req, iter);\n\t\tif (ret == -EIOCBQUEUED)\n\t\t\treturn 0;\n\t\t/* we got some bytes, but not all. retry. */\n\t\tkiocb->ki_flags &= ~IOCB_WAITQ;\n\t} while (ret > 0 && ret < io_size);\ndone:\n\tkiocb_done(kiocb, ret, issue_flags);\nout_free:\n\t/* it's faster to check here then delegate to kfree */\n\tif (iovec)\n\t\tkfree(iovec);\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -47,6 +47,7 @@\n \t\tif (req->flags & REQ_F_NOWAIT)\n \t\t\tgoto done;\n \t\t/* some cases will consume bytes even on error returns */\n+\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);\n \t\tiov_iter_revert(iter, io_size - iov_iter_count(iter));\n \t\tret = 0;\n \t} else if (ret == -EIOCBQUEUED) {",
        "function_modified_lines": {
            "added": [
                "\t\tiov_iter_reexpand(iter, iter->count + iter->truncated);"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read flaw was found in the Linux kernel\u2019s io_uring module in the way a user triggers the io_read() function with some special parameters. This flaw allows a local user to read some memory out of bounds.",
        "id": 3263
    },
    {
        "cve_id": "CVE-2019-15926",
        "code_before_change": "static int ath6kl_wmi_pstream_timeout_event_rx(struct wmi *wmi, u8 *datap,\n\t\t\t\t\t       int len)\n{\n\tstruct wmi_pstream_timeout_event *ev;\n\n\tif (len < sizeof(struct wmi_pstream_timeout_event))\n\t\treturn -EINVAL;\n\n\tev = (struct wmi_pstream_timeout_event *) datap;\n\n\t/*\n\t * When the pstream (fat pipe == AC) timesout, it means there were\n\t * no thinStreams within this pstream & it got implicitly created\n\t * due to data flow on this AC. We start the inactivity timer only\n\t * for implicitly created pstream. Just reset the host state.\n\t */\n\tspin_lock_bh(&wmi->lock);\n\twmi->stream_exist_for_ac[ev->traffic_class] = 0;\n\twmi->fat_pipe_exist &= ~(1 << ev->traffic_class);\n\tspin_unlock_bh(&wmi->lock);\n\n\t/* Indicate inactivity to driver layer for this fatpipe (pstream) */\n\tath6kl_indicate_tx_activity(wmi->parent_dev, ev->traffic_class, false);\n\n\treturn 0;\n}",
        "code_after_change": "static int ath6kl_wmi_pstream_timeout_event_rx(struct wmi *wmi, u8 *datap,\n\t\t\t\t\t       int len)\n{\n\tstruct wmi_pstream_timeout_event *ev;\n\n\tif (len < sizeof(struct wmi_pstream_timeout_event))\n\t\treturn -EINVAL;\n\n\tev = (struct wmi_pstream_timeout_event *) datap;\n\tif (ev->traffic_class >= WMM_NUM_AC) {\n\t\tath6kl_err(\"invalid traffic class: %d\\n\", ev->traffic_class);\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * When the pstream (fat pipe == AC) timesout, it means there were\n\t * no thinStreams within this pstream & it got implicitly created\n\t * due to data flow on this AC. We start the inactivity timer only\n\t * for implicitly created pstream. Just reset the host state.\n\t */\n\tspin_lock_bh(&wmi->lock);\n\twmi->stream_exist_for_ac[ev->traffic_class] = 0;\n\twmi->fat_pipe_exist &= ~(1 << ev->traffic_class);\n\tspin_unlock_bh(&wmi->lock);\n\n\t/* Indicate inactivity to driver layer for this fatpipe (pstream) */\n\tath6kl_indicate_tx_activity(wmi->parent_dev, ev->traffic_class, false);\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,6 +7,10 @@\n \t\treturn -EINVAL;\n \n \tev = (struct wmi_pstream_timeout_event *) datap;\n+\tif (ev->traffic_class >= WMM_NUM_AC) {\n+\t\tath6kl_err(\"invalid traffic class: %d\\n\", ev->traffic_class);\n+\t\treturn -EINVAL;\n+\t}\n \n \t/*\n \t * When the pstream (fat pipe == AC) timesout, it means there were",
        "function_modified_lines": {
            "added": [
                "\tif (ev->traffic_class >= WMM_NUM_AC) {",
                "\t\tath6kl_err(\"invalid traffic class: %d\\n\", ev->traffic_class);",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.3. Out of bounds access exists in the functions ath6kl_wmi_pstream_timeout_event_rx and ath6kl_wmi_cac_event_rx in the file drivers/net/wireless/ath/ath6kl/wmi.c.",
        "id": 2039
    },
    {
        "cve_id": "CVE-2017-18344",
        "code_before_change": "static struct pid *good_sigevent(sigevent_t * event)\n{\n\tstruct task_struct *rtn = current->group_leader;\n\n\tif ((event->sigev_notify & SIGEV_THREAD_ID ) &&\n\t\t(!(rtn = find_task_by_vpid(event->sigev_notify_thread_id)) ||\n\t\t !same_thread_group(rtn, current) ||\n\t\t (event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_SIGNAL))\n\t\treturn NULL;\n\n\tif (((event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE) &&\n\t    ((event->sigev_signo <= 0) || (event->sigev_signo > SIGRTMAX)))\n\t\treturn NULL;\n\n\treturn task_pid(rtn);\n}",
        "code_after_change": "static struct pid *good_sigevent(sigevent_t * event)\n{\n\tstruct task_struct *rtn = current->group_leader;\n\n\tswitch (event->sigev_notify) {\n\tcase SIGEV_SIGNAL | SIGEV_THREAD_ID:\n\t\trtn = find_task_by_vpid(event->sigev_notify_thread_id);\n\t\tif (!rtn || !same_thread_group(rtn, current))\n\t\t\treturn NULL;\n\t\t/* FALLTHRU */\n\tcase SIGEV_SIGNAL:\n\tcase SIGEV_THREAD:\n\t\tif (event->sigev_signo <= 0 || event->sigev_signo > SIGRTMAX)\n\t\t\treturn NULL;\n\t\t/* FALLTHRU */\n\tcase SIGEV_NONE:\n\t\treturn task_pid(rtn);\n\tdefault:\n\t\treturn NULL;\n\t}\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,15 +2,20 @@\n {\n \tstruct task_struct *rtn = current->group_leader;\n \n-\tif ((event->sigev_notify & SIGEV_THREAD_ID ) &&\n-\t\t(!(rtn = find_task_by_vpid(event->sigev_notify_thread_id)) ||\n-\t\t !same_thread_group(rtn, current) ||\n-\t\t (event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_SIGNAL))\n+\tswitch (event->sigev_notify) {\n+\tcase SIGEV_SIGNAL | SIGEV_THREAD_ID:\n+\t\trtn = find_task_by_vpid(event->sigev_notify_thread_id);\n+\t\tif (!rtn || !same_thread_group(rtn, current))\n+\t\t\treturn NULL;\n+\t\t/* FALLTHRU */\n+\tcase SIGEV_SIGNAL:\n+\tcase SIGEV_THREAD:\n+\t\tif (event->sigev_signo <= 0 || event->sigev_signo > SIGRTMAX)\n+\t\t\treturn NULL;\n+\t\t/* FALLTHRU */\n+\tcase SIGEV_NONE:\n+\t\treturn task_pid(rtn);\n+\tdefault:\n \t\treturn NULL;\n-\n-\tif (((event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE) &&\n-\t    ((event->sigev_signo <= 0) || (event->sigev_signo > SIGRTMAX)))\n-\t\treturn NULL;\n-\n-\treturn task_pid(rtn);\n+\t}\n }",
        "function_modified_lines": {
            "added": [
                "\tswitch (event->sigev_notify) {",
                "\tcase SIGEV_SIGNAL | SIGEV_THREAD_ID:",
                "\t\trtn = find_task_by_vpid(event->sigev_notify_thread_id);",
                "\t\tif (!rtn || !same_thread_group(rtn, current))",
                "\t\t\treturn NULL;",
                "\t\t/* FALLTHRU */",
                "\tcase SIGEV_SIGNAL:",
                "\tcase SIGEV_THREAD:",
                "\t\tif (event->sigev_signo <= 0 || event->sigev_signo > SIGRTMAX)",
                "\t\t\treturn NULL;",
                "\t\t/* FALLTHRU */",
                "\tcase SIGEV_NONE:",
                "\t\treturn task_pid(rtn);",
                "\tdefault:",
                "\t}"
            ],
            "deleted": [
                "\tif ((event->sigev_notify & SIGEV_THREAD_ID ) &&",
                "\t\t(!(rtn = find_task_by_vpid(event->sigev_notify_thread_id)) ||",
                "\t\t !same_thread_group(rtn, current) ||",
                "\t\t (event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_SIGNAL))",
                "",
                "\tif (((event->sigev_notify & ~SIGEV_THREAD_ID) != SIGEV_NONE) &&",
                "\t    ((event->sigev_signo <= 0) || (event->sigev_signo > SIGRTMAX)))",
                "\t\treturn NULL;",
                "",
                "\treturn task_pid(rtn);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The timer_create syscall implementation in kernel/time/posix-timers.c in the Linux kernel before 4.14.8 doesn't properly validate the sigevent->sigev_notify field, which leads to out-of-bounds access in the show_timer function (called when /proc/$PID/timers is read). This allows userspace applications to read arbitrary kernel memory (on a kernel built with CONFIG_POSIX_TIMERS and CONFIG_CHECKPOINT_RESTORE).",
        "id": 1430
    },
    {
        "cve_id": "CVE-2018-13099",
        "code_before_change": "static int f2fs_move_inline_dirents(struct inode *dir, struct page *ipage,\n\t\t\t\t\t\t\tvoid *inline_dentry)\n{\n\tstruct page *page;\n\tstruct dnode_of_data dn;\n\tstruct f2fs_dentry_block *dentry_blk;\n\tstruct f2fs_dentry_ptr src, dst;\n\tint err;\n\n\tpage = f2fs_grab_cache_page(dir->i_mapping, 0, false);\n\tif (!page) {\n\t\tf2fs_put_page(ipage, 1);\n\t\treturn -ENOMEM;\n\t}\n\n\tset_new_dnode(&dn, dir, ipage, NULL, 0);\n\terr = f2fs_reserve_block(&dn, 0);\n\tif (err)\n\t\tgoto out;\n\n\tf2fs_wait_on_page_writeback(page, DATA, true);\n\n\tdentry_blk = page_address(page);\n\n\tmake_dentry_ptr_inline(dir, &src, inline_dentry);\n\tmake_dentry_ptr_block(dir, &dst, dentry_blk);\n\n\t/* copy data from inline dentry block to new dentry block */\n\tmemcpy(dst.bitmap, src.bitmap, src.nr_bitmap);\n\tmemset(dst.bitmap + src.nr_bitmap, 0, dst.nr_bitmap - src.nr_bitmap);\n\t/*\n\t * we do not need to zero out remainder part of dentry and filename\n\t * field, since we have used bitmap for marking the usage status of\n\t * them, besides, we can also ignore copying/zeroing reserved space\n\t * of dentry block, because them haven't been used so far.\n\t */\n\tmemcpy(dst.dentry, src.dentry, SIZE_OF_DIR_ENTRY * src.max);\n\tmemcpy(dst.filename, src.filename, src.max * F2FS_SLOT_LEN);\n\n\tif (!PageUptodate(page))\n\t\tSetPageUptodate(page);\n\tset_page_dirty(page);\n\n\t/* clear inline dir and flag after data writeback */\n\tf2fs_truncate_inline_inode(dir, ipage, 0);\n\n\tstat_dec_inline_dir(dir);\n\tclear_inode_flag(dir, FI_INLINE_DENTRY);\n\n\tf2fs_i_depth_write(dir, 1);\n\tif (i_size_read(dir) < PAGE_SIZE)\n\t\tf2fs_i_size_write(dir, PAGE_SIZE);\nout:\n\tf2fs_put_page(page, 1);\n\treturn err;\n}",
        "code_after_change": "static int f2fs_move_inline_dirents(struct inode *dir, struct page *ipage,\n\t\t\t\t\t\t\tvoid *inline_dentry)\n{\n\tstruct page *page;\n\tstruct dnode_of_data dn;\n\tstruct f2fs_dentry_block *dentry_blk;\n\tstruct f2fs_dentry_ptr src, dst;\n\tint err;\n\n\tpage = f2fs_grab_cache_page(dir->i_mapping, 0, false);\n\tif (!page) {\n\t\tf2fs_put_page(ipage, 1);\n\t\treturn -ENOMEM;\n\t}\n\n\tset_new_dnode(&dn, dir, ipage, NULL, 0);\n\terr = f2fs_reserve_block(&dn, 0);\n\tif (err)\n\t\tgoto out;\n\n\tif (unlikely(dn.data_blkaddr != NEW_ADDR)) {\n\t\tf2fs_put_dnode(&dn);\n\t\tset_sbi_flag(F2FS_P_SB(page), SBI_NEED_FSCK);\n\t\tf2fs_msg(F2FS_P_SB(page)->sb, KERN_WARNING,\n\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"\n\t\t\t\"run fsck to fix.\",\n\t\t\t__func__, dir->i_ino, dn.data_blkaddr);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tf2fs_wait_on_page_writeback(page, DATA, true);\n\n\tdentry_blk = page_address(page);\n\n\tmake_dentry_ptr_inline(dir, &src, inline_dentry);\n\tmake_dentry_ptr_block(dir, &dst, dentry_blk);\n\n\t/* copy data from inline dentry block to new dentry block */\n\tmemcpy(dst.bitmap, src.bitmap, src.nr_bitmap);\n\tmemset(dst.bitmap + src.nr_bitmap, 0, dst.nr_bitmap - src.nr_bitmap);\n\t/*\n\t * we do not need to zero out remainder part of dentry and filename\n\t * field, since we have used bitmap for marking the usage status of\n\t * them, besides, we can also ignore copying/zeroing reserved space\n\t * of dentry block, because them haven't been used so far.\n\t */\n\tmemcpy(dst.dentry, src.dentry, SIZE_OF_DIR_ENTRY * src.max);\n\tmemcpy(dst.filename, src.filename, src.max * F2FS_SLOT_LEN);\n\n\tif (!PageUptodate(page))\n\t\tSetPageUptodate(page);\n\tset_page_dirty(page);\n\n\t/* clear inline dir and flag after data writeback */\n\tf2fs_truncate_inline_inode(dir, ipage, 0);\n\n\tstat_dec_inline_dir(dir);\n\tclear_inode_flag(dir, FI_INLINE_DENTRY);\n\n\tf2fs_i_depth_write(dir, 1);\n\tif (i_size_read(dir) < PAGE_SIZE)\n\t\tf2fs_i_size_write(dir, PAGE_SIZE);\nout:\n\tf2fs_put_page(page, 1);\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -17,6 +17,17 @@\n \terr = f2fs_reserve_block(&dn, 0);\n \tif (err)\n \t\tgoto out;\n+\n+\tif (unlikely(dn.data_blkaddr != NEW_ADDR)) {\n+\t\tf2fs_put_dnode(&dn);\n+\t\tset_sbi_flag(F2FS_P_SB(page), SBI_NEED_FSCK);\n+\t\tf2fs_msg(F2FS_P_SB(page)->sb, KERN_WARNING,\n+\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"\n+\t\t\t\"run fsck to fix.\",\n+\t\t\t__func__, dir->i_ino, dn.data_blkaddr);\n+\t\terr = -EINVAL;\n+\t\tgoto out;\n+\t}\n \n \tf2fs_wait_on_page_writeback(page, DATA, true);\n ",
        "function_modified_lines": {
            "added": [
                "",
                "\tif (unlikely(dn.data_blkaddr != NEW_ADDR)) {",
                "\t\tf2fs_put_dnode(&dn);",
                "\t\tset_sbi_flag(F2FS_P_SB(page), SBI_NEED_FSCK);",
                "\t\tf2fs_msg(F2FS_P_SB(page)->sb, KERN_WARNING,",
                "\t\t\t\"%s: corrupted inline inode ino=%lx, i_addr[0]:0x%x, \"",
                "\t\t\t\"run fsck to fix.\",",
                "\t\t\t__func__, dir->i_ino, dn.data_blkaddr);",
                "\t\terr = -EINVAL;",
                "\t\tgoto out;",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in fs/f2fs/inline.c in the Linux kernel through 4.4. A denial of service (out-of-bounds memory access and BUG) can occur for a modified f2fs filesystem image in which an inline inode contains an invalid reserved blkaddr.",
        "id": 1673
    },
    {
        "cve_id": "CVE-2019-15090",
        "code_before_change": "void\nqedi_dbg_warn(struct qedi_dbg_ctx *qedi, const char *func, u32 line,\n\t      const char *fmt, ...)\n{\n\tva_list va;\n\tstruct va_format vaf;\n\tchar nfunc[32];\n\n\tmemset(nfunc, 0, sizeof(nfunc));\n\tmemcpy(nfunc, func, sizeof(nfunc) - 1);\n\n\tva_start(va, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &va;\n\n\tif (!(qedi_dbg_log & QEDI_LOG_WARN))\n\t\tgoto ret;\n\n\tif (likely(qedi) && likely(qedi->pdev))\n\t\tpr_warn(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n\t\t\tnfunc, line, qedi->host_no, &vaf);\n\telse\n\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);\n\nret:\n\tva_end(va);\n}",
        "code_after_change": "void\nqedi_dbg_warn(struct qedi_dbg_ctx *qedi, const char *func, u32 line,\n\t      const char *fmt, ...)\n{\n\tva_list va;\n\tstruct va_format vaf;\n\n\tva_start(va, fmt);\n\n\tvaf.fmt = fmt;\n\tvaf.va = &va;\n\n\tif (!(qedi_dbg_log & QEDI_LOG_WARN))\n\t\tgoto ret;\n\n\tif (likely(qedi) && likely(qedi->pdev))\n\t\tpr_warn(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n\t\t\tfunc, line, qedi->host_no, &vaf);\n\telse\n\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);\n\nret:\n\tva_end(va);\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,10 +4,6 @@\n {\n \tva_list va;\n \tstruct va_format vaf;\n-\tchar nfunc[32];\n-\n-\tmemset(nfunc, 0, sizeof(nfunc));\n-\tmemcpy(nfunc, func, sizeof(nfunc) - 1);\n \n \tva_start(va, fmt);\n \n@@ -19,9 +15,9 @@\n \n \tif (likely(qedi) && likely(qedi->pdev))\n \t\tpr_warn(\"[%s]:[%s:%d]:%d: %pV\", dev_name(&qedi->pdev->dev),\n-\t\t\tnfunc, line, qedi->host_no, &vaf);\n+\t\t\tfunc, line, qedi->host_no, &vaf);\n \telse\n-\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);\n+\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);\n \n ret:\n \tva_end(va);",
        "function_modified_lines": {
            "added": [
                "\t\t\tfunc, line, qedi->host_no, &vaf);",
                "\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", func, line, &vaf);"
            ],
            "deleted": [
                "\tchar nfunc[32];",
                "",
                "\tmemset(nfunc, 0, sizeof(nfunc));",
                "\tmemcpy(nfunc, func, sizeof(nfunc) - 1);",
                "\t\t\tnfunc, line, qedi->host_no, &vaf);",
                "\t\tpr_warn(\"[0000:00:00.0]:[%s:%d]: %pV\", nfunc, line, &vaf);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in drivers/scsi/qedi/qedi_dbg.c in the Linux kernel before 5.1.12. In the qedi_dbg_* family of functions, there is an out-of-bounds read.",
        "id": 1986
    },
    {
        "cve_id": "CVE-2021-0941",
        "code_before_change": "\nBPF_CALL_4(bpf_skb_adjust_room, struct sk_buff *, skb, s32, len_diff,\n\t   u32, mode, u64, flags)\n{\n\tu32 len_cur, len_diff_abs = abs(len_diff);\n\tu32 len_min = bpf_skb_net_base_len(skb);\n\tu32 len_max = __bpf_skb_max_len(skb);\n\t__be16 proto = skb->protocol;\n\tbool shrink = len_diff < 0;\n\tu32 off;\n\tint ret;\n\n\tif (unlikely(flags & ~(BPF_F_ADJ_ROOM_MASK |\n\t\t\t       BPF_F_ADJ_ROOM_NO_CSUM_RESET)))\n\t\treturn -EINVAL;\n\tif (unlikely(len_diff_abs > 0xfffU))\n\t\treturn -EFAULT;\n\tif (unlikely(proto != htons(ETH_P_IP) &&\n\t\t     proto != htons(ETH_P_IPV6)))\n\t\treturn -ENOTSUPP;\n\n\toff = skb_mac_header_len(skb);\n\tswitch (mode) {\n\tcase BPF_ADJ_ROOM_NET:\n\t\toff += bpf_skb_net_base_len(skb);\n\t\tbreak;\n\tcase BPF_ADJ_ROOM_MAC:\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOTSUPP;\n\t}\n\n\tlen_cur = skb->len - skb_network_offset(skb);\n\tif ((shrink && (len_diff_abs >= len_cur ||\n\t\t\tlen_cur - len_diff_abs < len_min)) ||\n\t    (!shrink && (skb->len + len_diff_abs > len_max &&\n\t\t\t !skb_is_gso(skb))))\n\t\treturn -ENOTSUPP;\n\n\tret = shrink ? bpf_skb_net_shrink(skb, off, len_diff_abs, flags) :\n\t\t       bpf_skb_net_grow(skb, off, len_diff_abs, flags);\n\tif (!ret && !(flags & BPF_F_ADJ_ROOM_NO_CSUM_RESET))\n\t\t__skb_reset_checksum_unnecessary(skb);\n\n\tbpf_compute_data_pointers(skb);\n\treturn ret;\n}",
        "code_after_change": "\nBPF_CALL_4(bpf_skb_adjust_room, struct sk_buff *, skb, s32, len_diff,\n\t   u32, mode, u64, flags)\n{\n\tu32 len_cur, len_diff_abs = abs(len_diff);\n\tu32 len_min = bpf_skb_net_base_len(skb);\n\tu32 len_max = BPF_SKB_MAX_LEN;\n\t__be16 proto = skb->protocol;\n\tbool shrink = len_diff < 0;\n\tu32 off;\n\tint ret;\n\n\tif (unlikely(flags & ~(BPF_F_ADJ_ROOM_MASK |\n\t\t\t       BPF_F_ADJ_ROOM_NO_CSUM_RESET)))\n\t\treturn -EINVAL;\n\tif (unlikely(len_diff_abs > 0xfffU))\n\t\treturn -EFAULT;\n\tif (unlikely(proto != htons(ETH_P_IP) &&\n\t\t     proto != htons(ETH_P_IPV6)))\n\t\treturn -ENOTSUPP;\n\n\toff = skb_mac_header_len(skb);\n\tswitch (mode) {\n\tcase BPF_ADJ_ROOM_NET:\n\t\toff += bpf_skb_net_base_len(skb);\n\t\tbreak;\n\tcase BPF_ADJ_ROOM_MAC:\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOTSUPP;\n\t}\n\n\tlen_cur = skb->len - skb_network_offset(skb);\n\tif ((shrink && (len_diff_abs >= len_cur ||\n\t\t\tlen_cur - len_diff_abs < len_min)) ||\n\t    (!shrink && (skb->len + len_diff_abs > len_max &&\n\t\t\t !skb_is_gso(skb))))\n\t\treturn -ENOTSUPP;\n\n\tret = shrink ? bpf_skb_net_shrink(skb, off, len_diff_abs, flags) :\n\t\t       bpf_skb_net_grow(skb, off, len_diff_abs, flags);\n\tif (!ret && !(flags & BPF_F_ADJ_ROOM_NO_CSUM_RESET))\n\t\t__skb_reset_checksum_unnecessary(skb);\n\n\tbpf_compute_data_pointers(skb);\n\treturn ret;\n}",
        "patch": "--- code before\n+++ code after\n@@ -4,7 +4,7 @@\n {\n \tu32 len_cur, len_diff_abs = abs(len_diff);\n \tu32 len_min = bpf_skb_net_base_len(skb);\n-\tu32 len_max = __bpf_skb_max_len(skb);\n+\tu32 len_max = BPF_SKB_MAX_LEN;\n \t__be16 proto = skb->protocol;\n \tbool shrink = len_diff < 0;\n \tu32 off;",
        "function_modified_lines": {
            "added": [
                "\tu32 len_max = BPF_SKB_MAX_LEN;"
            ],
            "deleted": [
                "\tu32 len_max = __bpf_skb_max_len(skb);"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-416"
        ],
        "cve_description": "In bpf_skb_change_head of filter.c, there is a possible out of bounds read due to a use after free. This could lead to local escalation of privilege with System execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-154177719References: Upstream kernel",
        "id": 2838
    },
    {
        "cve_id": "CVE-2014-3145",
        "code_before_change": "static u64 __skb_get_nlattr_nest(u64 ctx, u64 A, u64 X, u64 r4, u64 r5)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)(long) ctx;\n\tstruct nlattr *nla;\n\n\tif (skb_is_nonlinear(skb))\n\t\treturn 0;\n\n\tif (A > skb->len - sizeof(struct nlattr))\n\t\treturn 0;\n\n\tnla = (struct nlattr *) &skb->data[A];\n\tif (nla->nla_len > A - skb->len)\n\t\treturn 0;\n\n\tnla = nla_find_nested(nla, X);\n\tif (nla)\n\t\treturn (void *) nla - (void *) skb->data;\n\n\treturn 0;\n}",
        "code_after_change": "static u64 __skb_get_nlattr_nest(u64 ctx, u64 A, u64 X, u64 r4, u64 r5)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)(long) ctx;\n\tstruct nlattr *nla;\n\n\tif (skb_is_nonlinear(skb))\n\t\treturn 0;\n\n\tif (skb->len < sizeof(struct nlattr))\n\t\treturn 0;\n\n\tif (A > skb->len - sizeof(struct nlattr))\n\t\treturn 0;\n\n\tnla = (struct nlattr *) &skb->data[A];\n\tif (nla->nla_len > skb->len - A)\n\t\treturn 0;\n\n\tnla = nla_find_nested(nla, X);\n\tif (nla)\n\t\treturn (void *) nla - (void *) skb->data;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -6,11 +6,14 @@\n \tif (skb_is_nonlinear(skb))\n \t\treturn 0;\n \n+\tif (skb->len < sizeof(struct nlattr))\n+\t\treturn 0;\n+\n \tif (A > skb->len - sizeof(struct nlattr))\n \t\treturn 0;\n \n \tnla = (struct nlattr *) &skb->data[A];\n-\tif (nla->nla_len > A - skb->len)\n+\tif (nla->nla_len > skb->len - A)\n \t\treturn 0;\n \n \tnla = nla_find_nested(nla, X);",
        "function_modified_lines": {
            "added": [
                "\tif (skb->len < sizeof(struct nlattr))",
                "\t\treturn 0;",
                "",
                "\tif (nla->nla_len > skb->len - A)"
            ],
            "deleted": [
                "\tif (nla->nla_len > A - skb->len)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The BPF_S_ANC_NLATTR_NEST extension implementation in the sk_run_filter function in net/core/filter.c in the Linux kernel through 3.14.3 uses the reverse order in a certain subtraction, which allows local users to cause a denial of service (over-read and system crash) via crafted BPF instructions.  NOTE: the affected code was moved to the __skb_get_nlattr_nest function before the vulnerability was announced.",
        "id": 505
    },
    {
        "cve_id": "CVE-2018-20854",
        "code_before_change": "static int serdes_probe(struct platform_device *pdev)\n{\n\tstruct phy_provider *provider;\n\tstruct serdes_ctrl *ctrl;\n\tunsigned int i;\n\tint ret;\n\n\tctrl = devm_kzalloc(&pdev->dev, sizeof(*ctrl), GFP_KERNEL);\n\tif (!ctrl)\n\t\treturn -ENOMEM;\n\n\tctrl->dev = &pdev->dev;\n\tctrl->regs = syscon_node_to_regmap(pdev->dev.parent->of_node);\n\tif (IS_ERR(ctrl->regs))\n\t\treturn PTR_ERR(ctrl->regs);\n\n\tfor (i = 0; i <= SERDES_MAX; i++) {\n\t\tret = serdes_phy_create(ctrl, i, &ctrl->phys[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tdev_set_drvdata(&pdev->dev, ctrl);\n\n\tprovider = devm_of_phy_provider_register(ctrl->dev,\n\t\t\t\t\t\t serdes_simple_xlate);\n\n\treturn PTR_ERR_OR_ZERO(provider);\n}",
        "code_after_change": "static int serdes_probe(struct platform_device *pdev)\n{\n\tstruct phy_provider *provider;\n\tstruct serdes_ctrl *ctrl;\n\tunsigned int i;\n\tint ret;\n\n\tctrl = devm_kzalloc(&pdev->dev, sizeof(*ctrl), GFP_KERNEL);\n\tif (!ctrl)\n\t\treturn -ENOMEM;\n\n\tctrl->dev = &pdev->dev;\n\tctrl->regs = syscon_node_to_regmap(pdev->dev.parent->of_node);\n\tif (IS_ERR(ctrl->regs))\n\t\treturn PTR_ERR(ctrl->regs);\n\n\tfor (i = 0; i < SERDES_MAX; i++) {\n\t\tret = serdes_phy_create(ctrl, i, &ctrl->phys[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tdev_set_drvdata(&pdev->dev, ctrl);\n\n\tprovider = devm_of_phy_provider_register(ctrl->dev,\n\t\t\t\t\t\t serdes_simple_xlate);\n\n\treturn PTR_ERR_OR_ZERO(provider);\n}",
        "patch": "--- code before\n+++ code after\n@@ -14,7 +14,7 @@\n \tif (IS_ERR(ctrl->regs))\n \t\treturn PTR_ERR(ctrl->regs);\n \n-\tfor (i = 0; i <= SERDES_MAX; i++) {\n+\tfor (i = 0; i < SERDES_MAX; i++) {\n \t\tret = serdes_phy_create(ctrl, i, &ctrl->phys[i]);\n \t\tif (ret)\n \t\t\treturn ret;",
        "function_modified_lines": {
            "added": [
                "\tfor (i = 0; i < SERDES_MAX; i++) {"
            ],
            "deleted": [
                "\tfor (i = 0; i <= SERDES_MAX; i++) {"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 4.20. drivers/phy/mscc/phy-ocelot-serdes.c has an off-by-one error with a resultant ctrl->phys out-of-bounds read.",
        "id": 1784
    },
    {
        "cve_id": "CVE-2019-3459",
        "code_before_change": "static int l2cap_parse_conf_rsp(struct l2cap_chan *chan, void *rsp, int len,\n\t\t\t\tvoid *data, size_t size, u16 *result)\n{\n\tstruct l2cap_conf_req *req = data;\n\tvoid *ptr = req->data;\n\tvoid *endptr = data + size;\n\tint type, olen;\n\tunsigned long val;\n\tstruct l2cap_conf_rfc rfc = { .mode = L2CAP_MODE_BASIC };\n\tstruct l2cap_conf_efs efs;\n\n\tBT_DBG(\"chan %p, rsp %p, len %d, req %p\", chan, rsp, len, data);\n\n\twhile (len >= L2CAP_CONF_OPT_SIZE) {\n\t\tlen -= l2cap_get_conf_opt(&rsp, &type, &olen, &val);\n\n\t\tswitch (type) {\n\t\tcase L2CAP_CONF_MTU:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tif (val < L2CAP_DEFAULT_MIN_MTU) {\n\t\t\t\t*result = L2CAP_CONF_UNACCEPT;\n\t\t\t\tchan->imtu = L2CAP_DEFAULT_MIN_MTU;\n\t\t\t} else\n\t\t\t\tchan->imtu = val;\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_MTU, 2, chan->imtu,\n\t\t\t\t\t   endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_FLUSH_TO:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tchan->flush_to = val;\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_FLUSH_TO, 2,\n\t\t\t\t\t   chan->flush_to, endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_RFC:\n\t\t\tif (olen != sizeof(rfc))\n\t\t\t\tbreak;\n\t\t\tmemcpy(&rfc, (void *)val, olen);\n\t\t\tif (test_bit(CONF_STATE2_DEVICE, &chan->conf_state) &&\n\t\t\t    rfc.mode != chan->mode)\n\t\t\t\treturn -ECONNREFUSED;\n\t\t\tchan->fcs = 0;\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC, sizeof(rfc),\n\t\t\t\t\t   (unsigned long) &rfc, endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_EWS:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tchan->ack_win = min_t(u16, val, chan->ack_win);\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_EWS, 2,\n\t\t\t\t\t   chan->tx_win, endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_EFS:\n\t\t\tif (olen != sizeof(efs))\n\t\t\t\tbreak;\n\t\t\tmemcpy(&efs, (void *)val, olen);\n\t\t\tif (chan->local_stype != L2CAP_SERV_NOTRAFIC &&\n\t\t\t    efs.stype != L2CAP_SERV_NOTRAFIC &&\n\t\t\t    efs.stype != chan->local_stype)\n\t\t\t\treturn -ECONNREFUSED;\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_EFS, sizeof(efs),\n\t\t\t\t\t   (unsigned long) &efs, endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_FCS:\n\t\t\tif (olen != 1)\n\t\t\t\tbreak;\n\t\t\tif (*result == L2CAP_CONF_PENDING)\n\t\t\t\tif (val == L2CAP_FCS_NONE)\n\t\t\t\t\tset_bit(CONF_RECV_NO_FCS,\n\t\t\t\t\t\t&chan->conf_state);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (chan->mode == L2CAP_MODE_BASIC && chan->mode != rfc.mode)\n\t\treturn -ECONNREFUSED;\n\n\tchan->mode = rfc.mode;\n\n\tif (*result == L2CAP_CONF_SUCCESS || *result == L2CAP_CONF_PENDING) {\n\t\tswitch (rfc.mode) {\n\t\tcase L2CAP_MODE_ERTM:\n\t\t\tchan->retrans_timeout = le16_to_cpu(rfc.retrans_timeout);\n\t\t\tchan->monitor_timeout = le16_to_cpu(rfc.monitor_timeout);\n\t\t\tchan->mps    = le16_to_cpu(rfc.max_pdu_size);\n\t\t\tif (!test_bit(FLAG_EXT_CTRL, &chan->flags))\n\t\t\t\tchan->ack_win = min_t(u16, chan->ack_win,\n\t\t\t\t\t\t      rfc.txwin_size);\n\n\t\t\tif (test_bit(FLAG_EFS_ENABLE, &chan->flags)) {\n\t\t\t\tchan->local_msdu = le16_to_cpu(efs.msdu);\n\t\t\t\tchan->local_sdu_itime =\n\t\t\t\t\tle32_to_cpu(efs.sdu_itime);\n\t\t\t\tchan->local_acc_lat = le32_to_cpu(efs.acc_lat);\n\t\t\t\tchan->local_flush_to =\n\t\t\t\t\tle32_to_cpu(efs.flush_to);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase L2CAP_MODE_STREAMING:\n\t\t\tchan->mps    = le16_to_cpu(rfc.max_pdu_size);\n\t\t}\n\t}\n\n\treq->dcid   = cpu_to_le16(chan->dcid);\n\treq->flags  = cpu_to_le16(0);\n\n\treturn ptr - data;\n}",
        "code_after_change": "static int l2cap_parse_conf_rsp(struct l2cap_chan *chan, void *rsp, int len,\n\t\t\t\tvoid *data, size_t size, u16 *result)\n{\n\tstruct l2cap_conf_req *req = data;\n\tvoid *ptr = req->data;\n\tvoid *endptr = data + size;\n\tint type, olen;\n\tunsigned long val;\n\tstruct l2cap_conf_rfc rfc = { .mode = L2CAP_MODE_BASIC };\n\tstruct l2cap_conf_efs efs;\n\n\tBT_DBG(\"chan %p, rsp %p, len %d, req %p\", chan, rsp, len, data);\n\n\twhile (len >= L2CAP_CONF_OPT_SIZE) {\n\t\tlen -= l2cap_get_conf_opt(&rsp, &type, &olen, &val);\n\t\tif (len < 0)\n\t\t\tbreak;\n\n\t\tswitch (type) {\n\t\tcase L2CAP_CONF_MTU:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tif (val < L2CAP_DEFAULT_MIN_MTU) {\n\t\t\t\t*result = L2CAP_CONF_UNACCEPT;\n\t\t\t\tchan->imtu = L2CAP_DEFAULT_MIN_MTU;\n\t\t\t} else\n\t\t\t\tchan->imtu = val;\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_MTU, 2, chan->imtu,\n\t\t\t\t\t   endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_FLUSH_TO:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tchan->flush_to = val;\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_FLUSH_TO, 2,\n\t\t\t\t\t   chan->flush_to, endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_RFC:\n\t\t\tif (olen != sizeof(rfc))\n\t\t\t\tbreak;\n\t\t\tmemcpy(&rfc, (void *)val, olen);\n\t\t\tif (test_bit(CONF_STATE2_DEVICE, &chan->conf_state) &&\n\t\t\t    rfc.mode != chan->mode)\n\t\t\t\treturn -ECONNREFUSED;\n\t\t\tchan->fcs = 0;\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC, sizeof(rfc),\n\t\t\t\t\t   (unsigned long) &rfc, endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_EWS:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tchan->ack_win = min_t(u16, val, chan->ack_win);\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_EWS, 2,\n\t\t\t\t\t   chan->tx_win, endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_EFS:\n\t\t\tif (olen != sizeof(efs))\n\t\t\t\tbreak;\n\t\t\tmemcpy(&efs, (void *)val, olen);\n\t\t\tif (chan->local_stype != L2CAP_SERV_NOTRAFIC &&\n\t\t\t    efs.stype != L2CAP_SERV_NOTRAFIC &&\n\t\t\t    efs.stype != chan->local_stype)\n\t\t\t\treturn -ECONNREFUSED;\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_EFS, sizeof(efs),\n\t\t\t\t\t   (unsigned long) &efs, endptr - ptr);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_FCS:\n\t\t\tif (olen != 1)\n\t\t\t\tbreak;\n\t\t\tif (*result == L2CAP_CONF_PENDING)\n\t\t\t\tif (val == L2CAP_FCS_NONE)\n\t\t\t\t\tset_bit(CONF_RECV_NO_FCS,\n\t\t\t\t\t\t&chan->conf_state);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (chan->mode == L2CAP_MODE_BASIC && chan->mode != rfc.mode)\n\t\treturn -ECONNREFUSED;\n\n\tchan->mode = rfc.mode;\n\n\tif (*result == L2CAP_CONF_SUCCESS || *result == L2CAP_CONF_PENDING) {\n\t\tswitch (rfc.mode) {\n\t\tcase L2CAP_MODE_ERTM:\n\t\t\tchan->retrans_timeout = le16_to_cpu(rfc.retrans_timeout);\n\t\t\tchan->monitor_timeout = le16_to_cpu(rfc.monitor_timeout);\n\t\t\tchan->mps    = le16_to_cpu(rfc.max_pdu_size);\n\t\t\tif (!test_bit(FLAG_EXT_CTRL, &chan->flags))\n\t\t\t\tchan->ack_win = min_t(u16, chan->ack_win,\n\t\t\t\t\t\t      rfc.txwin_size);\n\n\t\t\tif (test_bit(FLAG_EFS_ENABLE, &chan->flags)) {\n\t\t\t\tchan->local_msdu = le16_to_cpu(efs.msdu);\n\t\t\t\tchan->local_sdu_itime =\n\t\t\t\t\tle32_to_cpu(efs.sdu_itime);\n\t\t\t\tchan->local_acc_lat = le32_to_cpu(efs.acc_lat);\n\t\t\t\tchan->local_flush_to =\n\t\t\t\t\tle32_to_cpu(efs.flush_to);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase L2CAP_MODE_STREAMING:\n\t\t\tchan->mps    = le16_to_cpu(rfc.max_pdu_size);\n\t\t}\n\t}\n\n\treq->dcid   = cpu_to_le16(chan->dcid);\n\treq->flags  = cpu_to_le16(0);\n\n\treturn ptr - data;\n}",
        "patch": "--- code before\n+++ code after\n@@ -13,6 +13,8 @@\n \n \twhile (len >= L2CAP_CONF_OPT_SIZE) {\n \t\tlen -= l2cap_get_conf_opt(&rsp, &type, &olen, &val);\n+\t\tif (len < 0)\n+\t\t\tbreak;\n \n \t\tswitch (type) {\n \t\tcase L2CAP_CONF_MTU:",
        "function_modified_lines": {
            "added": [
                "\t\tif (len < 0)",
                "\t\t\tbreak;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A heap address information leak while using L2CAP_GET_CONF_OPT was discovered in the Linux kernel before 5.1-rc1.",
        "id": 2309
    },
    {
        "cve_id": "CVE-2020-28097",
        "code_before_change": "static const char *vgacon_startup(void)\n{\n\tconst char *display_desc = NULL;\n\tu16 saved1, saved2;\n\tvolatile u16 *p;\n\n\tif (screen_info.orig_video_isVGA == VIDEO_TYPE_VLFB ||\n\t    screen_info.orig_video_isVGA == VIDEO_TYPE_EFI) {\n\t      no_vga:\n#ifdef CONFIG_DUMMY_CONSOLE\n\t\tconswitchp = &dummy_con;\n\t\treturn conswitchp->con_startup();\n#else\n\t\treturn NULL;\n#endif\n\t}\n\n\t/* boot_params.screen_info reasonably initialized? */\n\tif ((screen_info.orig_video_lines == 0) ||\n\t    (screen_info.orig_video_cols  == 0))\n\t\tgoto no_vga;\n\n\t/* VGA16 modes are not handled by VGACON */\n\tif ((screen_info.orig_video_mode == 0x0D) ||\t/* 320x200/4 */\n\t    (screen_info.orig_video_mode == 0x0E) ||\t/* 640x200/4 */\n\t    (screen_info.orig_video_mode == 0x10) ||\t/* 640x350/4 */\n\t    (screen_info.orig_video_mode == 0x12) ||\t/* 640x480/4 */\n\t    (screen_info.orig_video_mode == 0x6A))\t/* 800x600/4 (VESA) */\n\t\tgoto no_vga;\n\n\tvga_video_num_lines = screen_info.orig_video_lines;\n\tvga_video_num_columns = screen_info.orig_video_cols;\n\tvgastate.vgabase = NULL;\n\n\tif (screen_info.orig_video_mode == 7) {\n\t\t/* Monochrome display */\n\t\tvga_vram_base = 0xb0000;\n\t\tvga_video_port_reg = VGA_CRT_IM;\n\t\tvga_video_port_val = VGA_CRT_DM;\n\t\tif ((screen_info.orig_video_ega_bx & 0xff) != 0x10) {\n\t\t\tstatic struct resource ega_console_resource =\n\t\t\t    { .name\t= \"ega\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3B0,\n\t\t\t      .end\t= 0x3BF };\n\t\t\tvga_video_type = VIDEO_TYPE_EGAM;\n\t\t\tvga_vram_size = 0x8000;\n\t\t\tdisplay_desc = \"EGA+\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &ega_console_resource);\n\t\t} else {\n\t\t\tstatic struct resource mda1_console_resource =\n\t\t\t    { .name\t= \"mda\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3B0,\n\t\t\t      .end\t= 0x3BB };\n\t\t\tstatic struct resource mda2_console_resource =\n\t\t\t    { .name\t= \"mda\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3BF,\n\t\t\t      .end\t= 0x3BF };\n\t\t\tvga_video_type = VIDEO_TYPE_MDA;\n\t\t\tvga_vram_size = 0x2000;\n\t\t\tdisplay_desc = \"*MDA\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &mda1_console_resource);\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &mda2_console_resource);\n\t\t\tvga_video_font_height = 14;\n\t\t}\n\t} else {\n\t\t/* If not, it is color. */\n\t\tvga_can_do_color = true;\n\t\tvga_vram_base = 0xb8000;\n\t\tvga_video_port_reg = VGA_CRT_IC;\n\t\tvga_video_port_val = VGA_CRT_DC;\n\t\tif ((screen_info.orig_video_ega_bx & 0xff) != 0x10) {\n\t\t\tint i;\n\n\t\t\tvga_vram_size = 0x8000;\n\n\t\t\tif (!screen_info.orig_video_isVGA) {\n\t\t\t\tstatic struct resource ega_console_resource =\n\t\t\t\t    { .name\t= \"ega\",\n\t\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t\t      .start\t= 0x3C0,\n\t\t\t\t      .end\t= 0x3DF };\n\t\t\t\tvga_video_type = VIDEO_TYPE_EGAC;\n\t\t\t\tdisplay_desc = \"EGA\";\n\t\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t\t &ega_console_resource);\n\t\t\t} else {\n\t\t\t\tstatic struct resource vga_console_resource =\n\t\t\t\t    { .name\t= \"vga+\",\n\t\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t\t      .start\t= 0x3C0,\n\t\t\t\t      .end\t= 0x3DF };\n\t\t\t\tvga_video_type = VIDEO_TYPE_VGAC;\n\t\t\t\tdisplay_desc = \"VGA+\";\n\t\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t\t &vga_console_resource);\n\n\t\t\t\t/*\n\t\t\t\t * Normalise the palette registers, to point\n\t\t\t\t * the 16 screen colours to the first 16\n\t\t\t\t * DAC entries.\n\t\t\t\t */\n\n\t\t\t\tfor (i = 0; i < 16; i++) {\n\t\t\t\t\tinb_p(VGA_IS1_RC);\n\t\t\t\t\toutb_p(i, VGA_ATT_W);\n\t\t\t\t\toutb_p(i, VGA_ATT_W);\n\t\t\t\t}\n\t\t\t\toutb_p(0x20, VGA_ATT_W);\n\n\t\t\t\t/*\n\t\t\t\t * Now set the DAC registers back to their\n\t\t\t\t * default values\n\t\t\t\t */\n\t\t\t\tfor (i = 0; i < 16; i++) {\n\t\t\t\t\toutb_p(color_table[i], VGA_PEL_IW);\n\t\t\t\t\toutb_p(default_red[i], VGA_PEL_D);\n\t\t\t\t\toutb_p(default_grn[i], VGA_PEL_D);\n\t\t\t\t\toutb_p(default_blu[i], VGA_PEL_D);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tstatic struct resource cga_console_resource =\n\t\t\t    { .name\t= \"cga\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3D4,\n\t\t\t      .end\t= 0x3D5 };\n\t\t\tvga_video_type = VIDEO_TYPE_CGA;\n\t\t\tvga_vram_size = 0x2000;\n\t\t\tdisplay_desc = \"*CGA\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &cga_console_resource);\n\t\t\tvga_video_font_height = 8;\n\t\t}\n\t}\n\n\tvga_vram_base = VGA_MAP_MEM(vga_vram_base, vga_vram_size);\n\tvga_vram_end = vga_vram_base + vga_vram_size;\n\n\t/*\n\t *      Find out if there is a graphics card present.\n\t *      Are there smarter methods around?\n\t */\n\tp = (volatile u16 *) vga_vram_base;\n\tsaved1 = scr_readw(p);\n\tsaved2 = scr_readw(p + 1);\n\tscr_writew(0xAA55, p);\n\tscr_writew(0x55AA, p + 1);\n\tif (scr_readw(p) != 0xAA55 || scr_readw(p + 1) != 0x55AA) {\n\t\tscr_writew(saved1, p);\n\t\tscr_writew(saved2, p + 1);\n\t\tgoto no_vga;\n\t}\n\tscr_writew(0x55AA, p);\n\tscr_writew(0xAA55, p + 1);\n\tif (scr_readw(p) != 0x55AA || scr_readw(p + 1) != 0xAA55) {\n\t\tscr_writew(saved1, p);\n\t\tscr_writew(saved2, p + 1);\n\t\tgoto no_vga;\n\t}\n\tscr_writew(saved1, p);\n\tscr_writew(saved2, p + 1);\n\n\tif (vga_video_type == VIDEO_TYPE_EGAC\n\t    || vga_video_type == VIDEO_TYPE_VGAC\n\t    || vga_video_type == VIDEO_TYPE_EGAM) {\n\t\tvga_hardscroll_enabled = vga_hardscroll_user_enable;\n\t\tvga_default_font_height = screen_info.orig_video_points;\n\t\tvga_video_font_height = screen_info.orig_video_points;\n\t\t/* This may be suboptimal but is a safe bet - go with it */\n\t\tvga_scan_lines =\n\t\t    vga_video_font_height * vga_video_num_lines;\n\t}\n\n\tvgacon_xres = screen_info.orig_video_cols * VGA_FONTWIDTH;\n\tvgacon_yres = vga_scan_lines;\n\n\tif (!vga_init_done) {\n\t\tvgacon_scrollback_startup();\n\t\tvga_init_done = true;\n\t}\n\n\treturn display_desc;\n}",
        "code_after_change": "static const char *vgacon_startup(void)\n{\n\tconst char *display_desc = NULL;\n\tu16 saved1, saved2;\n\tvolatile u16 *p;\n\n\tif (screen_info.orig_video_isVGA == VIDEO_TYPE_VLFB ||\n\t    screen_info.orig_video_isVGA == VIDEO_TYPE_EFI) {\n\t      no_vga:\n#ifdef CONFIG_DUMMY_CONSOLE\n\t\tconswitchp = &dummy_con;\n\t\treturn conswitchp->con_startup();\n#else\n\t\treturn NULL;\n#endif\n\t}\n\n\t/* boot_params.screen_info reasonably initialized? */\n\tif ((screen_info.orig_video_lines == 0) ||\n\t    (screen_info.orig_video_cols  == 0))\n\t\tgoto no_vga;\n\n\t/* VGA16 modes are not handled by VGACON */\n\tif ((screen_info.orig_video_mode == 0x0D) ||\t/* 320x200/4 */\n\t    (screen_info.orig_video_mode == 0x0E) ||\t/* 640x200/4 */\n\t    (screen_info.orig_video_mode == 0x10) ||\t/* 640x350/4 */\n\t    (screen_info.orig_video_mode == 0x12) ||\t/* 640x480/4 */\n\t    (screen_info.orig_video_mode == 0x6A))\t/* 800x600/4 (VESA) */\n\t\tgoto no_vga;\n\n\tvga_video_num_lines = screen_info.orig_video_lines;\n\tvga_video_num_columns = screen_info.orig_video_cols;\n\tvgastate.vgabase = NULL;\n\n\tif (screen_info.orig_video_mode == 7) {\n\t\t/* Monochrome display */\n\t\tvga_vram_base = 0xb0000;\n\t\tvga_video_port_reg = VGA_CRT_IM;\n\t\tvga_video_port_val = VGA_CRT_DM;\n\t\tif ((screen_info.orig_video_ega_bx & 0xff) != 0x10) {\n\t\t\tstatic struct resource ega_console_resource =\n\t\t\t    { .name\t= \"ega\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3B0,\n\t\t\t      .end\t= 0x3BF };\n\t\t\tvga_video_type = VIDEO_TYPE_EGAM;\n\t\t\tvga_vram_size = 0x8000;\n\t\t\tdisplay_desc = \"EGA+\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &ega_console_resource);\n\t\t} else {\n\t\t\tstatic struct resource mda1_console_resource =\n\t\t\t    { .name\t= \"mda\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3B0,\n\t\t\t      .end\t= 0x3BB };\n\t\t\tstatic struct resource mda2_console_resource =\n\t\t\t    { .name\t= \"mda\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3BF,\n\t\t\t      .end\t= 0x3BF };\n\t\t\tvga_video_type = VIDEO_TYPE_MDA;\n\t\t\tvga_vram_size = 0x2000;\n\t\t\tdisplay_desc = \"*MDA\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &mda1_console_resource);\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &mda2_console_resource);\n\t\t\tvga_video_font_height = 14;\n\t\t}\n\t} else {\n\t\t/* If not, it is color. */\n\t\tvga_can_do_color = true;\n\t\tvga_vram_base = 0xb8000;\n\t\tvga_video_port_reg = VGA_CRT_IC;\n\t\tvga_video_port_val = VGA_CRT_DC;\n\t\tif ((screen_info.orig_video_ega_bx & 0xff) != 0x10) {\n\t\t\tint i;\n\n\t\t\tvga_vram_size = 0x8000;\n\n\t\t\tif (!screen_info.orig_video_isVGA) {\n\t\t\t\tstatic struct resource ega_console_resource =\n\t\t\t\t    { .name\t= \"ega\",\n\t\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t\t      .start\t= 0x3C0,\n\t\t\t\t      .end\t= 0x3DF };\n\t\t\t\tvga_video_type = VIDEO_TYPE_EGAC;\n\t\t\t\tdisplay_desc = \"EGA\";\n\t\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t\t &ega_console_resource);\n\t\t\t} else {\n\t\t\t\tstatic struct resource vga_console_resource =\n\t\t\t\t    { .name\t= \"vga+\",\n\t\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t\t      .start\t= 0x3C0,\n\t\t\t\t      .end\t= 0x3DF };\n\t\t\t\tvga_video_type = VIDEO_TYPE_VGAC;\n\t\t\t\tdisplay_desc = \"VGA+\";\n\t\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t\t &vga_console_resource);\n\n\t\t\t\t/*\n\t\t\t\t * Normalise the palette registers, to point\n\t\t\t\t * the 16 screen colours to the first 16\n\t\t\t\t * DAC entries.\n\t\t\t\t */\n\n\t\t\t\tfor (i = 0; i < 16; i++) {\n\t\t\t\t\tinb_p(VGA_IS1_RC);\n\t\t\t\t\toutb_p(i, VGA_ATT_W);\n\t\t\t\t\toutb_p(i, VGA_ATT_W);\n\t\t\t\t}\n\t\t\t\toutb_p(0x20, VGA_ATT_W);\n\n\t\t\t\t/*\n\t\t\t\t * Now set the DAC registers back to their\n\t\t\t\t * default values\n\t\t\t\t */\n\t\t\t\tfor (i = 0; i < 16; i++) {\n\t\t\t\t\toutb_p(color_table[i], VGA_PEL_IW);\n\t\t\t\t\toutb_p(default_red[i], VGA_PEL_D);\n\t\t\t\t\toutb_p(default_grn[i], VGA_PEL_D);\n\t\t\t\t\toutb_p(default_blu[i], VGA_PEL_D);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tstatic struct resource cga_console_resource =\n\t\t\t    { .name\t= \"cga\",\n\t\t\t      .flags\t= IORESOURCE_IO,\n\t\t\t      .start\t= 0x3D4,\n\t\t\t      .end\t= 0x3D5 };\n\t\t\tvga_video_type = VIDEO_TYPE_CGA;\n\t\t\tvga_vram_size = 0x2000;\n\t\t\tdisplay_desc = \"*CGA\";\n\t\t\trequest_resource(&ioport_resource,\n\t\t\t\t\t &cga_console_resource);\n\t\t\tvga_video_font_height = 8;\n\t\t}\n\t}\n\n\tvga_vram_base = VGA_MAP_MEM(vga_vram_base, vga_vram_size);\n\tvga_vram_end = vga_vram_base + vga_vram_size;\n\n\t/*\n\t *      Find out if there is a graphics card present.\n\t *      Are there smarter methods around?\n\t */\n\tp = (volatile u16 *) vga_vram_base;\n\tsaved1 = scr_readw(p);\n\tsaved2 = scr_readw(p + 1);\n\tscr_writew(0xAA55, p);\n\tscr_writew(0x55AA, p + 1);\n\tif (scr_readw(p) != 0xAA55 || scr_readw(p + 1) != 0x55AA) {\n\t\tscr_writew(saved1, p);\n\t\tscr_writew(saved2, p + 1);\n\t\tgoto no_vga;\n\t}\n\tscr_writew(0x55AA, p);\n\tscr_writew(0xAA55, p + 1);\n\tif (scr_readw(p) != 0x55AA || scr_readw(p + 1) != 0xAA55) {\n\t\tscr_writew(saved1, p);\n\t\tscr_writew(saved2, p + 1);\n\t\tgoto no_vga;\n\t}\n\tscr_writew(saved1, p);\n\tscr_writew(saved2, p + 1);\n\n\tif (vga_video_type == VIDEO_TYPE_EGAC\n\t    || vga_video_type == VIDEO_TYPE_VGAC\n\t    || vga_video_type == VIDEO_TYPE_EGAM) {\n\t\tvga_hardscroll_enabled = vga_hardscroll_user_enable;\n\t\tvga_default_font_height = screen_info.orig_video_points;\n\t\tvga_video_font_height = screen_info.orig_video_points;\n\t\t/* This may be suboptimal but is a safe bet - go with it */\n\t\tvga_scan_lines =\n\t\t    vga_video_font_height * vga_video_num_lines;\n\t}\n\n\tvgacon_xres = screen_info.orig_video_cols * VGA_FONTWIDTH;\n\tvgacon_yres = vga_scan_lines;\n\n\tvga_init_done = true;\n\n\treturn display_desc;\n}",
        "patch": "--- code before\n+++ code after\n@@ -180,10 +180,7 @@\n \tvgacon_xres = screen_info.orig_video_cols * VGA_FONTWIDTH;\n \tvgacon_yres = vga_scan_lines;\n \n-\tif (!vga_init_done) {\n-\t\tvgacon_scrollback_startup();\n-\t\tvga_init_done = true;\n-\t}\n+\tvga_init_done = true;\n \n \treturn display_desc;\n }",
        "function_modified_lines": {
            "added": [
                "\tvga_init_done = true;"
            ],
            "deleted": [
                "\tif (!vga_init_done) {",
                "\t\tvgacon_scrollback_startup();",
                "\t\tvga_init_done = true;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The vgacon subsystem in the Linux kernel before 5.8.10 mishandles software scrollback. There is a vgacon_scrolldelta out-of-bounds read, aka CID-973c096f6a85.",
        "id": 2656
    },
    {
        "cve_id": "CVE-2018-19985",
        "code_before_change": "static int hso_probe(struct usb_interface *interface,\n\t\t     const struct usb_device_id *id)\n{\n\tint mux, i, if_num, port_spec;\n\tunsigned char port_mask;\n\tstruct hso_device *hso_dev = NULL;\n\tstruct hso_shared_int *shared_int;\n\tstruct hso_device *tmp_dev = NULL;\n\n\tif (interface->cur_altsetting->desc.bInterfaceClass != 0xFF) {\n\t\tdev_err(&interface->dev, \"Not our interface\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif_num = interface->cur_altsetting->desc.bInterfaceNumber;\n\n\t/* Get the interface/port specification from either driver_info or from\n\t * the device itself */\n\tif (id->driver_info)\n\t\tport_spec = ((u32 *)(id->driver_info))[if_num];\n\telse\n\t\tport_spec = hso_get_config_data(interface);\n\n\t/* Check if we need to switch to alt interfaces prior to port\n\t * configuration */\n\tif (interface->num_altsetting > 1)\n\t\tusb_set_interface(interface_to_usbdev(interface), if_num, 1);\n\tinterface->needs_remote_wakeup = 1;\n\n\t/* Allocate new hso device(s) */\n\tswitch (port_spec & HSO_INTF_MASK) {\n\tcase HSO_INTF_MUX:\n\t\tif ((port_spec & HSO_PORT_MASK) == HSO_PORT_NETWORK) {\n\t\t\t/* Create the network device */\n\t\t\tif (!disable_net) {\n\t\t\t\thso_dev = hso_create_net_device(interface,\n\t\t\t\t\t\t\t\tport_spec);\n\t\t\t\tif (!hso_dev)\n\t\t\t\t\tgoto exit;\n\t\t\t\ttmp_dev = hso_dev;\n\t\t\t}\n\t\t}\n\n\t\tif (hso_get_mux_ports(interface, &port_mask))\n\t\t\t/* TODO: de-allocate everything */\n\t\t\tgoto exit;\n\n\t\tshared_int = hso_create_shared_int(interface);\n\t\tif (!shared_int)\n\t\t\tgoto exit;\n\n\t\tfor (i = 1, mux = 0; i < 0x100; i = i << 1, mux++) {\n\t\t\tif (port_mask & i) {\n\t\t\t\thso_dev = hso_create_mux_serial_device(\n\t\t\t\t\t\tinterface, i, shared_int);\n\t\t\t\tif (!hso_dev)\n\t\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif (tmp_dev)\n\t\t\thso_dev = tmp_dev;\n\t\tbreak;\n\n\tcase HSO_INTF_BULK:\n\t\t/* It's a regular bulk interface */\n\t\tif ((port_spec & HSO_PORT_MASK) == HSO_PORT_NETWORK) {\n\t\t\tif (!disable_net)\n\t\t\t\thso_dev =\n\t\t\t\t    hso_create_net_device(interface, port_spec);\n\t\t} else {\n\t\t\thso_dev =\n\t\t\t    hso_create_bulk_serial_device(interface, port_spec);\n\t\t}\n\t\tif (!hso_dev)\n\t\t\tgoto exit;\n\t\tbreak;\n\tdefault:\n\t\tgoto exit;\n\t}\n\n\t/* save our data pointer in this device */\n\tusb_set_intfdata(interface, hso_dev);\n\n\t/* done */\n\treturn 0;\nexit:\n\thso_free_interface(interface);\n\treturn -ENODEV;\n}",
        "code_after_change": "static int hso_probe(struct usb_interface *interface,\n\t\t     const struct usb_device_id *id)\n{\n\tint mux, i, if_num, port_spec;\n\tunsigned char port_mask;\n\tstruct hso_device *hso_dev = NULL;\n\tstruct hso_shared_int *shared_int;\n\tstruct hso_device *tmp_dev = NULL;\n\n\tif (interface->cur_altsetting->desc.bInterfaceClass != 0xFF) {\n\t\tdev_err(&interface->dev, \"Not our interface\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif_num = interface->cur_altsetting->desc.bInterfaceNumber;\n\n\t/* Get the interface/port specification from either driver_info or from\n\t * the device itself */\n\tif (id->driver_info) {\n\t\t/* if_num is controlled by the device, driver_info is a 0 terminated\n\t\t * array. Make sure, the access is in bounds! */\n\t\tfor (i = 0; i <= if_num; ++i)\n\t\t\tif (((u32 *)(id->driver_info))[i] == 0)\n\t\t\t\tgoto exit;\n\t\tport_spec = ((u32 *)(id->driver_info))[if_num];\n\t} else {\n\t\tport_spec = hso_get_config_data(interface);\n\t\tif (port_spec < 0)\n\t\t\tgoto exit;\n\t}\n\n\t/* Check if we need to switch to alt interfaces prior to port\n\t * configuration */\n\tif (interface->num_altsetting > 1)\n\t\tusb_set_interface(interface_to_usbdev(interface), if_num, 1);\n\tinterface->needs_remote_wakeup = 1;\n\n\t/* Allocate new hso device(s) */\n\tswitch (port_spec & HSO_INTF_MASK) {\n\tcase HSO_INTF_MUX:\n\t\tif ((port_spec & HSO_PORT_MASK) == HSO_PORT_NETWORK) {\n\t\t\t/* Create the network device */\n\t\t\tif (!disable_net) {\n\t\t\t\thso_dev = hso_create_net_device(interface,\n\t\t\t\t\t\t\t\tport_spec);\n\t\t\t\tif (!hso_dev)\n\t\t\t\t\tgoto exit;\n\t\t\t\ttmp_dev = hso_dev;\n\t\t\t}\n\t\t}\n\n\t\tif (hso_get_mux_ports(interface, &port_mask))\n\t\t\t/* TODO: de-allocate everything */\n\t\t\tgoto exit;\n\n\t\tshared_int = hso_create_shared_int(interface);\n\t\tif (!shared_int)\n\t\t\tgoto exit;\n\n\t\tfor (i = 1, mux = 0; i < 0x100; i = i << 1, mux++) {\n\t\t\tif (port_mask & i) {\n\t\t\t\thso_dev = hso_create_mux_serial_device(\n\t\t\t\t\t\tinterface, i, shared_int);\n\t\t\t\tif (!hso_dev)\n\t\t\t\t\tgoto exit;\n\t\t\t}\n\t\t}\n\n\t\tif (tmp_dev)\n\t\t\thso_dev = tmp_dev;\n\t\tbreak;\n\n\tcase HSO_INTF_BULK:\n\t\t/* It's a regular bulk interface */\n\t\tif ((port_spec & HSO_PORT_MASK) == HSO_PORT_NETWORK) {\n\t\t\tif (!disable_net)\n\t\t\t\thso_dev =\n\t\t\t\t    hso_create_net_device(interface, port_spec);\n\t\t} else {\n\t\t\thso_dev =\n\t\t\t    hso_create_bulk_serial_device(interface, port_spec);\n\t\t}\n\t\tif (!hso_dev)\n\t\t\tgoto exit;\n\t\tbreak;\n\tdefault:\n\t\tgoto exit;\n\t}\n\n\t/* save our data pointer in this device */\n\tusb_set_intfdata(interface, hso_dev);\n\n\t/* done */\n\treturn 0;\nexit:\n\thso_free_interface(interface);\n\treturn -ENODEV;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,10 +16,18 @@\n \n \t/* Get the interface/port specification from either driver_info or from\n \t * the device itself */\n-\tif (id->driver_info)\n+\tif (id->driver_info) {\n+\t\t/* if_num is controlled by the device, driver_info is a 0 terminated\n+\t\t * array. Make sure, the access is in bounds! */\n+\t\tfor (i = 0; i <= if_num; ++i)\n+\t\t\tif (((u32 *)(id->driver_info))[i] == 0)\n+\t\t\t\tgoto exit;\n \t\tport_spec = ((u32 *)(id->driver_info))[if_num];\n-\telse\n+\t} else {\n \t\tport_spec = hso_get_config_data(interface);\n+\t\tif (port_spec < 0)\n+\t\t\tgoto exit;\n+\t}\n \n \t/* Check if we need to switch to alt interfaces prior to port\n \t * configuration */",
        "function_modified_lines": {
            "added": [
                "\tif (id->driver_info) {",
                "\t\t/* if_num is controlled by the device, driver_info is a 0 terminated",
                "\t\t * array. Make sure, the access is in bounds! */",
                "\t\tfor (i = 0; i <= if_num; ++i)",
                "\t\t\tif (((u32 *)(id->driver_info))[i] == 0)",
                "\t\t\t\tgoto exit;",
                "\t} else {",
                "\t\tif (port_spec < 0)",
                "\t\t\tgoto exit;",
                "\t}"
            ],
            "deleted": [
                "\tif (id->driver_info)",
                "\telse"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The function hso_get_config_data in drivers/net/usb/hso.c in the Linux kernel through 4.19.8 reads if_num from the USB device (as a u8) and uses it to index a small array, resulting in an object out-of-bounds (OOB) read that potentially allows arbitrary read in the kernel address space.",
        "id": 1752
    },
    {
        "cve_id": "CVE-2023-2176",
        "code_before_change": "static int cma_bind_addr(struct rdma_cm_id *id, struct sockaddr *src_addr,\n\t\t\t const struct sockaddr *dst_addr)\n{\n\tstruct sockaddr_storage zero_sock = {};\n\n\tif (src_addr && src_addr->sa_family)\n\t\treturn rdma_bind_addr(id, src_addr);\n\n\t/*\n\t * When the src_addr is not specified, automatically supply an any addr\n\t */\n\tzero_sock.ss_family = dst_addr->sa_family;\n\tif (IS_ENABLED(CONFIG_IPV6) && dst_addr->sa_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *src_addr6 =\n\t\t\t(struct sockaddr_in6 *)&zero_sock;\n\t\tstruct sockaddr_in6 *dst_addr6 =\n\t\t\t(struct sockaddr_in6 *)dst_addr;\n\n\t\tsrc_addr6->sin6_scope_id = dst_addr6->sin6_scope_id;\n\t\tif (ipv6_addr_type(&dst_addr6->sin6_addr) & IPV6_ADDR_LINKLOCAL)\n\t\t\tid->route.addr.dev_addr.bound_dev_if =\n\t\t\t\tdst_addr6->sin6_scope_id;\n\t} else if (dst_addr->sa_family == AF_IB) {\n\t\t((struct sockaddr_ib *)&zero_sock)->sib_pkey =\n\t\t\t((struct sockaddr_ib *)dst_addr)->sib_pkey;\n\t}\n\treturn rdma_bind_addr(id, (struct sockaddr *)&zero_sock);\n}",
        "code_after_change": "static int cma_bind_addr(struct rdma_cm_id *id, struct sockaddr *src_addr,\n\t\t\t const struct sockaddr *dst_addr)\n{\n\tstruct rdma_id_private *id_priv =\n\t\tcontainer_of(id, struct rdma_id_private, id);\n\tstruct sockaddr_storage zero_sock = {};\n\n\tif (src_addr && src_addr->sa_family)\n\t\treturn rdma_bind_addr_dst(id_priv, src_addr, dst_addr);\n\n\t/*\n\t * When the src_addr is not specified, automatically supply an any addr\n\t */\n\tzero_sock.ss_family = dst_addr->sa_family;\n\tif (IS_ENABLED(CONFIG_IPV6) && dst_addr->sa_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *src_addr6 =\n\t\t\t(struct sockaddr_in6 *)&zero_sock;\n\t\tstruct sockaddr_in6 *dst_addr6 =\n\t\t\t(struct sockaddr_in6 *)dst_addr;\n\n\t\tsrc_addr6->sin6_scope_id = dst_addr6->sin6_scope_id;\n\t\tif (ipv6_addr_type(&dst_addr6->sin6_addr) & IPV6_ADDR_LINKLOCAL)\n\t\t\tid->route.addr.dev_addr.bound_dev_if =\n\t\t\t\tdst_addr6->sin6_scope_id;\n\t} else if (dst_addr->sa_family == AF_IB) {\n\t\t((struct sockaddr_ib *)&zero_sock)->sib_pkey =\n\t\t\t((struct sockaddr_ib *)dst_addr)->sib_pkey;\n\t}\n\treturn rdma_bind_addr_dst(id_priv, (struct sockaddr *)&zero_sock, dst_addr);\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,10 +1,12 @@\n static int cma_bind_addr(struct rdma_cm_id *id, struct sockaddr *src_addr,\n \t\t\t const struct sockaddr *dst_addr)\n {\n+\tstruct rdma_id_private *id_priv =\n+\t\tcontainer_of(id, struct rdma_id_private, id);\n \tstruct sockaddr_storage zero_sock = {};\n \n \tif (src_addr && src_addr->sa_family)\n-\t\treturn rdma_bind_addr(id, src_addr);\n+\t\treturn rdma_bind_addr_dst(id_priv, src_addr, dst_addr);\n \n \t/*\n \t * When the src_addr is not specified, automatically supply an any addr\n@@ -24,5 +26,5 @@\n \t\t((struct sockaddr_ib *)&zero_sock)->sib_pkey =\n \t\t\t((struct sockaddr_ib *)dst_addr)->sib_pkey;\n \t}\n-\treturn rdma_bind_addr(id, (struct sockaddr *)&zero_sock);\n+\treturn rdma_bind_addr_dst(id_priv, (struct sockaddr *)&zero_sock, dst_addr);\n }",
        "function_modified_lines": {
            "added": [
                "\tstruct rdma_id_private *id_priv =",
                "\t\tcontainer_of(id, struct rdma_id_private, id);",
                "\t\treturn rdma_bind_addr_dst(id_priv, src_addr, dst_addr);",
                "\treturn rdma_bind_addr_dst(id_priv, (struct sockaddr *)&zero_sock, dst_addr);"
            ],
            "deleted": [
                "\t\treturn rdma_bind_addr(id, src_addr);",
                "\treturn rdma_bind_addr(id, (struct sockaddr *)&zero_sock);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A vulnerability was found in compare_netdev_and_ip in drivers/infiniband/core/cma.c in RDMA in the Linux Kernel. The improper cleanup results in out-of-boundary read, where a local user can utilize this problem to crash the system or escalation of privilege.",
        "id": 3930
    },
    {
        "cve_id": "CVE-2017-7558",
        "code_before_change": "static int inet_diag_msg_sctpladdrs_fill(struct sk_buff *skb,\n\t\t\t\t\t struct list_head *address_list)\n{\n\tstruct sctp_sockaddr_entry *laddr;\n\tint addrlen = sizeof(struct sockaddr_storage);\n\tint addrcnt = 0;\n\tstruct nlattr *attr;\n\tvoid *info = NULL;\n\n\tlist_for_each_entry_rcu(laddr, address_list, list)\n\t\taddrcnt++;\n\n\tattr = nla_reserve(skb, INET_DIAG_LOCALS, addrlen * addrcnt);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tinfo = nla_data(attr);\n\tlist_for_each_entry_rcu(laddr, address_list, list) {\n\t\tmemcpy(info, &laddr->a, addrlen);\n\t\tinfo += addrlen;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int inet_diag_msg_sctpladdrs_fill(struct sk_buff *skb,\n\t\t\t\t\t struct list_head *address_list)\n{\n\tstruct sctp_sockaddr_entry *laddr;\n\tint addrlen = sizeof(struct sockaddr_storage);\n\tint addrcnt = 0;\n\tstruct nlattr *attr;\n\tvoid *info = NULL;\n\n\tlist_for_each_entry_rcu(laddr, address_list, list)\n\t\taddrcnt++;\n\n\tattr = nla_reserve(skb, INET_DIAG_LOCALS, addrlen * addrcnt);\n\tif (!attr)\n\t\treturn -EMSGSIZE;\n\n\tinfo = nla_data(attr);\n\tlist_for_each_entry_rcu(laddr, address_list, list) {\n\t\tmemcpy(info, &laddr->a, sizeof(laddr->a));\n\t\tmemset(info + sizeof(laddr->a), 0, addrlen - sizeof(laddr->a));\n\t\tinfo += addrlen;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,7 +16,8 @@\n \n \tinfo = nla_data(attr);\n \tlist_for_each_entry_rcu(laddr, address_list, list) {\n-\t\tmemcpy(info, &laddr->a, addrlen);\n+\t\tmemcpy(info, &laddr->a, sizeof(laddr->a));\n+\t\tmemset(info + sizeof(laddr->a), 0, addrlen - sizeof(laddr->a));\n \t\tinfo += addrlen;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\t\tmemcpy(info, &laddr->a, sizeof(laddr->a));",
                "\t\tmemset(info + sizeof(laddr->a), 0, addrlen - sizeof(laddr->a));"
            ],
            "deleted": [
                "\t\tmemcpy(info, &laddr->a, addrlen);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A kernel data leak due to an out-of-bound read was found in the Linux kernel in inet_diag_msg_sctp{,l}addr_fill() and sctp_get_sctp_info() functions present since version 4.7-rc1 through version 4.13. A data leak happens when these functions fill in sockaddr data structures used to export socket's diagnostic information. As a result, up to 100 bytes of the slab data could be leaked to a userspace.",
        "id": 1515
    },
    {
        "cve_id": "CVE-2020-0430",
        "code_before_change": "static int check_func_arg(struct bpf_verifier_env *env, u32 regno,\n\t\t\t  enum bpf_arg_type arg_type,\n\t\t\t  struct bpf_call_arg_meta *meta)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\tenum bpf_reg_type expected_type, type = reg->type;\n\tint err = 0;\n\n\tif (arg_type == ARG_DONTCARE)\n\t\treturn 0;\n\n\terr = check_reg_arg(env, regno, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tif (arg_type == ARG_ANYTHING) {\n\t\tif (is_pointer_value(env, regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into helper function\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (type_is_pkt_pointer(type) &&\n\t    !may_access_direct_pkt_data(env, meta, BPF_READ)) {\n\t\tverbose(env, \"helper access to the packet is not allowed\\n\");\n\t\treturn -EACCES;\n\t}\n\n\tif (arg_type == ARG_PTR_TO_MAP_KEY ||\n\t    arg_type == ARG_PTR_TO_MAP_VALUE) {\n\t\texpected_type = PTR_TO_STACK;\n\t\tif (!type_is_pkt_pointer(type) && type != PTR_TO_MAP_VALUE &&\n\t\t    type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_CONST_SIZE ||\n\t\t   arg_type == ARG_CONST_SIZE_OR_ZERO) {\n\t\texpected_type = SCALAR_VALUE;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_CONST_MAP_PTR) {\n\t\texpected_type = CONST_PTR_TO_MAP;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_PTR_TO_CTX) {\n\t\texpected_type = PTR_TO_CTX;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type_is_mem_ptr(arg_type)) {\n\t\texpected_type = PTR_TO_STACK;\n\t\t/* One exception here. In case function allows for NULL to be\n\t\t * passed in as argument, it's a SCALAR_VALUE type. Final test\n\t\t * happens during stack boundary checking.\n\t\t */\n\t\tif (register_is_null(reg) &&\n\t\t    arg_type == ARG_PTR_TO_MEM_OR_NULL)\n\t\t\t/* final test in check_stack_boundary() */;\n\t\telse if (!type_is_pkt_pointer(type) &&\n\t\t\t type != PTR_TO_MAP_VALUE &&\n\t\t\t type != expected_type)\n\t\t\tgoto err_type;\n\t\tmeta->raw_mode = arg_type == ARG_PTR_TO_UNINIT_MEM;\n\t} else {\n\t\tverbose(env, \"unsupported arg_type %d\\n\", arg_type);\n\t\treturn -EFAULT;\n\t}\n\n\tif (arg_type == ARG_CONST_MAP_PTR) {\n\t\t/* bpf_map_xxx(map_ptr) call: remember that map_ptr */\n\t\tmeta->map_ptr = reg->map_ptr;\n\t} else if (arg_type == ARG_PTR_TO_MAP_KEY) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., key) call:\n\t\t * check that [key, key + map->key_size) are within\n\t\t * stack limits and initialized\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* in function declaration map_ptr must come before\n\t\t\t * map_key, so that it's verified and known before\n\t\t\t * we have to check map_key here. Otherwise it means\n\t\t\t * that kernel subsystem misconfigured verifier\n\t\t\t */\n\t\t\tverbose(env, \"invalid map_ptr to access map->key\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->key_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (arg_type == ARG_PTR_TO_MAP_VALUE) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., value) call:\n\t\t * check [value, value + map->value_size) validity\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* kernel subsystem misconfigured verifier */\n\t\t\tverbose(env, \"invalid map_ptr to access map->value\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->value_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (arg_type_is_mem_size(arg_type)) {\n\t\tbool zero_size_allowed = (arg_type == ARG_CONST_SIZE_OR_ZERO);\n\n\t\t/* remember the mem_size which may be used later\n\t\t * to refine return values.\n\t\t */\n\t\tmeta->msize_smax_value = reg->smax_value;\n\t\tmeta->msize_umax_value = reg->umax_value;\n\n\t\t/* The register is SCALAR_VALUE; the access check\n\t\t * happens using its boundaries.\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off))\n\t\t\t/* For unprivileged variable accesses, disable raw\n\t\t\t * mode so that the program is required to\n\t\t\t * initialize all the memory that the helper could\n\t\t\t * just partially fill up.\n\t\t\t */\n\t\t\tmeta = NULL;\n\n\t\tif (reg->smin_value < 0) {\n\t\t\tverbose(env, \"R%d min value is negative, either use unsigned or 'var &= const'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (reg->umin_value == 0) {\n\t\t\terr = check_helper_mem_access(env, regno - 1, 0,\n\t\t\t\t\t\t      zero_size_allowed,\n\t\t\t\t\t\t      meta);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (reg->umax_value >= BPF_MAX_VAR_SIZ) {\n\t\t\tverbose(env, \"R%d unbounded memory access, use 'var &= const' or 'if (var < const)'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno - 1,\n\t\t\t\t\t      reg->umax_value,\n\t\t\t\t\t      zero_size_allowed, meta);\n\t}\n\n\treturn err;\nerr_type:\n\tverbose(env, \"R%d type=%s expected=%s\\n\", regno,\n\t\treg_type_str[type], reg_type_str[expected_type]);\n\treturn -EACCES;\n}",
        "code_after_change": "static int check_func_arg(struct bpf_verifier_env *env, u32 regno,\n\t\t\t  enum bpf_arg_type arg_type,\n\t\t\t  struct bpf_call_arg_meta *meta)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env), *reg = &regs[regno];\n\tenum bpf_reg_type expected_type, type = reg->type;\n\tint err = 0;\n\n\tif (arg_type == ARG_DONTCARE)\n\t\treturn 0;\n\n\terr = check_reg_arg(env, regno, SRC_OP);\n\tif (err)\n\t\treturn err;\n\n\tif (arg_type == ARG_ANYTHING) {\n\t\tif (is_pointer_value(env, regno)) {\n\t\t\tverbose(env, \"R%d leaks addr into helper function\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (type_is_pkt_pointer(type) &&\n\t    !may_access_direct_pkt_data(env, meta, BPF_READ)) {\n\t\tverbose(env, \"helper access to the packet is not allowed\\n\");\n\t\treturn -EACCES;\n\t}\n\n\tif (arg_type == ARG_PTR_TO_MAP_KEY ||\n\t    arg_type == ARG_PTR_TO_MAP_VALUE) {\n\t\texpected_type = PTR_TO_STACK;\n\t\tif (!type_is_pkt_pointer(type) && type != PTR_TO_MAP_VALUE &&\n\t\t    type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_CONST_SIZE ||\n\t\t   arg_type == ARG_CONST_SIZE_OR_ZERO) {\n\t\texpected_type = SCALAR_VALUE;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_CONST_MAP_PTR) {\n\t\texpected_type = CONST_PTR_TO_MAP;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t} else if (arg_type == ARG_PTR_TO_CTX) {\n\t\texpected_type = PTR_TO_CTX;\n\t\tif (type != expected_type)\n\t\t\tgoto err_type;\n\t\terr = check_ctx_reg(env, reg, regno);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t} else if (arg_type_is_mem_ptr(arg_type)) {\n\t\texpected_type = PTR_TO_STACK;\n\t\t/* One exception here. In case function allows for NULL to be\n\t\t * passed in as argument, it's a SCALAR_VALUE type. Final test\n\t\t * happens during stack boundary checking.\n\t\t */\n\t\tif (register_is_null(reg) &&\n\t\t    arg_type == ARG_PTR_TO_MEM_OR_NULL)\n\t\t\t/* final test in check_stack_boundary() */;\n\t\telse if (!type_is_pkt_pointer(type) &&\n\t\t\t type != PTR_TO_MAP_VALUE &&\n\t\t\t type != expected_type)\n\t\t\tgoto err_type;\n\t\tmeta->raw_mode = arg_type == ARG_PTR_TO_UNINIT_MEM;\n\t} else {\n\t\tverbose(env, \"unsupported arg_type %d\\n\", arg_type);\n\t\treturn -EFAULT;\n\t}\n\n\tif (arg_type == ARG_CONST_MAP_PTR) {\n\t\t/* bpf_map_xxx(map_ptr) call: remember that map_ptr */\n\t\tmeta->map_ptr = reg->map_ptr;\n\t} else if (arg_type == ARG_PTR_TO_MAP_KEY) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., key) call:\n\t\t * check that [key, key + map->key_size) are within\n\t\t * stack limits and initialized\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* in function declaration map_ptr must come before\n\t\t\t * map_key, so that it's verified and known before\n\t\t\t * we have to check map_key here. Otherwise it means\n\t\t\t * that kernel subsystem misconfigured verifier\n\t\t\t */\n\t\t\tverbose(env, \"invalid map_ptr to access map->key\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->key_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (arg_type == ARG_PTR_TO_MAP_VALUE) {\n\t\t/* bpf_map_xxx(..., map_ptr, ..., value) call:\n\t\t * check [value, value + map->value_size) validity\n\t\t */\n\t\tif (!meta->map_ptr) {\n\t\t\t/* kernel subsystem misconfigured verifier */\n\t\t\tverbose(env, \"invalid map_ptr to access map->value\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno,\n\t\t\t\t\t      meta->map_ptr->value_size, false,\n\t\t\t\t\t      NULL);\n\t} else if (arg_type_is_mem_size(arg_type)) {\n\t\tbool zero_size_allowed = (arg_type == ARG_CONST_SIZE_OR_ZERO);\n\n\t\t/* remember the mem_size which may be used later\n\t\t * to refine return values.\n\t\t */\n\t\tmeta->msize_smax_value = reg->smax_value;\n\t\tmeta->msize_umax_value = reg->umax_value;\n\n\t\t/* The register is SCALAR_VALUE; the access check\n\t\t * happens using its boundaries.\n\t\t */\n\t\tif (!tnum_is_const(reg->var_off))\n\t\t\t/* For unprivileged variable accesses, disable raw\n\t\t\t * mode so that the program is required to\n\t\t\t * initialize all the memory that the helper could\n\t\t\t * just partially fill up.\n\t\t\t */\n\t\t\tmeta = NULL;\n\n\t\tif (reg->smin_value < 0) {\n\t\t\tverbose(env, \"R%d min value is negative, either use unsigned or 'var &= const'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (reg->umin_value == 0) {\n\t\t\terr = check_helper_mem_access(env, regno - 1, 0,\n\t\t\t\t\t\t      zero_size_allowed,\n\t\t\t\t\t\t      meta);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (reg->umax_value >= BPF_MAX_VAR_SIZ) {\n\t\t\tverbose(env, \"R%d unbounded memory access, use 'var &= const' or 'if (var < const)'\\n\",\n\t\t\t\tregno);\n\t\t\treturn -EACCES;\n\t\t}\n\t\terr = check_helper_mem_access(env, regno - 1,\n\t\t\t\t\t      reg->umax_value,\n\t\t\t\t\t      zero_size_allowed, meta);\n\t}\n\n\treturn err;\nerr_type:\n\tverbose(env, \"R%d type=%s expected=%s\\n\", regno,\n\t\treg_type_str[type], reg_type_str[expected_type]);\n\treturn -EACCES;\n}",
        "patch": "--- code before\n+++ code after\n@@ -47,6 +47,9 @@\n \t\texpected_type = PTR_TO_CTX;\n \t\tif (type != expected_type)\n \t\t\tgoto err_type;\n+\t\terr = check_ctx_reg(env, reg, regno);\n+\t\tif (err < 0)\n+\t\t\treturn err;\n \t} else if (arg_type_is_mem_ptr(arg_type)) {\n \t\texpected_type = PTR_TO_STACK;\n \t\t/* One exception here. In case function allows for NULL to be",
        "function_modified_lines": {
            "added": [
                "\t\terr = check_ctx_reg(env, reg, regno);",
                "\t\tif (err < 0)",
                "\t\t\treturn err;"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "In skb_headlen of /include/linux/skbuff.h, there is a possible out of bounds read due to memory corruption. This could lead to local escalation of privilege with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-153881554",
        "id": 2384
    },
    {
        "cve_id": "CVE-2021-4093",
        "code_before_change": "static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n{\n\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,\n\t       vcpu->arch.pio.count * vcpu->arch.pio.size);\n\tvcpu->arch.pio.count = 0;\n\n\treturn 1;\n}",
        "code_after_change": "static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n{\n\tint size = vcpu->arch.pio.size;\n\tint port = vcpu->arch.pio.port;\n\n\tadvance_sev_es_emulated_ins(vcpu);\n\tif (vcpu->arch.sev_pio_count)\n\t\treturn kvm_sev_es_ins(vcpu, size, port);\n\treturn 1;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,8 +1,10 @@\n static int complete_sev_es_emulated_ins(struct kvm_vcpu *vcpu)\n {\n-\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,\n-\t       vcpu->arch.pio.count * vcpu->arch.pio.size);\n-\tvcpu->arch.pio.count = 0;\n+\tint size = vcpu->arch.pio.size;\n+\tint port = vcpu->arch.pio.port;\n \n+\tadvance_sev_es_emulated_ins(vcpu);\n+\tif (vcpu->arch.sev_pio_count)\n+\t\treturn kvm_sev_es_ins(vcpu, size, port);\n \treturn 1;\n }",
        "function_modified_lines": {
            "added": [
                "\tint size = vcpu->arch.pio.size;",
                "\tint port = vcpu->arch.pio.port;",
                "\tadvance_sev_es_emulated_ins(vcpu);",
                "\tif (vcpu->arch.sev_pio_count)",
                "\t\treturn kvm_sev_es_ins(vcpu, size, port);"
            ],
            "deleted": [
                "\tmemcpy(vcpu->arch.sev_pio_data, vcpu->arch.pio_data,",
                "\t       vcpu->arch.pio.count * vcpu->arch.pio.size);",
                "\tvcpu->arch.pio.count = 0;"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "A flaw was found in the KVM's AMD code for supporting the Secure Encrypted Virtualization-Encrypted State (SEV-ES). A KVM guest using SEV-ES can trigger out-of-bounds reads and writes in the host kernel via a malicious VMGEXIT for a string I/O instruction (for example, outs or ins) using the exit reason SVM_EXIT_IOIO. This issue results in a crash of the entire system or a potential guest-to-host escape scenario.",
        "id": 3130
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "struct inode *ntfs_iget5(struct super_block *sb, const struct MFT_REF *ref,\n\t\t\t const struct cpu_str *name)\n{\n\tstruct inode *inode;\n\n\tinode = iget5_locked(sb, ino_get(ref), ntfs_test_inode, ntfs_set_inode,\n\t\t\t     (void *)ref);\n\tif (unlikely(!inode))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* If this is a freshly allocated inode, need to read it now. */\n\tif (inode->i_state & I_NEW)\n\t\tinode = ntfs_read_mft(inode, name, ref);\n\telse if (ref->seq != ntfs_i(inode)->mi.mrec->seq) {\n\t\t/* Inode overlaps? */\n\t\t_ntfs_bad_inode(inode);\n\t}\n\n\treturn inode;\n}",
        "code_after_change": "struct inode *ntfs_iget5(struct super_block *sb, const struct MFT_REF *ref,\n\t\t\t const struct cpu_str *name)\n{\n\tstruct inode *inode;\n\n\tinode = iget5_locked(sb, ino_get(ref), ntfs_test_inode, ntfs_set_inode,\n\t\t\t     (void *)ref);\n\tif (unlikely(!inode))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\t/* If this is a freshly allocated inode, need to read it now. */\n\tif (inode->i_state & I_NEW)\n\t\tinode = ntfs_read_mft(inode, name, ref);\n\telse if (ref->seq != ntfs_i(inode)->mi.mrec->seq) {\n\t\t/* Inode overlaps? */\n\t\t_ntfs_bad_inode(inode);\n\t}\n\n\tif (IS_ERR(inode) && name)\n\t\tntfs_set_state(sb->s_fs_info, NTFS_DIRTY_ERROR);\n\n\treturn inode;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,5 +16,8 @@\n \t\t_ntfs_bad_inode(inode);\n \t}\n \n+\tif (IS_ERR(inode) && name)\n+\t\tntfs_set_state(sb->s_fs_info, NTFS_DIRTY_ERROR);\n+\n \treturn inode;\n }",
        "function_modified_lines": {
            "added": [
                "\tif (IS_ERR(inode) && name)",
                "\t\tntfs_set_state(sb->s_fs_info, NTFS_DIRTY_ERROR);",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3796
    },
    {
        "cve_id": "CVE-2022-48502",
        "code_before_change": "int indx_read(struct ntfs_index *indx, struct ntfs_inode *ni, CLST vbn,\n\t      struct indx_node **node)\n{\n\tint err;\n\tstruct INDEX_BUFFER *ib;\n\tstruct runs_tree *run = &indx->alloc_run;\n\tstruct rw_semaphore *lock = &indx->run_lock;\n\tu64 vbo = (u64)vbn << indx->vbn2vbo_bits;\n\tu32 bytes = 1u << indx->index_bits;\n\tstruct indx_node *in = *node;\n\tconst struct INDEX_NAMES *name;\n\n\tif (!in) {\n\t\tin = kzalloc(sizeof(struct indx_node), GFP_NOFS);\n\t\tif (!in)\n\t\t\treturn -ENOMEM;\n\t} else {\n\t\tnb_put(&in->nb);\n\t}\n\n\tib = in->index;\n\tif (!ib) {\n\t\tib = kmalloc(bytes, GFP_NOFS);\n\t\tif (!ib) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tdown_read(lock);\n\terr = ntfs_read_bh(ni->mi.sbi, run, vbo, &ib->rhdr, bytes, &in->nb);\n\tup_read(lock);\n\tif (!err)\n\t\tgoto ok;\n\n\tif (err == -E_NTFS_FIXUP)\n\t\tgoto ok;\n\n\tif (err != -ENOENT)\n\t\tgoto out;\n\n\tname = &s_index_names[indx->type];\n\tdown_write(lock);\n\terr = attr_load_runs_range(ni, ATTR_ALLOC, name->name, name->name_len,\n\t\t\t\t   run, vbo, vbo + bytes);\n\tup_write(lock);\n\tif (err)\n\t\tgoto out;\n\n\tdown_read(lock);\n\terr = ntfs_read_bh(ni->mi.sbi, run, vbo, &ib->rhdr, bytes, &in->nb);\n\tup_read(lock);\n\tif (err == -E_NTFS_FIXUP)\n\t\tgoto ok;\n\n\tif (err)\n\t\tgoto out;\n\nok:\n\tif (err == -E_NTFS_FIXUP) {\n\t\tntfs_write_bh(ni->mi.sbi, &ib->rhdr, &in->nb, 0);\n\t\terr = 0;\n\t}\n\n\t/* check for index header length */\n\tif (offsetof(struct INDEX_BUFFER, ihdr) + ib->ihdr.used > bytes) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tin->index = ib;\n\t*node = in;\n\nout:\n\tif (ib != in->index)\n\t\tkfree(ib);\n\n\tif (*node != in) {\n\t\tnb_put(&in->nb);\n\t\tkfree(in);\n\t}\n\n\treturn err;\n}",
        "code_after_change": "int indx_read(struct ntfs_index *indx, struct ntfs_inode *ni, CLST vbn,\n\t      struct indx_node **node)\n{\n\tint err;\n\tstruct INDEX_BUFFER *ib;\n\tstruct runs_tree *run = &indx->alloc_run;\n\tstruct rw_semaphore *lock = &indx->run_lock;\n\tu64 vbo = (u64)vbn << indx->vbn2vbo_bits;\n\tu32 bytes = 1u << indx->index_bits;\n\tstruct indx_node *in = *node;\n\tconst struct INDEX_NAMES *name;\n\n\tif (!in) {\n\t\tin = kzalloc(sizeof(struct indx_node), GFP_NOFS);\n\t\tif (!in)\n\t\t\treturn -ENOMEM;\n\t} else {\n\t\tnb_put(&in->nb);\n\t}\n\n\tib = in->index;\n\tif (!ib) {\n\t\tib = kmalloc(bytes, GFP_NOFS);\n\t\tif (!ib) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tdown_read(lock);\n\terr = ntfs_read_bh(ni->mi.sbi, run, vbo, &ib->rhdr, bytes, &in->nb);\n\tup_read(lock);\n\tif (!err)\n\t\tgoto ok;\n\n\tif (err == -E_NTFS_FIXUP)\n\t\tgoto ok;\n\n\tif (err != -ENOENT)\n\t\tgoto out;\n\n\tname = &s_index_names[indx->type];\n\tdown_write(lock);\n\terr = attr_load_runs_range(ni, ATTR_ALLOC, name->name, name->name_len,\n\t\t\t\t   run, vbo, vbo + bytes);\n\tup_write(lock);\n\tif (err)\n\t\tgoto out;\n\n\tdown_read(lock);\n\terr = ntfs_read_bh(ni->mi.sbi, run, vbo, &ib->rhdr, bytes, &in->nb);\n\tup_read(lock);\n\tif (err == -E_NTFS_FIXUP)\n\t\tgoto ok;\n\n\tif (err)\n\t\tgoto out;\n\nok:\n\tif (!index_buf_check(ib, bytes, &vbn)) {\n\t\tntfs_inode_err(&ni->vfs_inode, \"directory corrupted\");\n\t\tntfs_set_state(ni->mi.sbi, NTFS_DIRTY_ERROR);\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (err == -E_NTFS_FIXUP) {\n\t\tntfs_write_bh(ni->mi.sbi, &ib->rhdr, &in->nb, 0);\n\t\terr = 0;\n\t}\n\n\t/* check for index header length */\n\tif (offsetof(struct INDEX_BUFFER, ihdr) + ib->ihdr.used > bytes) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tin->index = ib;\n\t*node = in;\n\nout:\n\tif (ib != in->index)\n\t\tkfree(ib);\n\n\tif (*node != in) {\n\t\tnb_put(&in->nb);\n\t\tkfree(in);\n\t}\n\n\treturn err;\n}",
        "patch": "--- code before\n+++ code after\n@@ -57,6 +57,13 @@\n \t\tgoto out;\n \n ok:\n+\tif (!index_buf_check(ib, bytes, &vbn)) {\n+\t\tntfs_inode_err(&ni->vfs_inode, \"directory corrupted\");\n+\t\tntfs_set_state(ni->mi.sbi, NTFS_DIRTY_ERROR);\n+\t\terr = -EINVAL;\n+\t\tgoto out;\n+\t}\n+\n \tif (err == -E_NTFS_FIXUP) {\n \t\tntfs_write_bh(ni->mi.sbi, &ib->rhdr, &in->nb, 0);\n \t\terr = 0;",
        "function_modified_lines": {
            "added": [
                "\tif (!index_buf_check(ib, bytes, &vbn)) {",
                "\t\tntfs_inode_err(&ni->vfs_inode, \"directory corrupted\");",
                "\t\tntfs_set_state(ni->mi.sbi, NTFS_DIRTY_ERROR);",
                "\t\terr = -EINVAL;",
                "\t\tgoto out;",
                "\t}",
                ""
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.2. The ntfs3 subsystem does not properly check for correctness during disk reads, leading to an out-of-bounds read in ntfs_set_ea in fs/ntfs3/xattr.c.",
        "id": 3793
    },
    {
        "cve_id": "CVE-2018-1093",
        "code_before_change": "struct buffer_head *\next4_read_block_bitmap_nowait(struct super_block *sb, ext4_group_t block_group)\n{\n\tstruct ext4_group_desc *desc;\n\tstruct buffer_head *bh;\n\text4_fsblk_t bitmap_blk;\n\tint err;\n\n\tdesc = ext4_get_group_desc(sb, block_group, NULL);\n\tif (!desc)\n\t\treturn ERR_PTR(-EFSCORRUPTED);\n\tbitmap_blk = ext4_block_bitmap(sb, desc);\n\tbh = sb_getblk(sb, bitmap_blk);\n\tif (unlikely(!bh)) {\n\t\text4_error(sb, \"Cannot get buffer for block bitmap - \"\n\t\t\t   \"block_group = %u, block_bitmap = %llu\",\n\t\t\t   block_group, bitmap_blk);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tif (bitmap_uptodate(bh))\n\t\tgoto verify;\n\n\tlock_buffer(bh);\n\tif (bitmap_uptodate(bh)) {\n\t\tunlock_buffer(bh);\n\t\tgoto verify;\n\t}\n\text4_lock_group(sb, block_group);\n\tif (desc->bg_flags & cpu_to_le16(EXT4_BG_BLOCK_UNINIT)) {\n\t\terr = ext4_init_block_bitmap(sb, bh, block_group, desc);\n\t\tset_bitmap_uptodate(bh);\n\t\tset_buffer_uptodate(bh);\n\t\tset_buffer_verified(bh);\n\t\text4_unlock_group(sb, block_group);\n\t\tunlock_buffer(bh);\n\t\tif (err) {\n\t\t\text4_error(sb, \"Failed to init block bitmap for group \"\n\t\t\t\t   \"%u: %d\", block_group, err);\n\t\t\tgoto out;\n\t\t}\n\t\tgoto verify;\n\t}\n\text4_unlock_group(sb, block_group);\n\tif (buffer_uptodate(bh)) {\n\t\t/*\n\t\t * if not uninit if bh is uptodate,\n\t\t * bitmap is also uptodate\n\t\t */\n\t\tset_bitmap_uptodate(bh);\n\t\tunlock_buffer(bh);\n\t\tgoto verify;\n\t}\n\t/*\n\t * submit the buffer_head for reading\n\t */\n\tset_buffer_new(bh);\n\ttrace_ext4_read_block_bitmap_load(sb, block_group);\n\tbh->b_end_io = ext4_end_bitmap_read;\n\tget_bh(bh);\n\tsubmit_bh(REQ_OP_READ, REQ_META | REQ_PRIO, bh);\n\treturn bh;\nverify:\n\terr = ext4_validate_block_bitmap(sb, desc, block_group, bh);\n\tif (err)\n\t\tgoto out;\n\treturn bh;\nout:\n\tput_bh(bh);\n\treturn ERR_PTR(err);\n}",
        "code_after_change": "struct buffer_head *\next4_read_block_bitmap_nowait(struct super_block *sb, ext4_group_t block_group)\n{\n\tstruct ext4_group_desc *desc;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct buffer_head *bh;\n\text4_fsblk_t bitmap_blk;\n\tint err;\n\n\tdesc = ext4_get_group_desc(sb, block_group, NULL);\n\tif (!desc)\n\t\treturn ERR_PTR(-EFSCORRUPTED);\n\tbitmap_blk = ext4_block_bitmap(sb, desc);\n\tif ((bitmap_blk <= le32_to_cpu(sbi->s_es->s_first_data_block)) ||\n\t    (bitmap_blk >= ext4_blocks_count(sbi->s_es))) {\n\t\text4_error(sb, \"Invalid block bitmap block %llu in \"\n\t\t\t   \"block_group %u\", bitmap_blk, block_group);\n\t\treturn ERR_PTR(-EFSCORRUPTED);\n\t}\n\tbh = sb_getblk(sb, bitmap_blk);\n\tif (unlikely(!bh)) {\n\t\text4_error(sb, \"Cannot get buffer for block bitmap - \"\n\t\t\t   \"block_group = %u, block_bitmap = %llu\",\n\t\t\t   block_group, bitmap_blk);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tif (bitmap_uptodate(bh))\n\t\tgoto verify;\n\n\tlock_buffer(bh);\n\tif (bitmap_uptodate(bh)) {\n\t\tunlock_buffer(bh);\n\t\tgoto verify;\n\t}\n\text4_lock_group(sb, block_group);\n\tif (desc->bg_flags & cpu_to_le16(EXT4_BG_BLOCK_UNINIT)) {\n\t\terr = ext4_init_block_bitmap(sb, bh, block_group, desc);\n\t\tset_bitmap_uptodate(bh);\n\t\tset_buffer_uptodate(bh);\n\t\tset_buffer_verified(bh);\n\t\text4_unlock_group(sb, block_group);\n\t\tunlock_buffer(bh);\n\t\tif (err) {\n\t\t\text4_error(sb, \"Failed to init block bitmap for group \"\n\t\t\t\t   \"%u: %d\", block_group, err);\n\t\t\tgoto out;\n\t\t}\n\t\tgoto verify;\n\t}\n\text4_unlock_group(sb, block_group);\n\tif (buffer_uptodate(bh)) {\n\t\t/*\n\t\t * if not uninit if bh is uptodate,\n\t\t * bitmap is also uptodate\n\t\t */\n\t\tset_bitmap_uptodate(bh);\n\t\tunlock_buffer(bh);\n\t\tgoto verify;\n\t}\n\t/*\n\t * submit the buffer_head for reading\n\t */\n\tset_buffer_new(bh);\n\ttrace_ext4_read_block_bitmap_load(sb, block_group);\n\tbh->b_end_io = ext4_end_bitmap_read;\n\tget_bh(bh);\n\tsubmit_bh(REQ_OP_READ, REQ_META | REQ_PRIO, bh);\n\treturn bh;\nverify:\n\terr = ext4_validate_block_bitmap(sb, desc, block_group, bh);\n\tif (err)\n\t\tgoto out;\n\treturn bh;\nout:\n\tput_bh(bh);\n\treturn ERR_PTR(err);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,7 @@\n ext4_read_block_bitmap_nowait(struct super_block *sb, ext4_group_t block_group)\n {\n \tstruct ext4_group_desc *desc;\n+\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n \tstruct buffer_head *bh;\n \text4_fsblk_t bitmap_blk;\n \tint err;\n@@ -10,6 +11,12 @@\n \tif (!desc)\n \t\treturn ERR_PTR(-EFSCORRUPTED);\n \tbitmap_blk = ext4_block_bitmap(sb, desc);\n+\tif ((bitmap_blk <= le32_to_cpu(sbi->s_es->s_first_data_block)) ||\n+\t    (bitmap_blk >= ext4_blocks_count(sbi->s_es))) {\n+\t\text4_error(sb, \"Invalid block bitmap block %llu in \"\n+\t\t\t   \"block_group %u\", bitmap_blk, block_group);\n+\t\treturn ERR_PTR(-EFSCORRUPTED);\n+\t}\n \tbh = sb_getblk(sb, bitmap_blk);\n \tif (unlikely(!bh)) {\n \t\text4_error(sb, \"Cannot get buffer for block bitmap - \"",
        "function_modified_lines": {
            "added": [
                "\tstruct ext4_sb_info *sbi = EXT4_SB(sb);",
                "\tif ((bitmap_blk <= le32_to_cpu(sbi->s_es->s_first_data_block)) ||",
                "\t    (bitmap_blk >= ext4_blocks_count(sbi->s_es))) {",
                "\t\text4_error(sb, \"Invalid block bitmap block %llu in \"",
                "\t\t\t   \"block_group %u\", bitmap_blk, block_group);",
                "\t\treturn ERR_PTR(-EFSCORRUPTED);",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The ext4_valid_block_bitmap function in fs/ext4/balloc.c in the Linux kernel through 4.15.15 allows attackers to cause a denial of service (out-of-bounds read and system crash) via a crafted ext4 image because balloc.c and ialloc.c do not validate bitmap block numbers.",
        "id": 1625
    },
    {
        "cve_id": "CVE-2018-1093",
        "code_before_change": "static struct buffer_head *\next4_read_inode_bitmap(struct super_block *sb, ext4_group_t block_group)\n{\n\tstruct ext4_group_desc *desc;\n\tstruct buffer_head *bh = NULL;\n\text4_fsblk_t bitmap_blk;\n\tint err;\n\n\tdesc = ext4_get_group_desc(sb, block_group, NULL);\n\tif (!desc)\n\t\treturn ERR_PTR(-EFSCORRUPTED);\n\n\tbitmap_blk = ext4_inode_bitmap(sb, desc);\n\tbh = sb_getblk(sb, bitmap_blk);\n\tif (unlikely(!bh)) {\n\t\text4_error(sb, \"Cannot read inode bitmap - \"\n\t\t\t    \"block_group = %u, inode_bitmap = %llu\",\n\t\t\t    block_group, bitmap_blk);\n\t\treturn ERR_PTR(-EIO);\n\t}\n\tif (bitmap_uptodate(bh))\n\t\tgoto verify;\n\n\tlock_buffer(bh);\n\tif (bitmap_uptodate(bh)) {\n\t\tunlock_buffer(bh);\n\t\tgoto verify;\n\t}\n\n\text4_lock_group(sb, block_group);\n\tif (desc->bg_flags & cpu_to_le16(EXT4_BG_INODE_UNINIT)) {\n\t\tmemset(bh->b_data, 0, (EXT4_INODES_PER_GROUP(sb) + 7) / 8);\n\t\text4_mark_bitmap_end(EXT4_INODES_PER_GROUP(sb),\n\t\t\t\t     sb->s_blocksize * 8, bh->b_data);\n\t\tset_bitmap_uptodate(bh);\n\t\tset_buffer_uptodate(bh);\n\t\tset_buffer_verified(bh);\n\t\text4_unlock_group(sb, block_group);\n\t\tunlock_buffer(bh);\n\t\treturn bh;\n\t}\n\text4_unlock_group(sb, block_group);\n\n\tif (buffer_uptodate(bh)) {\n\t\t/*\n\t\t * if not uninit if bh is uptodate,\n\t\t * bitmap is also uptodate\n\t\t */\n\t\tset_bitmap_uptodate(bh);\n\t\tunlock_buffer(bh);\n\t\tgoto verify;\n\t}\n\t/*\n\t * submit the buffer_head for reading\n\t */\n\ttrace_ext4_load_inode_bitmap(sb, block_group);\n\tbh->b_end_io = ext4_end_bitmap_read;\n\tget_bh(bh);\n\tsubmit_bh(REQ_OP_READ, REQ_META | REQ_PRIO, bh);\n\twait_on_buffer(bh);\n\tif (!buffer_uptodate(bh)) {\n\t\tput_bh(bh);\n\t\text4_error(sb, \"Cannot read inode bitmap - \"\n\t\t\t   \"block_group = %u, inode_bitmap = %llu\",\n\t\t\t   block_group, bitmap_blk);\n\t\treturn ERR_PTR(-EIO);\n\t}\n\nverify:\n\terr = ext4_validate_inode_bitmap(sb, desc, block_group, bh);\n\tif (err)\n\t\tgoto out;\n\treturn bh;\nout:\n\tput_bh(bh);\n\treturn ERR_PTR(err);\n}",
        "code_after_change": "static struct buffer_head *\next4_read_inode_bitmap(struct super_block *sb, ext4_group_t block_group)\n{\n\tstruct ext4_group_desc *desc;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct buffer_head *bh = NULL;\n\text4_fsblk_t bitmap_blk;\n\tint err;\n\n\tdesc = ext4_get_group_desc(sb, block_group, NULL);\n\tif (!desc)\n\t\treturn ERR_PTR(-EFSCORRUPTED);\n\n\tbitmap_blk = ext4_inode_bitmap(sb, desc);\n\tif ((bitmap_blk <= le32_to_cpu(sbi->s_es->s_first_data_block)) ||\n\t    (bitmap_blk >= ext4_blocks_count(sbi->s_es))) {\n\t\text4_error(sb, \"Invalid inode bitmap blk %llu in \"\n\t\t\t   \"block_group %u\", bitmap_blk, block_group);\n\t\treturn ERR_PTR(-EFSCORRUPTED);\n\t}\n\tbh = sb_getblk(sb, bitmap_blk);\n\tif (unlikely(!bh)) {\n\t\text4_error(sb, \"Cannot read inode bitmap - \"\n\t\t\t    \"block_group = %u, inode_bitmap = %llu\",\n\t\t\t    block_group, bitmap_blk);\n\t\treturn ERR_PTR(-EIO);\n\t}\n\tif (bitmap_uptodate(bh))\n\t\tgoto verify;\n\n\tlock_buffer(bh);\n\tif (bitmap_uptodate(bh)) {\n\t\tunlock_buffer(bh);\n\t\tgoto verify;\n\t}\n\n\text4_lock_group(sb, block_group);\n\tif (desc->bg_flags & cpu_to_le16(EXT4_BG_INODE_UNINIT)) {\n\t\tmemset(bh->b_data, 0, (EXT4_INODES_PER_GROUP(sb) + 7) / 8);\n\t\text4_mark_bitmap_end(EXT4_INODES_PER_GROUP(sb),\n\t\t\t\t     sb->s_blocksize * 8, bh->b_data);\n\t\tset_bitmap_uptodate(bh);\n\t\tset_buffer_uptodate(bh);\n\t\tset_buffer_verified(bh);\n\t\text4_unlock_group(sb, block_group);\n\t\tunlock_buffer(bh);\n\t\treturn bh;\n\t}\n\text4_unlock_group(sb, block_group);\n\n\tif (buffer_uptodate(bh)) {\n\t\t/*\n\t\t * if not uninit if bh is uptodate,\n\t\t * bitmap is also uptodate\n\t\t */\n\t\tset_bitmap_uptodate(bh);\n\t\tunlock_buffer(bh);\n\t\tgoto verify;\n\t}\n\t/*\n\t * submit the buffer_head for reading\n\t */\n\ttrace_ext4_load_inode_bitmap(sb, block_group);\n\tbh->b_end_io = ext4_end_bitmap_read;\n\tget_bh(bh);\n\tsubmit_bh(REQ_OP_READ, REQ_META | REQ_PRIO, bh);\n\twait_on_buffer(bh);\n\tif (!buffer_uptodate(bh)) {\n\t\tput_bh(bh);\n\t\text4_error(sb, \"Cannot read inode bitmap - \"\n\t\t\t   \"block_group = %u, inode_bitmap = %llu\",\n\t\t\t   block_group, bitmap_blk);\n\t\treturn ERR_PTR(-EIO);\n\t}\n\nverify:\n\terr = ext4_validate_inode_bitmap(sb, desc, block_group, bh);\n\tif (err)\n\t\tgoto out;\n\treturn bh;\nout:\n\tput_bh(bh);\n\treturn ERR_PTR(err);\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,6 +2,7 @@\n ext4_read_inode_bitmap(struct super_block *sb, ext4_group_t block_group)\n {\n \tstruct ext4_group_desc *desc;\n+\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n \tstruct buffer_head *bh = NULL;\n \text4_fsblk_t bitmap_blk;\n \tint err;\n@@ -11,6 +12,12 @@\n \t\treturn ERR_PTR(-EFSCORRUPTED);\n \n \tbitmap_blk = ext4_inode_bitmap(sb, desc);\n+\tif ((bitmap_blk <= le32_to_cpu(sbi->s_es->s_first_data_block)) ||\n+\t    (bitmap_blk >= ext4_blocks_count(sbi->s_es))) {\n+\t\text4_error(sb, \"Invalid inode bitmap blk %llu in \"\n+\t\t\t   \"block_group %u\", bitmap_blk, block_group);\n+\t\treturn ERR_PTR(-EFSCORRUPTED);\n+\t}\n \tbh = sb_getblk(sb, bitmap_blk);\n \tif (unlikely(!bh)) {\n \t\text4_error(sb, \"Cannot read inode bitmap - \"",
        "function_modified_lines": {
            "added": [
                "\tstruct ext4_sb_info *sbi = EXT4_SB(sb);",
                "\tif ((bitmap_blk <= le32_to_cpu(sbi->s_es->s_first_data_block)) ||",
                "\t    (bitmap_blk >= ext4_blocks_count(sbi->s_es))) {",
                "\t\text4_error(sb, \"Invalid inode bitmap blk %llu in \"",
                "\t\t\t   \"block_group %u\", bitmap_blk, block_group);",
                "\t\treturn ERR_PTR(-EFSCORRUPTED);",
                "\t}"
            ],
            "deleted": []
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The ext4_valid_block_bitmap function in fs/ext4/balloc.c in the Linux kernel through 4.15.15 allows attackers to cause a denial of service (out-of-bounds read and system crash) via a crafted ext4 image because balloc.c and ialloc.c do not validate bitmap block numbers.",
        "id": 1626
    },
    {
        "cve_id": "CVE-2017-9984",
        "code_before_change": "void snd_msndmidi_input_read(void *mpuv)\n{\n\tunsigned long flags;\n\tstruct snd_msndmidi *mpu = mpuv;\n\tvoid *pwMIDQData = mpu->dev->mappedbase + MIDQ_DATA_BUFF;\n\n\tspin_lock_irqsave(&mpu->input_lock, flags);\n\twhile (readw(mpu->dev->MIDQ + JQS_wTail) !=\n\t       readw(mpu->dev->MIDQ + JQS_wHead)) {\n\t\tu16 wTmp, val;\n\t\tval = readw(pwMIDQData + 2 * readw(mpu->dev->MIDQ + JQS_wHead));\n\n\t\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER,\n\t\t\t\t     &mpu->mode))\n\t\t\t\tsnd_rawmidi_receive(mpu->substream_input,\n\t\t\t\t\t\t    (unsigned char *)&val, 1);\n\n\t\twTmp = readw(mpu->dev->MIDQ + JQS_wHead) + 1;\n\t\tif (wTmp > readw(mpu->dev->MIDQ + JQS_wSize))\n\t\t\twritew(0,  mpu->dev->MIDQ + JQS_wHead);\n\t\telse\n\t\t\twritew(wTmp,  mpu->dev->MIDQ + JQS_wHead);\n\t}\n\tspin_unlock_irqrestore(&mpu->input_lock, flags);\n}",
        "code_after_change": "void snd_msndmidi_input_read(void *mpuv)\n{\n\tunsigned long flags;\n\tstruct snd_msndmidi *mpu = mpuv;\n\tvoid *pwMIDQData = mpu->dev->mappedbase + MIDQ_DATA_BUFF;\n\tu16 head, tail, size;\n\n\tspin_lock_irqsave(&mpu->input_lock, flags);\n\thead = readw(mpu->dev->MIDQ + JQS_wHead);\n\ttail = readw(mpu->dev->MIDQ + JQS_wTail);\n\tsize = readw(mpu->dev->MIDQ + JQS_wSize);\n\tif (head > size || tail > size)\n\t\tgoto out;\n\twhile (head != tail) {\n\t\tunsigned char val = readw(pwMIDQData + 2 * head);\n\n\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER, &mpu->mode))\n\t\t\tsnd_rawmidi_receive(mpu->substream_input, &val, 1);\n\t\tif (++head > size)\n\t\t\thead = 0;\n\t\twritew(head, mpu->dev->MIDQ + JQS_wHead);\n\t}\n out:\n\tspin_unlock_irqrestore(&mpu->input_lock, flags);\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,23 +3,23 @@\n \tunsigned long flags;\n \tstruct snd_msndmidi *mpu = mpuv;\n \tvoid *pwMIDQData = mpu->dev->mappedbase + MIDQ_DATA_BUFF;\n+\tu16 head, tail, size;\n \n \tspin_lock_irqsave(&mpu->input_lock, flags);\n-\twhile (readw(mpu->dev->MIDQ + JQS_wTail) !=\n-\t       readw(mpu->dev->MIDQ + JQS_wHead)) {\n-\t\tu16 wTmp, val;\n-\t\tval = readw(pwMIDQData + 2 * readw(mpu->dev->MIDQ + JQS_wHead));\n+\thead = readw(mpu->dev->MIDQ + JQS_wHead);\n+\ttail = readw(mpu->dev->MIDQ + JQS_wTail);\n+\tsize = readw(mpu->dev->MIDQ + JQS_wSize);\n+\tif (head > size || tail > size)\n+\t\tgoto out;\n+\twhile (head != tail) {\n+\t\tunsigned char val = readw(pwMIDQData + 2 * head);\n \n-\t\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER,\n-\t\t\t\t     &mpu->mode))\n-\t\t\t\tsnd_rawmidi_receive(mpu->substream_input,\n-\t\t\t\t\t\t    (unsigned char *)&val, 1);\n-\n-\t\twTmp = readw(mpu->dev->MIDQ + JQS_wHead) + 1;\n-\t\tif (wTmp > readw(mpu->dev->MIDQ + JQS_wSize))\n-\t\t\twritew(0,  mpu->dev->MIDQ + JQS_wHead);\n-\t\telse\n-\t\t\twritew(wTmp,  mpu->dev->MIDQ + JQS_wHead);\n+\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER, &mpu->mode))\n+\t\t\tsnd_rawmidi_receive(mpu->substream_input, &val, 1);\n+\t\tif (++head > size)\n+\t\t\thead = 0;\n+\t\twritew(head, mpu->dev->MIDQ + JQS_wHead);\n \t}\n+ out:\n \tspin_unlock_irqrestore(&mpu->input_lock, flags);\n }",
        "function_modified_lines": {
            "added": [
                "\tu16 head, tail, size;",
                "\thead = readw(mpu->dev->MIDQ + JQS_wHead);",
                "\ttail = readw(mpu->dev->MIDQ + JQS_wTail);",
                "\tsize = readw(mpu->dev->MIDQ + JQS_wSize);",
                "\tif (head > size || tail > size)",
                "\t\tgoto out;",
                "\twhile (head != tail) {",
                "\t\tunsigned char val = readw(pwMIDQData + 2 * head);",
                "\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER, &mpu->mode))",
                "\t\t\tsnd_rawmidi_receive(mpu->substream_input, &val, 1);",
                "\t\tif (++head > size)",
                "\t\t\thead = 0;",
                "\t\twritew(head, mpu->dev->MIDQ + JQS_wHead);",
                " out:"
            ],
            "deleted": [
                "\twhile (readw(mpu->dev->MIDQ + JQS_wTail) !=",
                "\t       readw(mpu->dev->MIDQ + JQS_wHead)) {",
                "\t\tu16 wTmp, val;",
                "\t\tval = readw(pwMIDQData + 2 * readw(mpu->dev->MIDQ + JQS_wHead));",
                "\t\t\tif (test_bit(MSNDMIDI_MODE_BIT_INPUT_TRIGGER,",
                "\t\t\t\t     &mpu->mode))",
                "\t\t\t\tsnd_rawmidi_receive(mpu->substream_input,",
                "\t\t\t\t\t\t    (unsigned char *)&val, 1);",
                "",
                "\t\twTmp = readw(mpu->dev->MIDQ + JQS_wHead) + 1;",
                "\t\tif (wTmp > readw(mpu->dev->MIDQ + JQS_wSize))",
                "\t\t\twritew(0,  mpu->dev->MIDQ + JQS_wHead);",
                "\t\telse",
                "\t\t\twritew(wTmp,  mpu->dev->MIDQ + JQS_wHead);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The snd_msnd_interrupt function in sound/isa/msnd/msnd_pinnacle.c in the Linux kernel through 4.11.7 allows local users to cause a denial of service (over-boundary access) or possibly have unspecified other impact by changing the value of a message queue head pointer between two kernel reads of that value, aka a \"double fetch\" vulnerability.",
        "id": 1571
    },
    {
        "cve_id": "CVE-2022-2785",
        "code_before_change": "static inline int skel_sys_bpf(enum bpf_cmd cmd, union bpf_attr *attr,\n\t\t\t  unsigned int size)\n{\n#ifdef __KERNEL__\n\treturn bpf_sys_bpf(cmd, attr, size);\n#else\n\treturn syscall(__NR_bpf, cmd, attr, size);\n#endif\n}",
        "code_after_change": "static inline int skel_sys_bpf(enum bpf_cmd cmd, union bpf_attr *attr,\n\t\t\t  unsigned int size)\n{\n#ifdef __KERNEL__\n\treturn kern_sys_bpf(cmd, attr, size);\n#else\n\treturn syscall(__NR_bpf, cmd, attr, size);\n#endif\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n \t\t\t  unsigned int size)\n {\n #ifdef __KERNEL__\n-\treturn bpf_sys_bpf(cmd, attr, size);\n+\treturn kern_sys_bpf(cmd, attr, size);\n #else\n \treturn syscall(__NR_bpf, cmd, attr, size);\n #endif",
        "function_modified_lines": {
            "added": [
                "\treturn kern_sys_bpf(cmd, attr, size);"
            ],
            "deleted": [
                "\treturn bpf_sys_bpf(cmd, attr, size);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "There exists an arbitrary memory read within the Linux Kernel BPF - Constants provided to fill pointers in structs passed in to bpf_sys_bpf are not verified and can point anywhere, including memory not owned by BPF. An attacker with CAP_BPF can arbitrarily read memory from anywhere on the system. We recommend upgrading past commit 86f44fcec22c",
        "id": 3497
    },
    {
        "cve_id": "CVE-2018-13098",
        "code_before_change": "struct inode *f2fs_iget(struct super_block *sb, unsigned long ino)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct inode *inode;\n\tint ret = 0;\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (!(inode->i_state & I_NEW)) {\n\t\ttrace_f2fs_iget(inode);\n\t\treturn inode;\n\t}\n\tif (ino == F2FS_NODE_INO(sbi) || ino == F2FS_META_INO(sbi))\n\t\tgoto make_now;\n\n\tret = do_read_inode(inode);\n\tif (ret)\n\t\tgoto bad_inode;\n\tif (!sanity_check_inode(inode)) {\n\t\tret = -EINVAL;\n\t\tgoto bad_inode;\n\t}\nmake_now:\n\tif (ino == F2FS_NODE_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_node_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (ino == F2FS_META_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_meta_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (S_ISREG(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_file_inode_operations;\n\t\tinode->i_fop = &f2fs_file_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_dir_inode_operations;\n\t\tinode->i_fop = &f2fs_dir_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tif (f2fs_encrypted_inode(inode))\n\t\t\tinode->i_op = &f2fs_encrypted_symlink_inode_operations;\n\t\telse\n\t\t\tinode->i_op = &f2fs_symlink_inode_operations;\n\t\tinode_nohighmem(inode);\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t\t\tS_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_special_inode_operations;\n\t\tinit_special_inode(inode, inode->i_mode, inode->i_rdev);\n\t} else {\n\t\tret = -EIO;\n\t\tgoto bad_inode;\n\t}\n\tf2fs_set_inode_flags(inode);\n\tunlock_new_inode(inode);\n\ttrace_f2fs_iget(inode);\n\treturn inode;\n\nbad_inode:\n\tiget_failed(inode);\n\ttrace_f2fs_iget_exit(inode, ret);\n\treturn ERR_PTR(ret);\n}",
        "code_after_change": "struct inode *f2fs_iget(struct super_block *sb, unsigned long ino)\n{\n\tstruct f2fs_sb_info *sbi = F2FS_SB(sb);\n\tstruct inode *inode;\n\tint ret = 0;\n\n\tinode = iget_locked(sb, ino);\n\tif (!inode)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (!(inode->i_state & I_NEW)) {\n\t\ttrace_f2fs_iget(inode);\n\t\treturn inode;\n\t}\n\tif (ino == F2FS_NODE_INO(sbi) || ino == F2FS_META_INO(sbi))\n\t\tgoto make_now;\n\n\tret = do_read_inode(inode);\n\tif (ret)\n\t\tgoto bad_inode;\nmake_now:\n\tif (ino == F2FS_NODE_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_node_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (ino == F2FS_META_INO(sbi)) {\n\t\tinode->i_mapping->a_ops = &f2fs_meta_aops;\n\t\tmapping_set_gfp_mask(inode->i_mapping, GFP_NOFS);\n\t} else if (S_ISREG(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_file_inode_operations;\n\t\tinode->i_fop = &f2fs_file_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_dir_inode_operations;\n\t\tinode->i_fop = &f2fs_dir_operations;\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t\tinode_nohighmem(inode);\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tif (f2fs_encrypted_inode(inode))\n\t\t\tinode->i_op = &f2fs_encrypted_symlink_inode_operations;\n\t\telse\n\t\t\tinode->i_op = &f2fs_symlink_inode_operations;\n\t\tinode_nohighmem(inode);\n\t\tinode->i_mapping->a_ops = &f2fs_dblock_aops;\n\t} else if (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode) ||\n\t\t\tS_ISFIFO(inode->i_mode) || S_ISSOCK(inode->i_mode)) {\n\t\tinode->i_op = &f2fs_special_inode_operations;\n\t\tinit_special_inode(inode, inode->i_mode, inode->i_rdev);\n\t} else {\n\t\tret = -EIO;\n\t\tgoto bad_inode;\n\t}\n\tf2fs_set_inode_flags(inode);\n\tunlock_new_inode(inode);\n\ttrace_f2fs_iget(inode);\n\treturn inode;\n\nbad_inode:\n\tiget_failed(inode);\n\ttrace_f2fs_iget_exit(inode, ret);\n\treturn ERR_PTR(ret);\n}",
        "patch": "--- code before\n+++ code after\n@@ -18,10 +18,6 @@\n \tret = do_read_inode(inode);\n \tif (ret)\n \t\tgoto bad_inode;\n-\tif (!sanity_check_inode(inode)) {\n-\t\tret = -EINVAL;\n-\t\tgoto bad_inode;\n-\t}\n make_now:\n \tif (ino == F2FS_NODE_INO(sbi)) {\n \t\tinode->i_mapping->a_ops = &f2fs_node_aops;",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (!sanity_check_inode(inode)) {",
                "\t\tret = -EINVAL;",
                "\t\tgoto bad_inode;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in fs/f2fs/inode.c in the Linux kernel through 4.17.3. A denial of service (slab out-of-bounds read and BUG) can occur for a modified f2fs filesystem image in which FI_EXTRA_ATTR is set in an inode.",
        "id": 1672
    },
    {
        "cve_id": "CVE-2023-38430",
        "code_before_change": "bool ksmbd_smb_request(struct ksmbd_conn *conn)\n{\n\treturn conn->request_buf[0] == 0;\n}",
        "code_after_change": "bool ksmbd_smb_request(struct ksmbd_conn *conn)\n{\n\t__le32 *proto = (__le32 *)smb2_get_msg(conn->request_buf);\n\n\tif (*proto == SMB2_COMPRESSION_TRANSFORM_ID) {\n\t\tpr_err_ratelimited(\"smb2 compression not support yet\");\n\t\treturn false;\n\t}\n\n\tif (*proto != SMB1_PROTO_NUMBER &&\n\t    *proto != SMB2_PROTO_NUMBER &&\n\t    *proto != SMB2_TRANSFORM_PROTO_NUM)\n\t\treturn false;\n\n\treturn true;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,4 +1,16 @@\n bool ksmbd_smb_request(struct ksmbd_conn *conn)\n {\n-\treturn conn->request_buf[0] == 0;\n+\t__le32 *proto = (__le32 *)smb2_get_msg(conn->request_buf);\n+\n+\tif (*proto == SMB2_COMPRESSION_TRANSFORM_ID) {\n+\t\tpr_err_ratelimited(\"smb2 compression not support yet\");\n+\t\treturn false;\n+\t}\n+\n+\tif (*proto != SMB1_PROTO_NUMBER &&\n+\t    *proto != SMB2_PROTO_NUMBER &&\n+\t    *proto != SMB2_TRANSFORM_PROTO_NUM)\n+\t\treturn false;\n+\n+\treturn true;\n }",
        "function_modified_lines": {
            "added": [
                "\t__le32 *proto = (__le32 *)smb2_get_msg(conn->request_buf);",
                "",
                "\tif (*proto == SMB2_COMPRESSION_TRANSFORM_ID) {",
                "\t\tpr_err_ratelimited(\"smb2 compression not support yet\");",
                "\t\treturn false;",
                "\t}",
                "",
                "\tif (*proto != SMB1_PROTO_NUMBER &&",
                "\t    *proto != SMB2_PROTO_NUMBER &&",
                "\t    *proto != SMB2_TRANSFORM_PROTO_NUM)",
                "\t\treturn false;",
                "",
                "\treturn true;"
            ],
            "deleted": [
                "\treturn conn->request_buf[0] == 0;"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.3.9. ksmbd does not validate the SMB request protocol ID, leading to an out-of-bounds read.",
        "id": 4142
    },
    {
        "cve_id": "CVE-2019-15925",
        "code_before_change": "static int hclge_shaper_para_calc(u32 ir, u8 shaper_level,\n\t\t\t\t  u8 *ir_b, u8 *ir_u, u8 *ir_s)\n{\n#define DIVISOR_CLK\t\t(1000 * 8)\n#define DIVISOR_IR_B_126\t(126 * DIVISOR_CLK)\n\n\tconst u16 tick_array[HCLGE_SHAPER_LVL_CNT] = {\n\t\t6 * 256,        /* Prioriy level */\n\t\t6 * 32,         /* Prioriy group level */\n\t\t6 * 8,          /* Port level */\n\t\t6 * 256         /* Qset level */\n\t};\n\tu8 ir_u_calc = 0;\n\tu8 ir_s_calc = 0;\n\tu32 ir_calc;\n\tu32 tick;\n\n\t/* Calc tick */\n\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT)\n\t\treturn -EINVAL;\n\n\ttick = tick_array[shaper_level];\n\n\t/**\n\t * Calc the speed if ir_b = 126, ir_u = 0 and ir_s = 0\n\t * the formula is changed to:\n\t *\t\t126 * 1 * 8\n\t * ir_calc = ---------------- * 1000\n\t *\t\ttick * 1\n\t */\n\tir_calc = (DIVISOR_IR_B_126 + (tick >> 1) - 1) / tick;\n\n\tif (ir_calc == ir) {\n\t\t*ir_b = 126;\n\t\t*ir_u = 0;\n\t\t*ir_s = 0;\n\n\t\treturn 0;\n\t} else if (ir_calc > ir) {\n\t\t/* Increasing the denominator to select ir_s value */\n\t\twhile (ir_calc > ir) {\n\t\t\tir_s_calc++;\n\t\t\tir_calc = DIVISOR_IR_B_126 / (tick * (1 << ir_s_calc));\n\t\t}\n\n\t\tif (ir_calc == ir)\n\t\t\t*ir_b = 126;\n\t\telse\n\t\t\t*ir_b = (ir * tick * (1 << ir_s_calc) +\n\t\t\t\t (DIVISOR_CLK >> 1)) / DIVISOR_CLK;\n\t} else {\n\t\t/* Increasing the numerator to select ir_u value */\n\t\tu32 numerator;\n\n\t\twhile (ir_calc < ir) {\n\t\t\tir_u_calc++;\n\t\t\tnumerator = DIVISOR_IR_B_126 * (1 << ir_u_calc);\n\t\t\tir_calc = (numerator + (tick >> 1)) / tick;\n\t\t}\n\n\t\tif (ir_calc == ir) {\n\t\t\t*ir_b = 126;\n\t\t} else {\n\t\t\tu32 denominator = (DIVISOR_CLK * (1 << --ir_u_calc));\n\t\t\t*ir_b = (ir * tick + (denominator >> 1)) / denominator;\n\t\t}\n\t}\n\n\t*ir_u = ir_u_calc;\n\t*ir_s = ir_s_calc;\n\n\treturn 0;\n}",
        "code_after_change": "static int hclge_shaper_para_calc(u32 ir, u8 shaper_level,\n\t\t\t\t  u8 *ir_b, u8 *ir_u, u8 *ir_s)\n{\n#define DIVISOR_CLK\t\t(1000 * 8)\n#define DIVISOR_IR_B_126\t(126 * DIVISOR_CLK)\n\n\tconst u16 tick_array[HCLGE_SHAPER_LVL_CNT] = {\n\t\t6 * 256,        /* Prioriy level */\n\t\t6 * 32,         /* Prioriy group level */\n\t\t6 * 8,          /* Port level */\n\t\t6 * 256         /* Qset level */\n\t};\n\tu8 ir_u_calc = 0;\n\tu8 ir_s_calc = 0;\n\tu32 ir_calc;\n\tu32 tick;\n\n\t/* Calc tick */\n\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT ||\n\t    ir > HCLGE_ETHER_MAX_RATE)\n\t\treturn -EINVAL;\n\n\ttick = tick_array[shaper_level];\n\n\t/**\n\t * Calc the speed if ir_b = 126, ir_u = 0 and ir_s = 0\n\t * the formula is changed to:\n\t *\t\t126 * 1 * 8\n\t * ir_calc = ---------------- * 1000\n\t *\t\ttick * 1\n\t */\n\tir_calc = (DIVISOR_IR_B_126 + (tick >> 1) - 1) / tick;\n\n\tif (ir_calc == ir) {\n\t\t*ir_b = 126;\n\t\t*ir_u = 0;\n\t\t*ir_s = 0;\n\n\t\treturn 0;\n\t} else if (ir_calc > ir) {\n\t\t/* Increasing the denominator to select ir_s value */\n\t\twhile (ir_calc > ir) {\n\t\t\tir_s_calc++;\n\t\t\tir_calc = DIVISOR_IR_B_126 / (tick * (1 << ir_s_calc));\n\t\t}\n\n\t\tif (ir_calc == ir)\n\t\t\t*ir_b = 126;\n\t\telse\n\t\t\t*ir_b = (ir * tick * (1 << ir_s_calc) +\n\t\t\t\t (DIVISOR_CLK >> 1)) / DIVISOR_CLK;\n\t} else {\n\t\t/* Increasing the numerator to select ir_u value */\n\t\tu32 numerator;\n\n\t\twhile (ir_calc < ir) {\n\t\t\tir_u_calc++;\n\t\t\tnumerator = DIVISOR_IR_B_126 * (1 << ir_u_calc);\n\t\t\tir_calc = (numerator + (tick >> 1)) / tick;\n\t\t}\n\n\t\tif (ir_calc == ir) {\n\t\t\t*ir_b = 126;\n\t\t} else {\n\t\t\tu32 denominator = (DIVISOR_CLK * (1 << --ir_u_calc));\n\t\t\t*ir_b = (ir * tick + (denominator >> 1)) / denominator;\n\t\t}\n\t}\n\n\t*ir_u = ir_u_calc;\n\t*ir_s = ir_s_calc;\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -16,7 +16,8 @@\n \tu32 tick;\n \n \t/* Calc tick */\n-\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT)\n+\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT ||\n+\t    ir > HCLGE_ETHER_MAX_RATE)\n \t\treturn -EINVAL;\n \n \ttick = tick_array[shaper_level];",
        "function_modified_lines": {
            "added": [
                "\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT ||",
                "\t    ir > HCLGE_ETHER_MAX_RATE)"
            ],
            "deleted": [
                "\tif (shaper_level >= HCLGE_SHAPER_LVL_CNT)"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 5.2.3. An out of bounds access exists in the function hclge_tm_schd_mode_vnet_base_cfg in the file drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_tm.c.",
        "id": 2037
    },
    {
        "cve_id": "CVE-2017-17741",
        "code_before_change": "static int read_prepare(struct kvm_vcpu *vcpu, void *val, int bytes)\n{\n\tif (vcpu->mmio_read_completed) {\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, bytes,\n\t\t\t       vcpu->mmio_fragments[0].gpa, *(u64 *)val);\n\t\tvcpu->mmio_read_completed = 0;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int read_prepare(struct kvm_vcpu *vcpu, void *val, int bytes)\n{\n\tif (vcpu->mmio_read_completed) {\n\t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, bytes,\n\t\t\t       vcpu->mmio_fragments[0].gpa, val);\n\t\tvcpu->mmio_read_completed = 0;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -2,7 +2,7 @@\n {\n \tif (vcpu->mmio_read_completed) {\n \t\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ, bytes,\n-\t\t\t       vcpu->mmio_fragments[0].gpa, *(u64 *)val);\n+\t\t\t       vcpu->mmio_fragments[0].gpa, val);\n \t\tvcpu->mmio_read_completed = 0;\n \t\treturn 1;\n \t}",
        "function_modified_lines": {
            "added": [
                "\t\t\t       vcpu->mmio_fragments[0].gpa, val);"
            ],
            "deleted": [
                "\t\t\t       vcpu->mmio_fragments[0].gpa, *(u64 *)val);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The KVM implementation in the Linux kernel through 4.14.7 allows attackers to obtain potentially sensitive information from kernel memory, aka a write_mmio stack-based out-of-bounds read, related to arch/x86/kvm/x86.c and include/trace/events/kvm.h.",
        "id": 1370
    },
    {
        "cve_id": "CVE-2017-17741",
        "code_before_change": "static int read_exit_mmio(struct kvm_vcpu *vcpu, gpa_t gpa,\n\t\t\t  void *val, int bytes)\n{\n\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, 0);\n\treturn X86EMUL_IO_NEEDED;\n}",
        "code_after_change": "static int read_exit_mmio(struct kvm_vcpu *vcpu, gpa_t gpa,\n\t\t\t  void *val, int bytes)\n{\n\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, NULL);\n\treturn X86EMUL_IO_NEEDED;\n}",
        "patch": "--- code before\n+++ code after\n@@ -1,6 +1,6 @@\n static int read_exit_mmio(struct kvm_vcpu *vcpu, gpa_t gpa,\n \t\t\t  void *val, int bytes)\n {\n-\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, 0);\n+\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, NULL);\n \treturn X86EMUL_IO_NEEDED;\n }",
        "function_modified_lines": {
            "added": [
                "\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, NULL);"
            ],
            "deleted": [
                "\ttrace_kvm_mmio(KVM_TRACE_MMIO_READ_UNSATISFIED, bytes, gpa, 0);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "The KVM implementation in the Linux kernel through 4.14.7 allows attackers to obtain potentially sensitive information from kernel memory, aka a write_mmio stack-based out-of-bounds read, related to arch/x86/kvm/x86.c and include/trace/events/kvm.h.",
        "id": 1367
    },
    {
        "cve_id": "CVE-2021-3753",
        "code_before_change": "static int vt_k_ioctl(struct tty_struct *tty, unsigned int cmd,\n\t\tunsigned long arg, bool perm)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tvoid __user *up = (void __user *)arg;\n\tunsigned int console = vc->vc_num;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase KIOCSOUND:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\t/*\n\t\t * The use of PIT_TICK_RATE is historic, it used to be\n\t\t * the platform-dependent CLOCK_TICK_RATE between 2.6.12\n\t\t * and 2.6.36, which was a minor but unfortunate ABI\n\t\t * change. kd_mksound is locked by the input layer.\n\t\t */\n\t\tif (arg)\n\t\t\targ = PIT_TICK_RATE / arg;\n\t\tkd_mksound(arg, 0);\n\t\tbreak;\n\n\tcase KDMKTONE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t{\n\t\tunsigned int ticks, count;\n\n\t\t/*\n\t\t * Generate the tone for the appropriate number of ticks.\n\t\t * If the time is zero, turn off sound ourselves.\n\t\t */\n\t\tticks = msecs_to_jiffies((arg >> 16) & 0xffff);\n\t\tcount = ticks ? (arg & 0xffff) : 0;\n\t\tif (count)\n\t\t\tcount = PIT_TICK_RATE / count;\n\t\tkd_mksound(count, ticks);\n\t\tbreak;\n\t}\n\n\tcase KDGKBTYPE:\n\t\t/*\n\t\t * this is na\u00efve.\n\t\t */\n\t\treturn put_user(KB_101, (char __user *)arg);\n\n\t\t/*\n\t\t * These cannot be implemented on any machine that implements\n\t\t * ioperm() in user level (such as Alpha PCs) or not at all.\n\t\t *\n\t\t * XXX: you should never use these, just call ioperm directly..\n\t\t */\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n\t\t/*\n\t\t * KDADDIO and KDDELIO may be able to add ports beyond what\n\t\t * we reject here, but to be safe...\n\t\t *\n\t\t * These are locked internally via sys_ioperm\n\t\t */\n\t\tif (arg < GPFIRST || arg > GPLAST)\n\t\t\treturn -EINVAL;\n\n\t\treturn ksys_ioperm(arg, 1, (cmd == KDADDIO)) ? -ENXIO : 0;\n\n\tcase KDENABIO:\n\tcase KDDISABIO:\n\t\treturn ksys_ioperm(GPFIRST, GPNUM,\n\t\t\t\t  (cmd == KDENABIO)) ? -ENXIO : 0;\n#endif\n\n\t/* Linux m68k/i386 interface for setting the keyboard delay/repeat rate */\n\n\tcase KDKBDREP:\n\t{\n\t\tstruct kbd_repeat kbrep;\n\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&kbrep, up, sizeof(struct kbd_repeat)))\n\t\t\treturn -EFAULT;\n\n\t\tret = kbd_rate(&kbrep);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (copy_to_user(up, &kbrep, sizeof(struct kbd_repeat)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\t}\n\n\tcase KDSETMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\treturn vt_kdsetmode(vc, arg);\n\n\tcase KDGETMODE:\n\t\treturn put_user(vc->vc_mode, (int __user *)arg);\n\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\t\t/*\n\t\t * these work like a combination of mmap and KDENABIO.\n\t\t * this could be easily finished.\n\t\t */\n\t\treturn -EINVAL;\n\n\tcase KDSKBMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tret = vt_do_kdskbmode(console, arg);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\ttty_ldisc_flush(tty);\n\t\tbreak;\n\n\tcase KDGKBMODE:\n\t\treturn put_user(vt_do_kdgkbmode(console), (int __user *)arg);\n\n\t/* this could be folded into KDSKBMODE, but for compatibility\n\t   reasons it is not so easy to fold KDGKBMETA into KDGKBMODE */\n\tcase KDSKBMETA:\n\t\treturn vt_do_kdskbmeta(console, arg);\n\n\tcase KDGKBMETA:\n\t\t/* FIXME: should review whether this is worth locking */\n\t\treturn put_user(vt_do_kdgkbmeta(console), (int __user *)arg);\n\n\tcase KDGETKEYCODE:\n\tcase KDSETKEYCODE:\n\t\tif(!capable(CAP_SYS_TTY_CONFIG))\n\t\t\tperm = 0;\n\t\treturn vt_do_kbkeycode_ioctl(cmd, up, perm);\n\n\tcase KDGKBENT:\n\tcase KDSKBENT:\n\t\treturn vt_do_kdsk_ioctl(cmd, up, perm, console);\n\n\tcase KDGKBSENT:\n\tcase KDSKBSENT:\n\t\treturn vt_do_kdgkb_ioctl(cmd, up, perm);\n\n\t/* Diacritical processing. Handled in keyboard.c as it has\n\t   to operate on the keyboard locks and structures */\n\tcase KDGKBDIACR:\n\tcase KDGKBDIACRUC:\n\tcase KDSKBDIACR:\n\tcase KDSKBDIACRUC:\n\t\treturn vt_do_diacrit(cmd, up, perm);\n\n\t/* the ioctls below read/set the flags usually shown in the leds */\n\t/* don't use them - they will go away without warning */\n\tcase KDGKBLED:\n\tcase KDSKBLED:\n\tcase KDGETLED:\n\tcase KDSETLED:\n\t\treturn vt_do_kdskled(console, cmd, arg, perm);\n\n\t/*\n\t * A process can indicate its willingness to accept signals\n\t * generated by pressing an appropriate key combination.\n\t * Thus, one can have a daemon that e.g. spawns a new console\n\t * upon a keypress and then changes to it.\n\t * See also the kbrequest field of inittab(5).\n\t */\n\tcase KDSIGACCEPT:\n\t\tif (!perm || !capable(CAP_KILL))\n\t\t\treturn -EPERM;\n\t\tif (!valid_signal(arg) || arg < 1 || arg == SIGKILL)\n\t\t\treturn -EINVAL;\n\n\t\tspin_lock_irq(&vt_spawn_con.lock);\n\t\tput_pid(vt_spawn_con.pid);\n\t\tvt_spawn_con.pid = get_pid(task_pid(current));\n\t\tvt_spawn_con.sig = arg;\n\t\tspin_unlock_irq(&vt_spawn_con.lock);\n\t\tbreak;\n\n\tcase KDFONTOP: {\n\t\tstruct console_font_op op;\n\n\t\tif (copy_from_user(&op, up, sizeof(op)))\n\t\t\treturn -EFAULT;\n\t\tif (!perm && op.op != KD_FONT_OP_GET)\n\t\t\treturn -EPERM;\n\t\tret = con_font_op(vc, &op);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (copy_to_user(up, &op, sizeof(op)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\treturn 0;\n}",
        "code_after_change": "static int vt_k_ioctl(struct tty_struct *tty, unsigned int cmd,\n\t\tunsigned long arg, bool perm)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tvoid __user *up = (void __user *)arg;\n\tunsigned int console = vc->vc_num;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase KIOCSOUND:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\t/*\n\t\t * The use of PIT_TICK_RATE is historic, it used to be\n\t\t * the platform-dependent CLOCK_TICK_RATE between 2.6.12\n\t\t * and 2.6.36, which was a minor but unfortunate ABI\n\t\t * change. kd_mksound is locked by the input layer.\n\t\t */\n\t\tif (arg)\n\t\t\targ = PIT_TICK_RATE / arg;\n\t\tkd_mksound(arg, 0);\n\t\tbreak;\n\n\tcase KDMKTONE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t{\n\t\tunsigned int ticks, count;\n\n\t\t/*\n\t\t * Generate the tone for the appropriate number of ticks.\n\t\t * If the time is zero, turn off sound ourselves.\n\t\t */\n\t\tticks = msecs_to_jiffies((arg >> 16) & 0xffff);\n\t\tcount = ticks ? (arg & 0xffff) : 0;\n\t\tif (count)\n\t\t\tcount = PIT_TICK_RATE / count;\n\t\tkd_mksound(count, ticks);\n\t\tbreak;\n\t}\n\n\tcase KDGKBTYPE:\n\t\t/*\n\t\t * this is na\u00efve.\n\t\t */\n\t\treturn put_user(KB_101, (char __user *)arg);\n\n\t\t/*\n\t\t * These cannot be implemented on any machine that implements\n\t\t * ioperm() in user level (such as Alpha PCs) or not at all.\n\t\t *\n\t\t * XXX: you should never use these, just call ioperm directly..\n\t\t */\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n\t\t/*\n\t\t * KDADDIO and KDDELIO may be able to add ports beyond what\n\t\t * we reject here, but to be safe...\n\t\t *\n\t\t * These are locked internally via sys_ioperm\n\t\t */\n\t\tif (arg < GPFIRST || arg > GPLAST)\n\t\t\treturn -EINVAL;\n\n\t\treturn ksys_ioperm(arg, 1, (cmd == KDADDIO)) ? -ENXIO : 0;\n\n\tcase KDENABIO:\n\tcase KDDISABIO:\n\t\treturn ksys_ioperm(GPFIRST, GPNUM,\n\t\t\t\t  (cmd == KDENABIO)) ? -ENXIO : 0;\n#endif\n\n\t/* Linux m68k/i386 interface for setting the keyboard delay/repeat rate */\n\n\tcase KDKBDREP:\n\t{\n\t\tstruct kbd_repeat kbrep;\n\n\t\tif (!capable(CAP_SYS_TTY_CONFIG))\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&kbrep, up, sizeof(struct kbd_repeat)))\n\t\t\treturn -EFAULT;\n\n\t\tret = kbd_rate(&kbrep);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (copy_to_user(up, &kbrep, sizeof(struct kbd_repeat)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\t}\n\n\tcase KDSETMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tconsole_lock();\n\t\tret = vt_kdsetmode(vc, arg);\n\t\tconsole_unlock();\n\t\treturn ret;\n\n\tcase KDGETMODE:\n\t\treturn put_user(vc->vc_mode, (int __user *)arg);\n\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\t\t/*\n\t\t * these work like a combination of mmap and KDENABIO.\n\t\t * this could be easily finished.\n\t\t */\n\t\treturn -EINVAL;\n\n\tcase KDSKBMODE:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tret = vt_do_kdskbmode(console, arg);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\ttty_ldisc_flush(tty);\n\t\tbreak;\n\n\tcase KDGKBMODE:\n\t\treturn put_user(vt_do_kdgkbmode(console), (int __user *)arg);\n\n\t/* this could be folded into KDSKBMODE, but for compatibility\n\t   reasons it is not so easy to fold KDGKBMETA into KDGKBMODE */\n\tcase KDSKBMETA:\n\t\treturn vt_do_kdskbmeta(console, arg);\n\n\tcase KDGKBMETA:\n\t\t/* FIXME: should review whether this is worth locking */\n\t\treturn put_user(vt_do_kdgkbmeta(console), (int __user *)arg);\n\n\tcase KDGETKEYCODE:\n\tcase KDSETKEYCODE:\n\t\tif(!capable(CAP_SYS_TTY_CONFIG))\n\t\t\tperm = 0;\n\t\treturn vt_do_kbkeycode_ioctl(cmd, up, perm);\n\n\tcase KDGKBENT:\n\tcase KDSKBENT:\n\t\treturn vt_do_kdsk_ioctl(cmd, up, perm, console);\n\n\tcase KDGKBSENT:\n\tcase KDSKBSENT:\n\t\treturn vt_do_kdgkb_ioctl(cmd, up, perm);\n\n\t/* Diacritical processing. Handled in keyboard.c as it has\n\t   to operate on the keyboard locks and structures */\n\tcase KDGKBDIACR:\n\tcase KDGKBDIACRUC:\n\tcase KDSKBDIACR:\n\tcase KDSKBDIACRUC:\n\t\treturn vt_do_diacrit(cmd, up, perm);\n\n\t/* the ioctls below read/set the flags usually shown in the leds */\n\t/* don't use them - they will go away without warning */\n\tcase KDGKBLED:\n\tcase KDSKBLED:\n\tcase KDGETLED:\n\tcase KDSETLED:\n\t\treturn vt_do_kdskled(console, cmd, arg, perm);\n\n\t/*\n\t * A process can indicate its willingness to accept signals\n\t * generated by pressing an appropriate key combination.\n\t * Thus, one can have a daemon that e.g. spawns a new console\n\t * upon a keypress and then changes to it.\n\t * See also the kbrequest field of inittab(5).\n\t */\n\tcase KDSIGACCEPT:\n\t\tif (!perm || !capable(CAP_KILL))\n\t\t\treturn -EPERM;\n\t\tif (!valid_signal(arg) || arg < 1 || arg == SIGKILL)\n\t\t\treturn -EINVAL;\n\n\t\tspin_lock_irq(&vt_spawn_con.lock);\n\t\tput_pid(vt_spawn_con.pid);\n\t\tvt_spawn_con.pid = get_pid(task_pid(current));\n\t\tvt_spawn_con.sig = arg;\n\t\tspin_unlock_irq(&vt_spawn_con.lock);\n\t\tbreak;\n\n\tcase KDFONTOP: {\n\t\tstruct console_font_op op;\n\n\t\tif (copy_from_user(&op, up, sizeof(op)))\n\t\t\treturn -EFAULT;\n\t\tif (!perm && op.op != KD_FONT_OP_GET)\n\t\t\treturn -EPERM;\n\t\tret = con_font_op(vc, &op);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (copy_to_user(up, &op, sizeof(op)))\n\t\t\treturn -EFAULT;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -95,7 +95,10 @@\n \t\tif (!perm)\n \t\t\treturn -EPERM;\n \n-\t\treturn vt_kdsetmode(vc, arg);\n+\t\tconsole_lock();\n+\t\tret = vt_kdsetmode(vc, arg);\n+\t\tconsole_unlock();\n+\t\treturn ret;\n \n \tcase KDGETMODE:\n \t\treturn put_user(vc->vc_mode, (int __user *)arg);",
        "function_modified_lines": {
            "added": [
                "\t\tconsole_lock();",
                "\t\tret = vt_kdsetmode(vc, arg);",
                "\t\tconsole_unlock();",
                "\t\treturn ret;"
            ],
            "deleted": [
                "\t\treturn vt_kdsetmode(vc, arg);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "A race problem was seen in the vt_k_ioctl in drivers/tty/vt/vt_ioctl.c in the Linux kernel, which may cause an out of bounds read in vt as the write access to vc_mode is not protected by lock-in vt_ioctl (KDSETMDE). The highest threat from this vulnerability is to data confidentiality.",
        "id": 3057
    },
    {
        "cve_id": "CVE-2023-38426",
        "code_before_change": "static int smb2_create_sd_buffer(struct ksmbd_work *work,\n\t\t\t\t struct smb2_create_req *req,\n\t\t\t\t const struct path *path)\n{\n\tstruct create_context *context;\n\tstruct create_sd_buf_req *sd_buf;\n\n\tif (!req->CreateContextsOffset)\n\t\treturn -ENOENT;\n\n\t/* Parse SD BUFFER create contexts */\n\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER);\n\tif (!context)\n\t\treturn -ENOENT;\n\telse if (IS_ERR(context))\n\t\treturn PTR_ERR(context);\n\n\tksmbd_debug(SMB,\n\t\t    \"Set ACLs using SMB2_CREATE_SD_BUFFER context\\n\");\n\tsd_buf = (struct create_sd_buf_req *)context;\n\tif (le16_to_cpu(context->DataOffset) +\n\t    le32_to_cpu(context->DataLength) <\n\t    sizeof(struct create_sd_buf_req))\n\t\treturn -EINVAL;\n\treturn set_info_sec(work->conn, work->tcon, path, &sd_buf->ntsd,\n\t\t\t    le32_to_cpu(sd_buf->ccontext.DataLength), true);\n}",
        "code_after_change": "static int smb2_create_sd_buffer(struct ksmbd_work *work,\n\t\t\t\t struct smb2_create_req *req,\n\t\t\t\t const struct path *path)\n{\n\tstruct create_context *context;\n\tstruct create_sd_buf_req *sd_buf;\n\n\tif (!req->CreateContextsOffset)\n\t\treturn -ENOENT;\n\n\t/* Parse SD BUFFER create contexts */\n\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER, 4);\n\tif (!context)\n\t\treturn -ENOENT;\n\telse if (IS_ERR(context))\n\t\treturn PTR_ERR(context);\n\n\tksmbd_debug(SMB,\n\t\t    \"Set ACLs using SMB2_CREATE_SD_BUFFER context\\n\");\n\tsd_buf = (struct create_sd_buf_req *)context;\n\tif (le16_to_cpu(context->DataOffset) +\n\t    le32_to_cpu(context->DataLength) <\n\t    sizeof(struct create_sd_buf_req))\n\t\treturn -EINVAL;\n\treturn set_info_sec(work->conn, work->tcon, path, &sd_buf->ntsd,\n\t\t\t    le32_to_cpu(sd_buf->ccontext.DataLength), true);\n}",
        "patch": "--- code before\n+++ code after\n@@ -9,7 +9,7 @@\n \t\treturn -ENOENT;\n \n \t/* Parse SD BUFFER create contexts */\n-\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER);\n+\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER, 4);\n \tif (!context)\n \t\treturn -ENOENT;\n \telse if (IS_ERR(context))",
        "function_modified_lines": {
            "added": [
                "\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER, 4);"
            ],
            "deleted": [
                "\tcontext = smb2_find_context_vals(req, SMB2_CREATE_SD_BUFFER);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the Linux kernel before 6.3.4. ksmbd has an out-of-bounds read in smb2_find_context_vals when create_context's name_len is larger than the tag length.",
        "id": 4139
    },
    {
        "cve_id": "CVE-2023-37453",
        "code_before_change": "static int usb_reset_and_verify_device(struct usb_device *udev)\n{\n\tstruct usb_device\t\t*parent_hdev = udev->parent;\n\tstruct usb_hub\t\t\t*parent_hub;\n\tstruct usb_hcd\t\t\t*hcd = bus_to_hcd(udev->bus);\n\tstruct usb_device_descriptor\tdescriptor = udev->descriptor;\n\tstruct usb_host_bos\t\t*bos;\n\tint\t\t\t\ti, j, ret = 0;\n\tint\t\t\t\tport1 = udev->portnum;\n\n\tif (udev->state == USB_STATE_NOTATTACHED ||\n\t\t\tudev->state == USB_STATE_SUSPENDED) {\n\t\tdev_dbg(&udev->dev, \"device reset not allowed in state %d\\n\",\n\t\t\t\tudev->state);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!parent_hdev)\n\t\treturn -EISDIR;\n\n\tparent_hub = usb_hub_to_struct_hub(parent_hdev);\n\n\t/* Disable USB2 hardware LPM.\n\t * It will be re-enabled by the enumeration process.\n\t */\n\tusb_disable_usb2_hardware_lpm(udev);\n\n\tbos = udev->bos;\n\tudev->bos = NULL;\n\n\tmutex_lock(hcd->address0_mutex);\n\n\tfor (i = 0; i < PORT_INIT_TRIES; ++i) {\n\t\tif (hub_port_stop_enumerate(parent_hub, port1, i)) {\n\t\t\tret = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* ep0 maxpacket size may change; let the HCD know about it.\n\t\t * Other endpoints will be handled by re-enumeration. */\n\t\tusb_ep0_reinit(udev);\n\t\tret = hub_port_init(parent_hub, udev, port1, i);\n\t\tif (ret >= 0 || ret == -ENOTCONN || ret == -ENODEV)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(hcd->address0_mutex);\n\n\tif (ret < 0)\n\t\tgoto re_enumerate;\n\n\t/* Device might have changed firmware (DFU or similar) */\n\tif (descriptors_changed(udev, &descriptor, bos)) {\n\t\tdev_info(&udev->dev, \"device firmware changed\\n\");\n\t\tudev->descriptor = descriptor;\t/* for disconnect() calls */\n\t\tgoto re_enumerate;\n\t}\n\n\t/* Restore the device's previous configuration */\n\tif (!udev->actconfig)\n\t\tgoto done;\n\n\tmutex_lock(hcd->bandwidth_mutex);\n\tret = usb_hcd_alloc_bandwidth(udev, udev->actconfig, NULL, NULL);\n\tif (ret < 0) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\t\"Busted HC?  Not enough HCD resources for \"\n\t\t\t\t\"old configuration.\\n\");\n\t\tmutex_unlock(hcd->bandwidth_mutex);\n\t\tgoto re_enumerate;\n\t}\n\tret = usb_control_msg(udev, usb_sndctrlpipe(udev, 0),\n\t\t\tUSB_REQ_SET_CONFIGURATION, 0,\n\t\t\tudev->actconfig->desc.bConfigurationValue, 0,\n\t\t\tNULL, 0, USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_err(&udev->dev,\n\t\t\t\"can't restore configuration #%d (error=%d)\\n\",\n\t\t\tudev->actconfig->desc.bConfigurationValue, ret);\n\t\tmutex_unlock(hcd->bandwidth_mutex);\n\t\tgoto re_enumerate;\n\t}\n\tmutex_unlock(hcd->bandwidth_mutex);\n\tusb_set_device_state(udev, USB_STATE_CONFIGURED);\n\n\t/* Put interfaces back into the same altsettings as before.\n\t * Don't bother to send the Set-Interface request for interfaces\n\t * that were already in altsetting 0; besides being unnecessary,\n\t * many devices can't handle it.  Instead just reset the host-side\n\t * endpoint state.\n\t */\n\tfor (i = 0; i < udev->actconfig->desc.bNumInterfaces; i++) {\n\t\tstruct usb_host_config *config = udev->actconfig;\n\t\tstruct usb_interface *intf = config->interface[i];\n\t\tstruct usb_interface_descriptor *desc;\n\n\t\tdesc = &intf->cur_altsetting->desc;\n\t\tif (desc->bAlternateSetting == 0) {\n\t\t\tusb_disable_interface(udev, intf, true);\n\t\t\tusb_enable_interface(udev, intf, true);\n\t\t\tret = 0;\n\t\t} else {\n\t\t\t/* Let the bandwidth allocation function know that this\n\t\t\t * device has been reset, and it will have to use\n\t\t\t * alternate setting 0 as the current alternate setting.\n\t\t\t */\n\t\t\tintf->resetting_device = 1;\n\t\t\tret = usb_set_interface(udev, desc->bInterfaceNumber,\n\t\t\t\t\tdesc->bAlternateSetting);\n\t\t\tintf->resetting_device = 0;\n\t\t}\n\t\tif (ret < 0) {\n\t\t\tdev_err(&udev->dev, \"failed to restore interface %d \"\n\t\t\t\t\"altsetting %d (error=%d)\\n\",\n\t\t\t\tdesc->bInterfaceNumber,\n\t\t\t\tdesc->bAlternateSetting,\n\t\t\t\tret);\n\t\t\tgoto re_enumerate;\n\t\t}\n\t\t/* Resetting also frees any allocated streams */\n\t\tfor (j = 0; j < intf->cur_altsetting->desc.bNumEndpoints; j++)\n\t\t\tintf->cur_altsetting->endpoint[j].streams = 0;\n\t}\n\ndone:\n\t/* Now that the alt settings are re-installed, enable LTM and LPM. */\n\tusb_enable_usb2_hardware_lpm(udev);\n\tusb_unlocked_enable_lpm(udev);\n\tusb_enable_ltm(udev);\n\tusb_release_bos_descriptor(udev);\n\tudev->bos = bos;\n\treturn 0;\n\nre_enumerate:\n\tusb_release_bos_descriptor(udev);\n\tudev->bos = bos;\n\thub_port_logical_disconnect(parent_hub, port1);\n\treturn -ENODEV;\n}",
        "code_after_change": "static int usb_reset_and_verify_device(struct usb_device *udev)\n{\n\tstruct usb_device\t\t*parent_hdev = udev->parent;\n\tstruct usb_hub\t\t\t*parent_hub;\n\tstruct usb_hcd\t\t\t*hcd = bus_to_hcd(udev->bus);\n\tstruct usb_device_descriptor\tdescriptor;\n\tstruct usb_host_bos\t\t*bos;\n\tint\t\t\t\ti, j, ret = 0;\n\tint\t\t\t\tport1 = udev->portnum;\n\n\tif (udev->state == USB_STATE_NOTATTACHED ||\n\t\t\tudev->state == USB_STATE_SUSPENDED) {\n\t\tdev_dbg(&udev->dev, \"device reset not allowed in state %d\\n\",\n\t\t\t\tudev->state);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!parent_hdev)\n\t\treturn -EISDIR;\n\n\tparent_hub = usb_hub_to_struct_hub(parent_hdev);\n\n\t/* Disable USB2 hardware LPM.\n\t * It will be re-enabled by the enumeration process.\n\t */\n\tusb_disable_usb2_hardware_lpm(udev);\n\n\tbos = udev->bos;\n\tudev->bos = NULL;\n\n\tmutex_lock(hcd->address0_mutex);\n\n\tfor (i = 0; i < PORT_INIT_TRIES; ++i) {\n\t\tif (hub_port_stop_enumerate(parent_hub, port1, i)) {\n\t\t\tret = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* ep0 maxpacket size may change; let the HCD know about it.\n\t\t * Other endpoints will be handled by re-enumeration. */\n\t\tusb_ep0_reinit(udev);\n\t\tret = hub_port_init(parent_hub, udev, port1, i, &descriptor);\n\t\tif (ret >= 0 || ret == -ENOTCONN || ret == -ENODEV)\n\t\t\tbreak;\n\t}\n\tmutex_unlock(hcd->address0_mutex);\n\n\tif (ret < 0)\n\t\tgoto re_enumerate;\n\n\t/* Device might have changed firmware (DFU or similar) */\n\tif (descriptors_changed(udev, &descriptor, bos)) {\n\t\tdev_info(&udev->dev, \"device firmware changed\\n\");\n\t\tgoto re_enumerate;\n\t}\n\n\t/* Restore the device's previous configuration */\n\tif (!udev->actconfig)\n\t\tgoto done;\n\n\tmutex_lock(hcd->bandwidth_mutex);\n\tret = usb_hcd_alloc_bandwidth(udev, udev->actconfig, NULL, NULL);\n\tif (ret < 0) {\n\t\tdev_warn(&udev->dev,\n\t\t\t\t\"Busted HC?  Not enough HCD resources for \"\n\t\t\t\t\"old configuration.\\n\");\n\t\tmutex_unlock(hcd->bandwidth_mutex);\n\t\tgoto re_enumerate;\n\t}\n\tret = usb_control_msg(udev, usb_sndctrlpipe(udev, 0),\n\t\t\tUSB_REQ_SET_CONFIGURATION, 0,\n\t\t\tudev->actconfig->desc.bConfigurationValue, 0,\n\t\t\tNULL, 0, USB_CTRL_SET_TIMEOUT);\n\tif (ret < 0) {\n\t\tdev_err(&udev->dev,\n\t\t\t\"can't restore configuration #%d (error=%d)\\n\",\n\t\t\tudev->actconfig->desc.bConfigurationValue, ret);\n\t\tmutex_unlock(hcd->bandwidth_mutex);\n\t\tgoto re_enumerate;\n\t}\n\tmutex_unlock(hcd->bandwidth_mutex);\n\tusb_set_device_state(udev, USB_STATE_CONFIGURED);\n\n\t/* Put interfaces back into the same altsettings as before.\n\t * Don't bother to send the Set-Interface request for interfaces\n\t * that were already in altsetting 0; besides being unnecessary,\n\t * many devices can't handle it.  Instead just reset the host-side\n\t * endpoint state.\n\t */\n\tfor (i = 0; i < udev->actconfig->desc.bNumInterfaces; i++) {\n\t\tstruct usb_host_config *config = udev->actconfig;\n\t\tstruct usb_interface *intf = config->interface[i];\n\t\tstruct usb_interface_descriptor *desc;\n\n\t\tdesc = &intf->cur_altsetting->desc;\n\t\tif (desc->bAlternateSetting == 0) {\n\t\t\tusb_disable_interface(udev, intf, true);\n\t\t\tusb_enable_interface(udev, intf, true);\n\t\t\tret = 0;\n\t\t} else {\n\t\t\t/* Let the bandwidth allocation function know that this\n\t\t\t * device has been reset, and it will have to use\n\t\t\t * alternate setting 0 as the current alternate setting.\n\t\t\t */\n\t\t\tintf->resetting_device = 1;\n\t\t\tret = usb_set_interface(udev, desc->bInterfaceNumber,\n\t\t\t\t\tdesc->bAlternateSetting);\n\t\t\tintf->resetting_device = 0;\n\t\t}\n\t\tif (ret < 0) {\n\t\t\tdev_err(&udev->dev, \"failed to restore interface %d \"\n\t\t\t\t\"altsetting %d (error=%d)\\n\",\n\t\t\t\tdesc->bInterfaceNumber,\n\t\t\t\tdesc->bAlternateSetting,\n\t\t\t\tret);\n\t\t\tgoto re_enumerate;\n\t\t}\n\t\t/* Resetting also frees any allocated streams */\n\t\tfor (j = 0; j < intf->cur_altsetting->desc.bNumEndpoints; j++)\n\t\t\tintf->cur_altsetting->endpoint[j].streams = 0;\n\t}\n\ndone:\n\t/* Now that the alt settings are re-installed, enable LTM and LPM. */\n\tusb_enable_usb2_hardware_lpm(udev);\n\tusb_unlocked_enable_lpm(udev);\n\tusb_enable_ltm(udev);\n\tusb_release_bos_descriptor(udev);\n\tudev->bos = bos;\n\treturn 0;\n\nre_enumerate:\n\tusb_release_bos_descriptor(udev);\n\tudev->bos = bos;\n\thub_port_logical_disconnect(parent_hub, port1);\n\treturn -ENODEV;\n}",
        "patch": "--- code before\n+++ code after\n@@ -3,7 +3,7 @@\n \tstruct usb_device\t\t*parent_hdev = udev->parent;\n \tstruct usb_hub\t\t\t*parent_hub;\n \tstruct usb_hcd\t\t\t*hcd = bus_to_hcd(udev->bus);\n-\tstruct usb_device_descriptor\tdescriptor = udev->descriptor;\n+\tstruct usb_device_descriptor\tdescriptor;\n \tstruct usb_host_bos\t\t*bos;\n \tint\t\t\t\ti, j, ret = 0;\n \tint\t\t\t\tport1 = udev->portnum;\n@@ -39,7 +39,7 @@\n \t\t/* ep0 maxpacket size may change; let the HCD know about it.\n \t\t * Other endpoints will be handled by re-enumeration. */\n \t\tusb_ep0_reinit(udev);\n-\t\tret = hub_port_init(parent_hub, udev, port1, i);\n+\t\tret = hub_port_init(parent_hub, udev, port1, i, &descriptor);\n \t\tif (ret >= 0 || ret == -ENOTCONN || ret == -ENODEV)\n \t\t\tbreak;\n \t}\n@@ -51,7 +51,6 @@\n \t/* Device might have changed firmware (DFU or similar) */\n \tif (descriptors_changed(udev, &descriptor, bos)) {\n \t\tdev_info(&udev->dev, \"device firmware changed\\n\");\n-\t\tudev->descriptor = descriptor;\t/* for disconnect() calls */\n \t\tgoto re_enumerate;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tstruct usb_device_descriptor\tdescriptor;",
                "\t\tret = hub_port_init(parent_hub, udev, port1, i, &descriptor);"
            ],
            "deleted": [
                "\tstruct usb_device_descriptor\tdescriptor = udev->descriptor;",
                "\t\tret = hub_port_init(parent_hub, udev, port1, i);",
                "\t\tudev->descriptor = descriptor;\t/* for disconnect() calls */"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An issue was discovered in the USB subsystem in the Linux kernel through 6.4.2. There is an out-of-bounds and crash in read_descriptors in drivers/usb/core/sysfs.c.",
        "id": 4132
    },
    {
        "cve_id": "CVE-2020-8835",
        "code_before_change": "static void reg_set_min_max_inv(struct bpf_reg_state *true_reg,\n\t\t\t\tstruct bpf_reg_state *false_reg, u64 val,\n\t\t\t\tu8 opcode, bool is_jmp32)\n{\n\ts64 sval;\n\n\tif (__is_pointer_value(false, false_reg))\n\t\treturn;\n\n\tval = is_jmp32 ? (u32)val : val;\n\tsval = is_jmp32 ? (s64)(s32)val : (s64)val;\n\n\tswitch (opcode) {\n\tcase BPF_JEQ:\n\tcase BPF_JNE:\n\t{\n\t\tstruct bpf_reg_state *reg =\n\t\t\topcode == BPF_JEQ ? true_reg : false_reg;\n\n\t\tif (is_jmp32) {\n\t\t\tu64 old_v = reg->var_off.value;\n\t\t\tu64 hi_mask = ~0xffffffffULL;\n\n\t\t\treg->var_off.value = (old_v & hi_mask) | val;\n\t\t\treg->var_off.mask &= hi_mask;\n\t\t} else {\n\t\t\t__mark_reg_known(reg, val);\n\t\t}\n\t\tbreak;\n\t}\n\tcase BPF_JSET:\n\t\tfalse_reg->var_off = tnum_and(false_reg->var_off,\n\t\t\t\t\t      tnum_const(~val));\n\t\tif (is_power_of_2(val))\n\t\t\ttrue_reg->var_off = tnum_or(true_reg->var_off,\n\t\t\t\t\t\t    tnum_const(val));\n\t\tbreak;\n\tcase BPF_JGE:\n\tcase BPF_JGT:\n\t{\n\t\tu64 false_umin = opcode == BPF_JGT ? val    : val + 1;\n\t\tu64 true_umax = opcode == BPF_JGT ? val - 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umin += gen_hi_min(false_reg->var_off);\n\t\t\ttrue_umax += gen_hi_max(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umin_value = max(false_reg->umin_value, false_umin);\n\t\ttrue_reg->umax_value = min(true_reg->umax_value, true_umax);\n\t\tbreak;\n\t}\n\tcase BPF_JSGE:\n\tcase BPF_JSGT:\n\t{\n\t\ts64 false_smin = opcode == BPF_JSGT ? sval    : sval + 1;\n\t\ts64 true_smax = opcode == BPF_JSGT ? sval - 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smin_value = max(false_reg->smin_value, false_smin);\n\t\ttrue_reg->smax_value = min(true_reg->smax_value, true_smax);\n\t\tbreak;\n\t}\n\tcase BPF_JLE:\n\tcase BPF_JLT:\n\t{\n\t\tu64 false_umax = opcode == BPF_JLT ? val    : val - 1;\n\t\tu64 true_umin = opcode == BPF_JLT ? val + 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umax += gen_hi_max(false_reg->var_off);\n\t\t\ttrue_umin += gen_hi_min(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umax_value = min(false_reg->umax_value, false_umax);\n\t\ttrue_reg->umin_value = max(true_reg->umin_value, true_umin);\n\t\tbreak;\n\t}\n\tcase BPF_JSLE:\n\tcase BPF_JSLT:\n\t{\n\t\ts64 false_smax = opcode == BPF_JSLT ? sval    : sval - 1;\n\t\ts64 true_smin = opcode == BPF_JSLT ? sval + 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smax_value = min(false_reg->smax_value, false_smax);\n\t\ttrue_reg->smin_value = max(true_reg->smin_value, true_smin);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\t__reg_deduce_bounds(false_reg);\n\t__reg_deduce_bounds(true_reg);\n\t/* We might have learned some bits from the bounds. */\n\t__reg_bound_offset(false_reg);\n\t__reg_bound_offset(true_reg);\n\tif (is_jmp32) {\n\t\t__reg_bound_offset32(false_reg);\n\t\t__reg_bound_offset32(true_reg);\n\t}\n\t/* Intersecting with the old var_off might have improved our bounds\n\t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n\t * then new var_off is (0; 0x7f...fc) which improves our umax.\n\t */\n\t__update_reg_bounds(false_reg);\n\t__update_reg_bounds(true_reg);\n}",
        "code_after_change": "static void reg_set_min_max_inv(struct bpf_reg_state *true_reg,\n\t\t\t\tstruct bpf_reg_state *false_reg, u64 val,\n\t\t\t\tu8 opcode, bool is_jmp32)\n{\n\ts64 sval;\n\n\tif (__is_pointer_value(false, false_reg))\n\t\treturn;\n\n\tval = is_jmp32 ? (u32)val : val;\n\tsval = is_jmp32 ? (s64)(s32)val : (s64)val;\n\n\tswitch (opcode) {\n\tcase BPF_JEQ:\n\tcase BPF_JNE:\n\t{\n\t\tstruct bpf_reg_state *reg =\n\t\t\topcode == BPF_JEQ ? true_reg : false_reg;\n\n\t\tif (is_jmp32) {\n\t\t\tu64 old_v = reg->var_off.value;\n\t\t\tu64 hi_mask = ~0xffffffffULL;\n\n\t\t\treg->var_off.value = (old_v & hi_mask) | val;\n\t\t\treg->var_off.mask &= hi_mask;\n\t\t} else {\n\t\t\t__mark_reg_known(reg, val);\n\t\t}\n\t\tbreak;\n\t}\n\tcase BPF_JSET:\n\t\tfalse_reg->var_off = tnum_and(false_reg->var_off,\n\t\t\t\t\t      tnum_const(~val));\n\t\tif (is_power_of_2(val))\n\t\t\ttrue_reg->var_off = tnum_or(true_reg->var_off,\n\t\t\t\t\t\t    tnum_const(val));\n\t\tbreak;\n\tcase BPF_JGE:\n\tcase BPF_JGT:\n\t{\n\t\tu64 false_umin = opcode == BPF_JGT ? val    : val + 1;\n\t\tu64 true_umax = opcode == BPF_JGT ? val - 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umin += gen_hi_min(false_reg->var_off);\n\t\t\ttrue_umax += gen_hi_max(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umin_value = max(false_reg->umin_value, false_umin);\n\t\ttrue_reg->umax_value = min(true_reg->umax_value, true_umax);\n\t\tbreak;\n\t}\n\tcase BPF_JSGE:\n\tcase BPF_JSGT:\n\t{\n\t\ts64 false_smin = opcode == BPF_JSGT ? sval    : sval + 1;\n\t\ts64 true_smax = opcode == BPF_JSGT ? sval - 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smin_value = max(false_reg->smin_value, false_smin);\n\t\ttrue_reg->smax_value = min(true_reg->smax_value, true_smax);\n\t\tbreak;\n\t}\n\tcase BPF_JLE:\n\tcase BPF_JLT:\n\t{\n\t\tu64 false_umax = opcode == BPF_JLT ? val    : val - 1;\n\t\tu64 true_umin = opcode == BPF_JLT ? val + 1 : val;\n\n\t\tif (is_jmp32) {\n\t\t\tfalse_umax += gen_hi_max(false_reg->var_off);\n\t\t\ttrue_umin += gen_hi_min(true_reg->var_off);\n\t\t}\n\t\tfalse_reg->umax_value = min(false_reg->umax_value, false_umax);\n\t\ttrue_reg->umin_value = max(true_reg->umin_value, true_umin);\n\t\tbreak;\n\t}\n\tcase BPF_JSLE:\n\tcase BPF_JSLT:\n\t{\n\t\ts64 false_smax = opcode == BPF_JSLT ? sval    : sval - 1;\n\t\ts64 true_smin = opcode == BPF_JSLT ? sval + 1 : sval;\n\n\t\tif (is_jmp32 && !cmp_val_with_extended_s64(sval, false_reg))\n\t\t\tbreak;\n\t\tfalse_reg->smax_value = min(false_reg->smax_value, false_smax);\n\t\ttrue_reg->smin_value = max(true_reg->smin_value, true_smin);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\t__reg_deduce_bounds(false_reg);\n\t__reg_deduce_bounds(true_reg);\n\t/* We might have learned some bits from the bounds. */\n\t__reg_bound_offset(false_reg);\n\t__reg_bound_offset(true_reg);\n\t/* Intersecting with the old var_off might have improved our bounds\n\t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n\t * then new var_off is (0; 0x7f...fc) which improves our umax.\n\t */\n\t__update_reg_bounds(false_reg);\n\t__update_reg_bounds(true_reg);\n}",
        "patch": "--- code before\n+++ code after\n@@ -96,10 +96,6 @@\n \t/* We might have learned some bits from the bounds. */\n \t__reg_bound_offset(false_reg);\n \t__reg_bound_offset(true_reg);\n-\tif (is_jmp32) {\n-\t\t__reg_bound_offset32(false_reg);\n-\t\t__reg_bound_offset32(true_reg);\n-\t}\n \t/* Intersecting with the old var_off might have improved our bounds\n \t * slightly.  e.g. if umax was 0x7f...f and var_off was (0; 0xf...fc),\n \t * then new var_off is (0; 0x7f...fc) which improves our umax.",
        "function_modified_lines": {
            "added": [],
            "deleted": [
                "\tif (is_jmp32) {",
                "\t\t__reg_bound_offset32(false_reg);",
                "\t\t__reg_bound_offset32(true_reg);",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-787"
        ],
        "cve_description": "In the Linux kernel 5.5.0 and newer, the bpf verifier (kernel/bpf/verifier.c) did not properly restrict the register bounds for 32-bit operations, leading to out-of-bounds reads and writes in kernel memory. The vulnerability also affects the Linux 5.4 stable series, starting with v5.4.7, as the introducing commit was backported to that branch. This vulnerability was fixed in 5.6.1, 5.5.14, and 5.4.29. (issue is aka ZDI-CAN-10780)",
        "id": 2808
    },
    {
        "cve_id": "CVE-2023-6610",
        "code_before_change": "int\nsmb2_check_message(char *buf, unsigned int len, struct TCP_Server_Info *server)\n{\n\tstruct TCP_Server_Info *pserver;\n\tstruct smb2_hdr *shdr = (struct smb2_hdr *)buf;\n\tstruct smb2_pdu *pdu = (struct smb2_pdu *)shdr;\n\tint hdr_size = sizeof(struct smb2_hdr);\n\tint pdu_size = sizeof(struct smb2_pdu);\n\tint command;\n\t__u32 calc_len; /* calculated length */\n\t__u64 mid;\n\n\t/* If server is a channel, select the primary channel */\n\tpserver = SERVER_IS_CHAN(server) ? server->primary_server : server;\n\n\t/*\n\t * Add function to do table lookup of StructureSize by command\n\t * ie Validate the wct via smb2_struct_sizes table above\n\t */\n\tif (shdr->ProtocolId == SMB2_TRANSFORM_PROTO_NUM) {\n\t\tstruct smb2_transform_hdr *thdr =\n\t\t\t(struct smb2_transform_hdr *)buf;\n\t\tstruct cifs_ses *ses = NULL;\n\t\tstruct cifs_ses *iter;\n\n\t\t/* decrypt frame now that it is completely read in */\n\t\tspin_lock(&cifs_tcp_ses_lock);\n\t\tlist_for_each_entry(iter, &pserver->smb_ses_list, smb_ses_list) {\n\t\t\tif (iter->Suid == le64_to_cpu(thdr->SessionId)) {\n\t\t\t\tses = iter;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&cifs_tcp_ses_lock);\n\t\tif (!ses) {\n\t\t\tcifs_dbg(VFS, \"no decryption - session id not found\\n\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tmid = le64_to_cpu(shdr->MessageId);\n\tif (len < pdu_size) {\n\t\tif ((len >= hdr_size)\n\t\t    && (shdr->Status != 0)) {\n\t\t\tpdu->StructureSize2 = 0;\n\t\t\t/*\n\t\t\t * As with SMB/CIFS, on some error cases servers may\n\t\t\t * not return wct properly\n\t\t\t */\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tcifs_dbg(VFS, \"Length less than SMB header size\\n\");\n\t\t}\n\t\treturn 1;\n\t}\n\tif (len > CIFSMaxBufSize + MAX_SMB2_HDR_SIZE) {\n\t\tcifs_dbg(VFS, \"SMB length greater than maximum, mid=%llu\\n\",\n\t\t\t mid);\n\t\treturn 1;\n\t}\n\n\tif (check_smb2_hdr(shdr, mid))\n\t\treturn 1;\n\n\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {\n\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",\n\t\t\t le16_to_cpu(shdr->StructureSize));\n\t\treturn 1;\n\t}\n\n\tcommand = le16_to_cpu(shdr->Command);\n\tif (command >= NUMBER_OF_SMB2_COMMANDS) {\n\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);\n\t\treturn 1;\n\t}\n\n\tif (smb2_rsp_struct_sizes[command] != pdu->StructureSize2) {\n\t\tif (command != SMB2_OPLOCK_BREAK_HE && (shdr->Status == 0 ||\n\t\t    pdu->StructureSize2 != SMB2_ERROR_STRUCTURE_SIZE2_LE)) {\n\t\t\t/* error packets have 9 byte structure size */\n\t\t\tcifs_dbg(VFS, \"Invalid response size %u for command %d\\n\",\n\t\t\t\t le16_to_cpu(pdu->StructureSize2), command);\n\t\t\treturn 1;\n\t\t} else if (command == SMB2_OPLOCK_BREAK_HE\n\t\t\t   && (shdr->Status == 0)\n\t\t\t   && (le16_to_cpu(pdu->StructureSize2) != 44)\n\t\t\t   && (le16_to_cpu(pdu->StructureSize2) != 36)) {\n\t\t\t/* special case for SMB2.1 lease break message */\n\t\t\tcifs_dbg(VFS, \"Invalid response size %d for oplock break\\n\",\n\t\t\t\t le16_to_cpu(pdu->StructureSize2));\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tcalc_len = smb2_calc_size(buf);\n\n\t/* For SMB2_IOCTL, OutputOffset and OutputLength are optional, so might\n\t * be 0, and not a real miscalculation */\n\tif (command == SMB2_IOCTL_HE && calc_len == 0)\n\t\treturn 0;\n\n\tif (command == SMB2_NEGOTIATE_HE)\n\t\tcalc_len += get_neg_ctxt_len(shdr, len, calc_len);\n\n\tif (len != calc_len) {\n\t\t/* create failed on symlink */\n\t\tif (command == SMB2_CREATE_HE &&\n\t\t    shdr->Status == STATUS_STOPPED_ON_SYMLINK)\n\t\t\treturn 0;\n\t\t/* Windows 7 server returns 24 bytes more */\n\t\tif (calc_len + 24 == len && command == SMB2_OPLOCK_BREAK_HE)\n\t\t\treturn 0;\n\t\t/* server can return one byte more due to implied bcc[0] */\n\t\tif (calc_len == len + 1)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Some windows servers (win2016) will pad also the final\n\t\t * PDU in a compound to 8 bytes.\n\t\t */\n\t\tif (ALIGN(calc_len, 8) == len)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * MacOS server pads after SMB2.1 write response with 3 bytes\n\t\t * of junk. Other servers match RFC1001 len to actual\n\t\t * SMB2/SMB3 frame length (header + smb2 response specific data)\n\t\t * Some windows servers also pad up to 8 bytes when compounding.\n\t\t */\n\t\tif (calc_len < len)\n\t\t\treturn 0;\n\n\t\t/* Only log a message if len was really miscalculated */\n\t\tif (unlikely(cifsFYI))\n\t\t\tcifs_dbg(FYI, \"Server response too short: calculated \"\n\t\t\t\t \"length %u doesn't match read length %u (cmd=%d, mid=%llu)\\n\",\n\t\t\t\t calc_len, len, command, mid);\n\t\telse\n\t\t\tpr_warn(\"Server response too short: calculated length \"\n\t\t\t\t\"%u doesn't match read length %u (cmd=%d, mid=%llu)\\n\",\n\t\t\t\tcalc_len, len, command, mid);\n\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "code_after_change": "int\nsmb2_check_message(char *buf, unsigned int len, struct TCP_Server_Info *server)\n{\n\tstruct TCP_Server_Info *pserver;\n\tstruct smb2_hdr *shdr = (struct smb2_hdr *)buf;\n\tstruct smb2_pdu *pdu = (struct smb2_pdu *)shdr;\n\tint hdr_size = sizeof(struct smb2_hdr);\n\tint pdu_size = sizeof(struct smb2_pdu);\n\tint command;\n\t__u32 calc_len; /* calculated length */\n\t__u64 mid;\n\n\t/* If server is a channel, select the primary channel */\n\tpserver = SERVER_IS_CHAN(server) ? server->primary_server : server;\n\n\t/*\n\t * Add function to do table lookup of StructureSize by command\n\t * ie Validate the wct via smb2_struct_sizes table above\n\t */\n\tif (shdr->ProtocolId == SMB2_TRANSFORM_PROTO_NUM) {\n\t\tstruct smb2_transform_hdr *thdr =\n\t\t\t(struct smb2_transform_hdr *)buf;\n\t\tstruct cifs_ses *ses = NULL;\n\t\tstruct cifs_ses *iter;\n\n\t\t/* decrypt frame now that it is completely read in */\n\t\tspin_lock(&cifs_tcp_ses_lock);\n\t\tlist_for_each_entry(iter, &pserver->smb_ses_list, smb_ses_list) {\n\t\t\tif (iter->Suid == le64_to_cpu(thdr->SessionId)) {\n\t\t\t\tses = iter;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&cifs_tcp_ses_lock);\n\t\tif (!ses) {\n\t\t\tcifs_dbg(VFS, \"no decryption - session id not found\\n\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tmid = le64_to_cpu(shdr->MessageId);\n\tif (check_smb2_hdr(shdr, mid))\n\t\treturn 1;\n\n\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {\n\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",\n\t\t\t le16_to_cpu(shdr->StructureSize));\n\t\treturn 1;\n\t}\n\n\tcommand = le16_to_cpu(shdr->Command);\n\tif (command >= NUMBER_OF_SMB2_COMMANDS) {\n\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);\n\t\treturn 1;\n\t}\n\n\tif (len < pdu_size) {\n\t\tif ((len >= hdr_size)\n\t\t    && (shdr->Status != 0)) {\n\t\t\tpdu->StructureSize2 = 0;\n\t\t\t/*\n\t\t\t * As with SMB/CIFS, on some error cases servers may\n\t\t\t * not return wct properly\n\t\t\t */\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tcifs_dbg(VFS, \"Length less than SMB header size\\n\");\n\t\t}\n\t\treturn 1;\n\t}\n\tif (len > CIFSMaxBufSize + MAX_SMB2_HDR_SIZE) {\n\t\tcifs_dbg(VFS, \"SMB length greater than maximum, mid=%llu\\n\",\n\t\t\t mid);\n\t\treturn 1;\n\t}\n\n\tif (smb2_rsp_struct_sizes[command] != pdu->StructureSize2) {\n\t\tif (command != SMB2_OPLOCK_BREAK_HE && (shdr->Status == 0 ||\n\t\t    pdu->StructureSize2 != SMB2_ERROR_STRUCTURE_SIZE2_LE)) {\n\t\t\t/* error packets have 9 byte structure size */\n\t\t\tcifs_dbg(VFS, \"Invalid response size %u for command %d\\n\",\n\t\t\t\t le16_to_cpu(pdu->StructureSize2), command);\n\t\t\treturn 1;\n\t\t} else if (command == SMB2_OPLOCK_BREAK_HE\n\t\t\t   && (shdr->Status == 0)\n\t\t\t   && (le16_to_cpu(pdu->StructureSize2) != 44)\n\t\t\t   && (le16_to_cpu(pdu->StructureSize2) != 36)) {\n\t\t\t/* special case for SMB2.1 lease break message */\n\t\t\tcifs_dbg(VFS, \"Invalid response size %d for oplock break\\n\",\n\t\t\t\t le16_to_cpu(pdu->StructureSize2));\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tcalc_len = smb2_calc_size(buf);\n\n\t/* For SMB2_IOCTL, OutputOffset and OutputLength are optional, so might\n\t * be 0, and not a real miscalculation */\n\tif (command == SMB2_IOCTL_HE && calc_len == 0)\n\t\treturn 0;\n\n\tif (command == SMB2_NEGOTIATE_HE)\n\t\tcalc_len += get_neg_ctxt_len(shdr, len, calc_len);\n\n\tif (len != calc_len) {\n\t\t/* create failed on symlink */\n\t\tif (command == SMB2_CREATE_HE &&\n\t\t    shdr->Status == STATUS_STOPPED_ON_SYMLINK)\n\t\t\treturn 0;\n\t\t/* Windows 7 server returns 24 bytes more */\n\t\tif (calc_len + 24 == len && command == SMB2_OPLOCK_BREAK_HE)\n\t\t\treturn 0;\n\t\t/* server can return one byte more due to implied bcc[0] */\n\t\tif (calc_len == len + 1)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Some windows servers (win2016) will pad also the final\n\t\t * PDU in a compound to 8 bytes.\n\t\t */\n\t\tif (ALIGN(calc_len, 8) == len)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * MacOS server pads after SMB2.1 write response with 3 bytes\n\t\t * of junk. Other servers match RFC1001 len to actual\n\t\t * SMB2/SMB3 frame length (header + smb2 response specific data)\n\t\t * Some windows servers also pad up to 8 bytes when compounding.\n\t\t */\n\t\tif (calc_len < len)\n\t\t\treturn 0;\n\n\t\t/* Only log a message if len was really miscalculated */\n\t\tif (unlikely(cifsFYI))\n\t\t\tcifs_dbg(FYI, \"Server response too short: calculated \"\n\t\t\t\t \"length %u doesn't match read length %u (cmd=%d, mid=%llu)\\n\",\n\t\t\t\t calc_len, len, command, mid);\n\t\telse\n\t\t\tpr_warn(\"Server response too short: calculated length \"\n\t\t\t\t\"%u doesn't match read length %u (cmd=%d, mid=%llu)\\n\",\n\t\t\t\tcalc_len, len, command, mid);\n\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "patch": "--- code before\n+++ code after\n@@ -39,6 +39,21 @@\n \t}\n \n \tmid = le64_to_cpu(shdr->MessageId);\n+\tif (check_smb2_hdr(shdr, mid))\n+\t\treturn 1;\n+\n+\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {\n+\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",\n+\t\t\t le16_to_cpu(shdr->StructureSize));\n+\t\treturn 1;\n+\t}\n+\n+\tcommand = le16_to_cpu(shdr->Command);\n+\tif (command >= NUMBER_OF_SMB2_COMMANDS) {\n+\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);\n+\t\treturn 1;\n+\t}\n+\n \tif (len < pdu_size) {\n \t\tif ((len >= hdr_size)\n \t\t    && (shdr->Status != 0)) {\n@@ -56,21 +71,6 @@\n \tif (len > CIFSMaxBufSize + MAX_SMB2_HDR_SIZE) {\n \t\tcifs_dbg(VFS, \"SMB length greater than maximum, mid=%llu\\n\",\n \t\t\t mid);\n-\t\treturn 1;\n-\t}\n-\n-\tif (check_smb2_hdr(shdr, mid))\n-\t\treturn 1;\n-\n-\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {\n-\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",\n-\t\t\t le16_to_cpu(shdr->StructureSize));\n-\t\treturn 1;\n-\t}\n-\n-\tcommand = le16_to_cpu(shdr->Command);\n-\tif (command >= NUMBER_OF_SMB2_COMMANDS) {\n-\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);\n \t\treturn 1;\n \t}\n ",
        "function_modified_lines": {
            "added": [
                "\tif (check_smb2_hdr(shdr, mid))",
                "\t\treturn 1;",
                "",
                "\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {",
                "\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",",
                "\t\t\t le16_to_cpu(shdr->StructureSize));",
                "\t\treturn 1;",
                "\t}",
                "",
                "\tcommand = le16_to_cpu(shdr->Command);",
                "\tif (command >= NUMBER_OF_SMB2_COMMANDS) {",
                "\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);",
                "\t\treturn 1;",
                "\t}",
                ""
            ],
            "deleted": [
                "\t\treturn 1;",
                "\t}",
                "",
                "\tif (check_smb2_hdr(shdr, mid))",
                "\t\treturn 1;",
                "",
                "\tif (shdr->StructureSize != SMB2_HEADER_STRUCTURE_SIZE) {",
                "\t\tcifs_dbg(VFS, \"Invalid structure size %u\\n\",",
                "\t\t\t le16_to_cpu(shdr->StructureSize));",
                "\t\treturn 1;",
                "\t}",
                "",
                "\tcommand = le16_to_cpu(shdr->Command);",
                "\tif (command >= NUMBER_OF_SMB2_COMMANDS) {",
                "\t\tcifs_dbg(VFS, \"Invalid SMB2 command %d\\n\", command);"
            ]
        },
        "cwe": [
            "CWE-125"
        ],
        "cve_description": "An out-of-bounds read vulnerability was found in smb2_dump_detail in fs/smb/client/smb2ops.c in the Linux Kernel. This issue could allow a local attacker to crash the system or leak internal kernel information.",
        "id": 4305
    },
    {
        "cve_id": "CVE-2020-0427",
        "code_before_change": "static int dt_remember_or_free_map(struct pinctrl *p, const char *statename,\n\t\t\t\t   struct pinctrl_dev *pctldev,\n\t\t\t\t   struct pinctrl_map *map, unsigned num_maps)\n{\n\tint i;\n\tstruct pinctrl_dt_map *dt_map;\n\n\t/* Initialize common mapping table entry fields */\n\tfor (i = 0; i < num_maps; i++) {\n\t\tmap[i].dev_name = dev_name(p->dev);\n\t\tmap[i].name = statename;\n\t\tif (pctldev)\n\t\t\tmap[i].ctrl_dev_name = dev_name(pctldev->dev);\n\t}\n\n\t/* Remember the converted mapping table entries */\n\tdt_map = kzalloc(sizeof(*dt_map), GFP_KERNEL);\n\tif (!dt_map) {\n\t\tdt_free_map(pctldev, map, num_maps);\n\t\treturn -ENOMEM;\n\t}\n\n\tdt_map->pctldev = pctldev;\n\tdt_map->map = map;\n\tdt_map->num_maps = num_maps;\n\tlist_add_tail(&dt_map->node, &p->dt_maps);\n\n\treturn pinctrl_register_map(map, num_maps, false);\n}",
        "code_after_change": "static int dt_remember_or_free_map(struct pinctrl *p, const char *statename,\n\t\t\t\t   struct pinctrl_dev *pctldev,\n\t\t\t\t   struct pinctrl_map *map, unsigned num_maps)\n{\n\tint i;\n\tstruct pinctrl_dt_map *dt_map;\n\n\t/* Initialize common mapping table entry fields */\n\tfor (i = 0; i < num_maps; i++) {\n\t\tconst char *devname;\n\n\t\tdevname = kstrdup_const(dev_name(p->dev), GFP_KERNEL);\n\t\tif (!devname)\n\t\t\tgoto err_free_map;\n\n\t\tmap[i].dev_name = devname;\n\t\tmap[i].name = statename;\n\t\tif (pctldev)\n\t\t\tmap[i].ctrl_dev_name = dev_name(pctldev->dev);\n\t}\n\n\t/* Remember the converted mapping table entries */\n\tdt_map = kzalloc(sizeof(*dt_map), GFP_KERNEL);\n\tif (!dt_map)\n\t\tgoto err_free_map;\n\n\tdt_map->pctldev = pctldev;\n\tdt_map->map = map;\n\tdt_map->num_maps = num_maps;\n\tlist_add_tail(&dt_map->node, &p->dt_maps);\n\n\treturn pinctrl_register_map(map, num_maps, false);\n\nerr_free_map:\n\tdt_free_map(pctldev, map, num_maps);\n\treturn -ENOMEM;\n}",
        "patch": "--- code before\n+++ code after\n@@ -7,7 +7,13 @@\n \n \t/* Initialize common mapping table entry fields */\n \tfor (i = 0; i < num_maps; i++) {\n-\t\tmap[i].dev_name = dev_name(p->dev);\n+\t\tconst char *devname;\n+\n+\t\tdevname = kstrdup_const(dev_name(p->dev), GFP_KERNEL);\n+\t\tif (!devname)\n+\t\t\tgoto err_free_map;\n+\n+\t\tmap[i].dev_name = devname;\n \t\tmap[i].name = statename;\n \t\tif (pctldev)\n \t\t\tmap[i].ctrl_dev_name = dev_name(pctldev->dev);\n@@ -15,10 +21,8 @@\n \n \t/* Remember the converted mapping table entries */\n \tdt_map = kzalloc(sizeof(*dt_map), GFP_KERNEL);\n-\tif (!dt_map) {\n-\t\tdt_free_map(pctldev, map, num_maps);\n-\t\treturn -ENOMEM;\n-\t}\n+\tif (!dt_map)\n+\t\tgoto err_free_map;\n \n \tdt_map->pctldev = pctldev;\n \tdt_map->map = map;\n@@ -26,4 +30,8 @@\n \tlist_add_tail(&dt_map->node, &p->dt_maps);\n \n \treturn pinctrl_register_map(map, num_maps, false);\n+\n+err_free_map:\n+\tdt_free_map(pctldev, map, num_maps);\n+\treturn -ENOMEM;\n }",
        "function_modified_lines": {
            "added": [
                "\t\tconst char *devname;",
                "",
                "\t\tdevname = kstrdup_const(dev_name(p->dev), GFP_KERNEL);",
                "\t\tif (!devname)",
                "\t\t\tgoto err_free_map;",
                "",
                "\t\tmap[i].dev_name = devname;",
                "\tif (!dt_map)",
                "\t\tgoto err_free_map;",
                "",
                "err_free_map:",
                "\tdt_free_map(pctldev, map, num_maps);",
                "\treturn -ENOMEM;"
            ],
            "deleted": [
                "\t\tmap[i].dev_name = dev_name(p->dev);",
                "\tif (!dt_map) {",
                "\t\tdt_free_map(pctldev, map, num_maps);",
                "\t\treturn -ENOMEM;",
                "\t}"
            ]
        },
        "cwe": [
            "CWE-125",
            "CWE-416"
        ],
        "cve_description": "In create_pinctrl of core.c, there is a possible out of bounds read due to a use after free. This could lead to local information disclosure with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android kernelAndroid ID: A-140550171",
        "id": 2380
    }
]